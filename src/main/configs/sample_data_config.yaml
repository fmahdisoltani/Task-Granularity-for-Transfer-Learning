paths:
  videos_folder: &vidpath /home/farzaneh/PycharmProjects/pytorch-captioning/sample_data/videos_npz
  checkpoint_folder: /home/farzaneh/PycharmProjects/pytorch-captioning/checkpoint_sample/

  train_annot: &train_annot /home/farzaneh/PycharmProjects/pytorch-captioning/sample_data/json/training_sample.json
  validation_annot: *train_annot
  test_annot: *train_annot

pretrained:
  pretrained_folder:
  pretrained_file:

device:
  synchronize_gpu: &sync True
  gpus: [0]

dataloaders:
  kwargs: {batch_size: &b 16, num_workers: 16, pin_memory: True}

model:
  type: RtorchnCaptioner
  kwargs: {}

loss:
  type: SequenceCrossEntropy

optimizer:
  type: Adam
  kwargs: {lr: &lr 0.01 }

training:
  num_epochs: 200
  clip_grad:
  teacher_force: True
  verbose: False

validation:
  frequency: 5
  teacher_force: False
  verbose: True

criteria:
  score: loss
  higher_is_better: False

targets:
  caption_type: template

tokenizer:
  kwargs: {user_maxlen: 10}

scheduler:
  type:
  kwargs: {}

logging:
  verbose: True
  tensorboard_frequency: