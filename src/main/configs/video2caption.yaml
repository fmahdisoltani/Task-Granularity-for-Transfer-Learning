paths:
  videos_folder: &vidpath /home/waseem/20bn-gitrepo/pytorch-captioning/sample_data/frames
  annot_folder: /home/waseem/20bn-gitrepo/pytorch-captioning/sample_data/json
  checkpoint_folder: /home/waseem/pytorch_models/sample_model/

  train_annot: &train_annot /home/waseem/20bn-gitrepo/pytorch-captioning/sample_data/json/training_sample.json
  validation_annot: *train_annot
  test_annot: *train_annot
  pretrained_path:

device:
  use_cuda: &use_cuda False
  synchronize_gpu: &sync True
  gpus: [0]

dataloaders:
  batch_size: &b 1
  kwargs: {batch_size: *b, num_workers: 16, pin_memory: False}

model:
  type: RtorchnCaptioner
  kwargs: {use_cuda: *use_cuda}

training:
  num_epochs: 200
  learning_rate: &lr 0.01
  teacher_force: True
  verbose: True

validation:
  frequency: 1
  teacher_force: False
  verbose: True

criteria:
  score: loss
  higher_is_better: False

