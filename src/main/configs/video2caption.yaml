paths:
  videos_folder: &vidpath /data/20bn-gestures/videos
  annot_folder: /data/20bn-gestures/json
  train_annot: train_20170517.json.gz
  validation_annot: validation_20170517.json.gz
  test_annot: test_20170517.json.gz
  checkpoint: &ckpt /model_checkpoints/vid2caption_001

training:
  num_epochs: 200
  learning_rate: &lr 0.001
  patience: &pat 10
  resume: False
  pretrained_model: /path/to/checkpoint/dir
  verbose: True

device:
  use_cuda: &use_cuda True
  synchronize_gpu: &sync True
  gpus: [0]

datasets:
  token_min_count: 1
  video_preprocessing:
    train:
      type: random_crop_preprocessing
      args: &trn_args [[36, 96, 96], 64.]
    validation: &val_vid_prep
      type: crop_center_preprocessing
      args: *trn_args
    test: *val_vid_prep
  kwargs: {}

dataloaders:
  batch_size: &b 16
  num_batches_per_epoch: 2500
  kwargs: {batch_size: *b, num_workers: 16, pin_memory: True}

model:
  encoder: FullyConnected
  mapper: FullyConnected
  decoder: FullyConnected

loss:
  type: SequenceCrossEntropy
  args: []

optimizer:
  type: Adam
  kwargs: {lr: *lr}