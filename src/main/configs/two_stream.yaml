paths:
  videos_folder: &vidpath /data-ssd/v2-gulp-160/

  checkpoint_folder: /home/farzaneh/PycharmProjects/pytorch-captioning/results/ECCV/hierarchichal_groups
  pretrained_file: model.best

  train_annot: &train_annot /data/20bn-something-something-v2/v2-train.json
  validation_annot: /data/20bn-something-something-v2/v2-validation.json
  test_annot: /data/20bn-something-something-v2/v2-validation.json
  annot_type: hierarchichal


pretrained:
  pretrained_folder:
  pretrained_file: model.best
  load_encoder_only: True


device:
  synchronize_gpu: &sync True
  gpus: &gpus [0, 1]

dataloaders:
  kwargs: {batch_size: 16, num_workers: 8, pin_memory: False}

model:
  type: EncoderDecoder
  encoder: TwoStreamEncoder
  encoder_args:
  encoder_kwargs: {encoder_output_size: 1024,
                   rnn_output_size: 1024,
                   c2d_out_ch: 0,
                   c3d_out_ch: 32}
  decoder: CoupledLSTMDecoder
  decoder_args:
  decoder_kwargs: {embedding_size: 256,
                   hidden_size: 1024,
                   num_lstm_layers: 2,
                   fc_size: 1024}

loss:
  caption_loss: SequenceCrossEntropy
  balanced: False
  w_caption_loss: 0

  classif_loss: CrossEntropy
  w_classif_loss: 0

  group_loss: CrossEntropy
  w_group_loss: 1



optimizer:
  type: &optimizer Adam
  kwargs: {lr: 0.0001}

scheduler:
  type: ReduceLROnPlateau
  kwargs: {factor: 0.1,
           min_lr: 1.0e-8,
           optimizer: *optimizer,
           patience: 2,
           threshold: 1.0e-4}

training:
  num_epochs: 200
  clip_grad:
  teacher_force: True
  verbose: False

validation:
  frequency: 1
  teacher_force: False
  verbose: True

criteria:
  score: caption_accuracy
  higher_is_better: True

targets:
  caption_type: label

tokenizer:
  kwargs: {user_maxlen: 13, cutoff: 5}

logging:
  verbose: True
  tensorboard_frequency: 1000

preprocess:
    train: &train_video_prep
      [
        {type: PadVideo, args:  [[48, 96, 96]]},
        {type: RandomCrop, args:  [[48, 96, 96]]},
        {type: Float32Converter, args: [64.]},
        {type: PytorchTransposer, args:}
      ]
    valid: &valid_video_prep
      [
        {type: PadVideo, args:  [[48, 96, 96]]},
        {type: CenterCropper, args:  [[48, 96, 96]]},
        {type: Float32Converter, args: [64.]},
        {type: PytorchTransposer, args:}
      ]
    test: *valid_video_prep

dataset:
  train_dataset_type: HierarchichalDataset
  train_dataset_kwargs: {gulp_dir: *vidpath,
                         size: [128, 128]}
  valid_dataset_type: HierarchichalDataset
  valid_dataset_kwargs: {gulp_dir: *vidpath,
                         size: [128, 128]}

preprocess2:
  train_prep_type: FixedSizeCrop1D
  train_prep_kwargs: {cropsize: 48}
  val_prep_type: FixedSizeCrop1D
  val_prep_kwargs: {cropsize: 48}
