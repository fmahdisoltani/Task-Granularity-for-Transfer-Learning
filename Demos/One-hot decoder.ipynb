{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import json\n",
    "\n",
    "import gzip\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def forward(self, decoder_states, teacher_captions,\n",
    "                use_teacher_forcing=False):\n",
    "        \"\"\"(BxD, BxKxV) -> BxKxV\"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "\n",
    "class LSTMDecoder(Decoder):\n",
    "\n",
    "    def __init__(self, embedding_size, hidden_size, vocab_size,\n",
    "                 num_lstm_layers, go_token=0, gpus=None):\n",
    "\n",
    "        super(LSTMDecoder, self).__init__()\n",
    "        self.num_lstm_layers = num_lstm_layers\n",
    "\n",
    "        # Embed each token in vocab to a 128 dimensional vector\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.mapping = nn.Embedding(178, hidden_size)\n",
    "\n",
    "        # batch_first: whether input and output are (batch, seq, feature)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, self.num_lstm_layers, batch_first=True)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "        self.logsoftmax = nn.LogSoftmax()\n",
    "        self.use_cuda = True if gpus else False\n",
    "        self.gpus = gpus\n",
    "        self.go_token = go_token\n",
    "\n",
    "    def init_hidden(self, features):\n",
    "        \"\"\"\n",
    "        Hidden states of the LSTM are initialized with features.\n",
    "        c0 and h0 should have the shape of 1 * batch_size * hidden_size\n",
    "        \"\"\"\n",
    "\n",
    "        c0 = self.mapping(features).unsqueeze(0)\n",
    "        h0 = self.mapping(features).unsqueeze(0)\n",
    "        return h0, c0\n",
    "\n",
    "    def forward(self, features, captions, use_teacher_forcing=False):\n",
    "        \"\"\"\n",
    "        This method computes the forward pass of the decoder with or without\n",
    "        teacher forcing. It should be noted that the <GO> token is\n",
    "        automatically appended to the input captions.\n",
    "        Args:\n",
    "            features: Video features extracted by the encoder.\n",
    "            captions: Video captions (required if use_teacher_forcing=True).\n",
    "            use_teacher_forcing: Whether to use teacher forcing or not.\n",
    "        Returns:\n",
    "            The probability distribution over the vocabulary across the entire\n",
    "            sequence.\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size, num_step = captions.size()\n",
    "        go_part = Variable(self.go_token * torch.ones(batch_size, 1).long())\n",
    "        if self.use_cuda:\n",
    "            go_part = go_part.cuda(self.gpus[0])\n",
    "\n",
    "        if use_teacher_forcing:\n",
    "            # Add go token and remove the last token for all captions\n",
    "            captions_with_go_token = torch.cat([go_part, captions[:, :-1]], 1)\n",
    "            probs, _ = self.apply_lstm(features, captions_with_go_token)\n",
    "        else:\n",
    "            # Without teacher forcing: use its own predictions as the next input\n",
    "            probs = self.predict(features, go_part, num_step)\n",
    "\n",
    "        return probs\n",
    "\n",
    "    def apply_lstm(self, features, captions, lstm_hidden=None):\n",
    "\n",
    "        if lstm_hidden is None:\n",
    "            lstm_hidden = self.init_hidden(features)\n",
    "        embedded_captions = self.embedding(captions)\n",
    "        lstm_output, lstm_hidden = self.lstm(embedded_captions, lstm_hidden)\n",
    "\n",
    "        # Project features in a 'vocab_size'-dimensional space\n",
    "        lstm_out_projected = torch.stack([self.linear(h) for h in lstm_output],\n",
    "                                         0)\n",
    "        probs = torch.stack([self.logsoftmax(h) for h in lstm_out_projected], 0)\n",
    "\n",
    "        return probs, lstm_hidden\n",
    "\n",
    "    def predict(self, features, go_tokens, num_step=1):\n",
    "        lstm_input = go_tokens\n",
    "        output_probs = []\n",
    "        lstm_hidden = None\n",
    "\n",
    "        for i in range(num_step):\n",
    "            probs, lstm_hidden = self.apply_lstm(features, lstm_input,\n",
    "                                                 lstm_hidden)\n",
    "\n",
    "            output_probs.append(probs)\n",
    "            # Greedy decoding\n",
    "            _, preds = torch.max(probs, dim=2)\n",
    "\n",
    "            lstm_input = preds\n",
    "\n",
    "        concatenated_probs = torch.cat(output_probs, dim=1)\n",
    "        return concatenated_probs\n",
    "    \n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def forward(self, decoder_states, teacher_captions,\n",
    "                use_teacher_forcing=False):\n",
    "        \"\"\"(BxD, BxKxV) -> BxKxV\"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "\n",
    "class LSTMDecoder2(Decoder):\n",
    "\n",
    "    def __init__(self, embedding_size, hidden_size, vocab_size,\n",
    "                 num_lstm_layers, go_token=0, gpus=None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.num_lstm_layers = num_lstm_layers\n",
    "\n",
    "        # Embed each token in vocab to a 128 dimensional vector\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "\n",
    "        # batch_first: whether input and output are (batch, seq, feature)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, self.num_lstm_layers, batch_first=True)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "        self.logsoftmax = nn.LogSoftmax()\n",
    "        self.use_cuda = True if gpus else False\n",
    "        self.gpus = gpus\n",
    "        self.go_token = go_token\n",
    "\n",
    "    def init_hidden(self, features):\n",
    "        \"\"\"\n",
    "        Hidden states of the LSTM are initialized with features.\n",
    "        c0 and h0 should have the shape of 1 * batch_size * hidden_size\n",
    "        \"\"\"\n",
    "\n",
    "        c0 = features.unsqueeze(0)\n",
    "        h0 = features.unsqueeze(0)\n",
    "        return h0, c0\n",
    "\n",
    "    def forward(self, features, captions, use_teacher_forcing=False):\n",
    "        \"\"\"\n",
    "        This method computes the forward pass of the decoder with or without\n",
    "        teacher forcing. It should be noted that the <GO> token is\n",
    "        automatically appended to the input captions.\n",
    "        Args:\n",
    "            features: Video features extracted by the encoder.\n",
    "            captions: Video captions (required if use_teacher_forcing=True).\n",
    "            use_teacher_forcing: Whether to use teacher forcing or not.\n",
    "        Returns:\n",
    "            The probability distribution over the vocabulary across the entire\n",
    "            sequence.\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size, num_step = captions.size()\n",
    "        go_part = Variable(self.go_token * torch.ones(batch_size, 1).long())\n",
    "        if self.use_cuda:\n",
    "            go_part = go_part.cuda(self.gpus[0])\n",
    "\n",
    "        if use_teacher_forcing:\n",
    "            # Add go token and remove the last token for all captions\n",
    "            captions_with_go_token = torch.cat([go_part, captions[:, :-1]], 1)\n",
    "            probs, _ = self.apply_lstm(features, captions_with_go_token)\n",
    "        else:\n",
    "            # Without teacher forcing: use its own predictions as the next input\n",
    "            probs = self.predict(features, go_part, num_step)\n",
    "\n",
    "        return probs\n",
    "\n",
    "    def apply_lstm(self, features, captions, lstm_hidden=None):\n",
    "\n",
    "        if lstm_hidden is None:\n",
    "            lstm_hidden = self.init_hidden(features)\n",
    "        embedded_captions = self.embedding(captions)\n",
    "        lstm_output, lstm_hidden = self.lstm(embedded_captions, lstm_hidden)\n",
    "\n",
    "        # Project features in a 'vocab_size'-dimensional space\n",
    "        lstm_out_projected = torch.stack([self.linear(h) for h in lstm_output],\n",
    "                                         0)\n",
    "        probs = torch.stack([self.logsoftmax(h) for h in lstm_out_projected], 0)\n",
    "\n",
    "        return probs, lstm_hidden\n",
    "\n",
    "    def predict(self, features, go_tokens, num_step=1):\n",
    "        lstm_input = go_tokens\n",
    "        output_probs = []\n",
    "        lstm_hidden = None\n",
    "\n",
    "        for i in range(num_step):\n",
    "            probs, lstm_hidden = self.apply_lstm(features, lstm_input,\n",
    "                                                 lstm_hidden)\n",
    "\n",
    "            output_probs.append(probs)\n",
    "            # Greedy decoding\n",
    "            _, preds = torch.max(probs, dim=2)\n",
    "\n",
    "            lstm_input = preds\n",
    "\n",
    "        concatenated_probs = torch.cat(output_probs, dim=1)\n",
    "        return concatenated_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_annotation(path):\n",
    "    if path.endswith(\"gz\"):\n",
    "        with gzip.open(path, \"rb\") as f:\n",
    "            json = pd.read_json(f.read().decode(\"utf-8\"))\n",
    "    else:\n",
    "        json = pd.read_json(path)\n",
    "    return json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "class Tokenizer(object):\n",
    "\n",
    "    GO = \"<GO>\"\n",
    "    END = \"<END>\"\n",
    "    UNK = \"<UNK>\"\n",
    "\n",
    "    def __init__(self, captions=None, user_maxlen=None, cutoff=0):\n",
    "        \"\"\"\n",
    "            Build captions from all the expanded labels in all annotation files.\n",
    "        Args:\n",
    "            captions: list of paths to annotation files.\n",
    "            user_maxlen: the maximum length of the captions set by the user.\n",
    "        \"\"\"\n",
    "\n",
    "        self.maxlen = None if user_maxlen is None else user_maxlen\n",
    "        self.cutoff = cutoff\n",
    "        if captions:\n",
    "            self.build_dictionaries(captions)\n",
    "\n",
    "    def build_dictionaries(self, captions):\n",
    "        \"\"\"\n",
    "            Builds two dictionaries: One that maps from tokens to ints, and\n",
    "            another that maps from ints back to tokens.\n",
    "        \"\"\"\n",
    "\n",
    "        maxlen = np.max([len(caption.split()) for caption in captions]) + 1\n",
    "\n",
    "        self.set_maxlen(maxlen)\n",
    "\n",
    "        print(\"\\nBuilding dictionary for captions...\")\n",
    "        extra_tokens = [self.GO, self.END, self.UNK]\n",
    "        tokens = [self.tokenize(p) for p in captions]\n",
    "        tokens = [item for sublist in tokens for item in sublist]\n",
    "        tokens = self.filter_tokens(tokens)\n",
    "        all_tokens = extra_tokens + sorted(set(tokens))\n",
    "        print(\"Number of different tokens: \", len(all_tokens))\n",
    "        self.caption_dict = {k: idx for idx, k in enumerate(all_tokens)}\n",
    "        self.inv_caption_dict = {idx: k for k, idx in self.caption_dict.items()}\n",
    "        print(self.caption_dict)\n",
    "        print(self.inv_caption_dict)\n",
    "\n",
    "    def tokenize(self, caption):\n",
    "        tokenize_regex = re.compile(\"[^A-Z\\s]\")\n",
    "        return [x for x in tokenize_regex.sub(\n",
    "            \"\", caption.upper()).split(\" \") if x is not \"\"]\n",
    "\n",
    "    def filter_tokens(self, tokens):\n",
    "        count = Counter(tokens)\n",
    "        return [token for token in count if count[token] > self.cutoff]\n",
    "\n",
    "    def encode_caption(self, caption):\n",
    "\n",
    "        tokenized_caption = self.tokenize(caption)\n",
    "        if len(tokenized_caption) >= self.maxlen:\n",
    "            tokenized_caption = tokenized_caption[0:self.maxlen - 1]\n",
    "        encoded_caption = [self.encode_token(token)\n",
    "                           for token in tokenized_caption]\n",
    "        return self.pad_with_end(encoded_caption)\n",
    "\n",
    "    def encode_token(self, token):\n",
    "        return self.caption_dict[token] if token in self.caption_dict else \\\n",
    "            self.caption_dict[self.UNK]\n",
    "\n",
    "    def decode_caption(self, indices):\n",
    "        return [self.inv_caption_dict[index] for index in indices]\n",
    "\n",
    "    def pad_with_end(self, encoded_caption):\n",
    "        num_end = self.maxlen - len(encoded_caption)\n",
    "        return encoded_caption + num_end * [self.caption_dict[self.END]]\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return len(self.caption_dict)\n",
    "\n",
    "    def get_string(self, predictions):\n",
    "        output_tokens = self.decode_caption(predictions)\n",
    "        if self.END in output_tokens:\n",
    "            end_index = output_tokens.index(self.END)\n",
    "        else:\n",
    "            end_index = len(predictions)\n",
    "        return \" \".join(output_tokens[:end_index]).upper()\n",
    "\n",
    "    def set_maxlen(self, maxlen):\n",
    "        assert maxlen >= 1\n",
    "        if self.maxlen is None:\n",
    "            self.maxlen = maxlen\n",
    "        else:\n",
    "            self.maxlen = np.min([self.maxlen, maxlen])\n",
    "\n",
    "    def load_dictionaries(self, path):\n",
    "        with open(os.path.join(path, \"tokenizer_dicts\"), \"rb\") as f:\n",
    "            (self.maxlen, self.caption_dict,\n",
    "             self.inv_caption_dict) = pickle.load(f)\n",
    "\n",
    "    def save_dictionaries(self, path):\n",
    "        with open(os.path.join(path, \"tokenizer_dicts\"), \"wb\") as f:\n",
    "            pickle.dump((self.maxlen, self.caption_dict,\n",
    "                         self.inv_caption_dict), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SequenceCrossEntropy(nn.Module):\n",
    "\n",
    "    def __init__(self, loss=nn.NLLLoss):\n",
    "        super(SequenceCrossEntropy, self).__init__()\n",
    "        self.loss_function = loss()\n",
    "\n",
    "    def forward(self, preds, target):\n",
    "        batch_size, num_step, _ = preds.size()\n",
    "        loss = 0.\n",
    "        for t in range(num_step):\n",
    "            loss += self.loss_function(preds[:, t], target[:, t])\n",
    "        return loss / (batch_size*num_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annot = open_annotation('/data/20bn-somethingsomething/json/train_20171102.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_templates = sorted(set(list(annot.template)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building dictionary for captions...\n",
      "Number of different tokens:  232\n",
      "{'STICK': 179, '<UNK>': 2, 'WET': 222, 'ON': 109, 'NEXT': 103, 'ALMOST': 8, 'DOWNWARDS': 53, 'SEPARATES': 148, 'MAKING': 97, 'UNFOLDING': 215, 'GETS': 75, 'UPRIGHT': 218, 'BUT': 30, 'SQUEEZING': 173, 'GLIDE': 76, 'AS': 15, 'PUT': 135, 'ROLL': 143, 'TABLE': 188, 'SHADOW': 149, 'NUMBER': 106, 'SLANTED': 154, 'SPILLING': 164, '<END>': 1, 'FALLING': 65, 'FOR': 72, 'BECAUSE': 21, 'AIR': 7, 'TILTING': 200, 'FAILING': 63, 'ONTO': 111, 'SLIDE': 155, 'APPROACHING': 12, 'HOLE': 82, 'QUICKLY': 137, 'PASS': 121, 'ONE': 110, 'SUPPORTED': 185, 'TWO': 211, 'IS': 86, 'TO': 202, 'PRETENDING': 132, 'ARE': 13, 'OPENING': 113, 'FEATHER': 67, 'THROWING': 199, 'UPWARDS': 220, 'ATTACH': 16, 'PILING': 126, 'COLLAPSING': 39, 'DIGGING': 49, 'NOTHING': 105, 'WITHOUT': 228, 'COMPLETELY': 44, 'THEY': 196, 'MANY': 98, 'COME': 42, 'SPRINKLING': 171, 'ENDS': 61, 'PHOTO': 122, 'PAPER': 119, 'SHOW': 150, 'PICK': 123, 'OPEN': 112, 'JUST': 89, 'ALONG': 9, 'WATER': 221, 'SURE': 186, 'MOVING': 102, 'REMOVING': 139, 'WIPE': 225, 'SOMEWHERE': 163, 'TOP': 203, 'ELSE': 58, 'DEFORMS': 48, 'THEN': 195, 'COVERING': 46, 'PICKING': 124, 'BENDING': 25, 'LAYING': 90, 'EDGE': 57, 'THE': 194, 'DOWN': 52, 'UNDERNEATH': 214, 'ITS': 88, 'BEND': 24, 'IT': 87, 'ROLLS': 145, 'FROM': 73, 'CANT': 33, 'HOLDING': 81, 'SUPPORT': 184, 'SQUEEZE': 172, 'SIDE': 152, 'SOMETHING': 162, 'SIMILAR': 153, 'SPREADING': 169, 'ROCK': 142, 'LEFT': 91, 'THROW': 198, 'LIGHTLY': 94, 'PUTTING': 136, 'WHILE': 224, 'ENOUGH': 62, 'EACH': 56, 'YOUR': 231, 'STACKING': 175, 'SPRINKLE': 170, 'SLIGHTLY': 158, 'STACK': 174, 'SUBSTANCE': 183, 'RIGHT': 141, 'CATCHING': 34, 'OF': 107, 'WITH': 227, 'PULLING': 133, 'WIPING': 226, 'BEING': 23, 'TRYING': 206, 'BEHIND': 22, 'FIT': 69, 'LIFTING': 93, 'ALREADY': 10, 'POKE': 128, 'PIECES': 125, 'TAKE': 189, 'BE': 20, 'ACTUALLY': 5, 'AGAINST': 6, 'INSIDE': 84, 'CANNOT': 32, 'SO': 159, 'PUSHING': 134, 'DOES': 50, 'HAND': 78, 'TURN': 207, 'HALT': 77, 'CONTINUES': 45, 'DOESNT': 51, 'STOPS': 180, 'END': 60, 'TOWARDS': 205, 'PLUGGING': 127, 'SCOOP': 146, 'STRETCHED': 181, 'COLLAPSES': 38, 'CAMERA': 31, 'HITTING': 80, 'INTO': 85, 'A': 3, '<GO>': 0, 'DROP': 54, 'OFF': 108, 'UP': 217, 'ACROSS': 4, 'SOME': 161, 'DEFLECTED': 47, 'SCOOPING': 147, 'TWIST': 209, 'SLIDES': 156, 'LITTLE': 96, 'EMPTY': 59, 'FALL': 64, 'BURYING': 29, 'PART': 120, 'STAND': 176, 'STAYS': 178, 'TWISTING': 210, 'STARTS': 177, 'WHERE': 223, 'SLIDING': 157, 'THINGS': 197, 'DROPPING': 55, 'TEARABLE': 191, 'REVEALING': 140, 'SURFACE': 187, 'THAT': 193, 'MISSING': 99, 'TEARING': 192, 'BOTH': 27, 'UNCOVERING': 213, 'MOVES': 101, 'TAKING': 190, 'SPREAD': 168, 'BREAKS': 28, 'OUT': 116, 'AROUND': 14, 'SOFT': 160, 'POURING': 131, 'AND': 11, 'ROLLING': 144, 'OR': 114, 'FILMING': 68, 'STUFFING': 182, 'SHOWING': 151, 'CLOSER': 36, 'CLOSE': 35, 'COLLIDING': 41, 'FRONT': 74, 'UPSIDE': 219, 'OVERFLOWS': 118, 'SPINS': 167, 'CLOSING': 37, 'YOU': 230, 'SPILLS': 165, 'WRINGING': 229, 'ATTACHING': 17, 'IN': 83, 'TURNING': 208, 'NOT': 104, 'COMES': 43, 'HAPPENS': 79, 'AWAY': 18, 'OTHER': 115, 'SPINNING': 166, 'LETTING': 92, 'FALLS': 66, 'UNTIL': 216, 'POUR': 130, 'LIKE': 95, 'POKING': 129, 'MOVE': 100, 'FOLDING': 71, 'TOUCHING': 204, 'BIT': 26, 'OVER': 117, 'COLLIDE': 40, 'UNBENDABLE': 212, 'TIPPING': 201, 'BACK': 19, 'REMOVE': 138, 'FLAT': 70}\n",
      "{0: '<GO>', 1: '<END>', 2: '<UNK>', 3: 'A', 4: 'ACROSS', 5: 'ACTUALLY', 6: 'AGAINST', 7: 'AIR', 8: 'ALMOST', 9: 'ALONG', 10: 'ALREADY', 11: 'AND', 12: 'APPROACHING', 13: 'ARE', 14: 'AROUND', 15: 'AS', 16: 'ATTACH', 17: 'ATTACHING', 18: 'AWAY', 19: 'BACK', 20: 'BE', 21: 'BECAUSE', 22: 'BEHIND', 23: 'BEING', 24: 'BEND', 25: 'BENDING', 26: 'BIT', 27: 'BOTH', 28: 'BREAKS', 29: 'BURYING', 30: 'BUT', 31: 'CAMERA', 32: 'CANNOT', 33: 'CANT', 34: 'CATCHING', 35: 'CLOSE', 36: 'CLOSER', 37: 'CLOSING', 38: 'COLLAPSES', 39: 'COLLAPSING', 40: 'COLLIDE', 41: 'COLLIDING', 42: 'COME', 43: 'COMES', 44: 'COMPLETELY', 45: 'CONTINUES', 46: 'COVERING', 47: 'DEFLECTED', 48: 'DEFORMS', 49: 'DIGGING', 50: 'DOES', 51: 'DOESNT', 52: 'DOWN', 53: 'DOWNWARDS', 54: 'DROP', 55: 'DROPPING', 56: 'EACH', 57: 'EDGE', 58: 'ELSE', 59: 'EMPTY', 60: 'END', 61: 'ENDS', 62: 'ENOUGH', 63: 'FAILING', 64: 'FALL', 65: 'FALLING', 66: 'FALLS', 67: 'FEATHER', 68: 'FILMING', 69: 'FIT', 70: 'FLAT', 71: 'FOLDING', 72: 'FOR', 73: 'FROM', 74: 'FRONT', 75: 'GETS', 76: 'GLIDE', 77: 'HALT', 78: 'HAND', 79: 'HAPPENS', 80: 'HITTING', 81: 'HOLDING', 82: 'HOLE', 83: 'IN', 84: 'INSIDE', 85: 'INTO', 86: 'IS', 87: 'IT', 88: 'ITS', 89: 'JUST', 90: 'LAYING', 91: 'LEFT', 92: 'LETTING', 93: 'LIFTING', 94: 'LIGHTLY', 95: 'LIKE', 96: 'LITTLE', 97: 'MAKING', 98: 'MANY', 99: 'MISSING', 100: 'MOVE', 101: 'MOVES', 102: 'MOVING', 103: 'NEXT', 104: 'NOT', 105: 'NOTHING', 106: 'NUMBER', 107: 'OF', 108: 'OFF', 109: 'ON', 110: 'ONE', 111: 'ONTO', 112: 'OPEN', 113: 'OPENING', 114: 'OR', 115: 'OTHER', 116: 'OUT', 117: 'OVER', 118: 'OVERFLOWS', 119: 'PAPER', 120: 'PART', 121: 'PASS', 122: 'PHOTO', 123: 'PICK', 124: 'PICKING', 125: 'PIECES', 126: 'PILING', 127: 'PLUGGING', 128: 'POKE', 129: 'POKING', 130: 'POUR', 131: 'POURING', 132: 'PRETENDING', 133: 'PULLING', 134: 'PUSHING', 135: 'PUT', 136: 'PUTTING', 137: 'QUICKLY', 138: 'REMOVE', 139: 'REMOVING', 140: 'REVEALING', 141: 'RIGHT', 142: 'ROCK', 143: 'ROLL', 144: 'ROLLING', 145: 'ROLLS', 146: 'SCOOP', 147: 'SCOOPING', 148: 'SEPARATES', 149: 'SHADOW', 150: 'SHOW', 151: 'SHOWING', 152: 'SIDE', 153: 'SIMILAR', 154: 'SLANTED', 155: 'SLIDE', 156: 'SLIDES', 157: 'SLIDING', 158: 'SLIGHTLY', 159: 'SO', 160: 'SOFT', 161: 'SOME', 162: 'SOMETHING', 163: 'SOMEWHERE', 164: 'SPILLING', 165: 'SPILLS', 166: 'SPINNING', 167: 'SPINS', 168: 'SPREAD', 169: 'SPREADING', 170: 'SPRINKLE', 171: 'SPRINKLING', 172: 'SQUEEZE', 173: 'SQUEEZING', 174: 'STACK', 175: 'STACKING', 176: 'STAND', 177: 'STARTS', 178: 'STAYS', 179: 'STICK', 180: 'STOPS', 181: 'STRETCHED', 182: 'STUFFING', 183: 'SUBSTANCE', 184: 'SUPPORT', 185: 'SUPPORTED', 186: 'SURE', 187: 'SURFACE', 188: 'TABLE', 189: 'TAKE', 190: 'TAKING', 191: 'TEARABLE', 192: 'TEARING', 193: 'THAT', 194: 'THE', 195: 'THEN', 196: 'THEY', 197: 'THINGS', 198: 'THROW', 199: 'THROWING', 200: 'TILTING', 201: 'TIPPING', 202: 'TO', 203: 'TOP', 204: 'TOUCHING', 205: 'TOWARDS', 206: 'TRYING', 207: 'TURN', 208: 'TURNING', 209: 'TWIST', 210: 'TWISTING', 211: 'TWO', 212: 'UNBENDABLE', 213: 'UNCOVERING', 214: 'UNDERNEATH', 215: 'UNFOLDING', 216: 'UNTIL', 217: 'UP', 218: 'UPRIGHT', 219: 'UPSIDE', 220: 'UPWARDS', 221: 'WATER', 222: 'WET', 223: 'WHERE', 224: 'WHILE', 225: 'WIPE', 226: 'WIPING', 227: 'WITH', 228: 'WITHOUT', 229: 'WRINGING', 230: 'YOU', 231: 'YOUR'}\n"
     ]
    }
   ],
   "source": [
    "tokenizer.build_dictionaries(unique_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17, 162, 202, 162, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(unique_templates[0])\n",
    "\n",
    "tokenizer.encode_caption(unique_templates[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = LSTMDecoder(256, 100, tokenizer.get_vocab_size(), 1, gpus=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cls = 0\n",
    "\n",
    "caption = tokenizer.encode_caption(unique_templates[cls])\n",
    "caption = torch.from_numpy(np.array(caption)[None]).long()\n",
    "\n",
    "features = cls * torch.ones((1, 1)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caption = Variable(caption)\n",
    "features = Variable(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pred = net.forward(features, caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = SequenceCrossEntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 18])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l = loss(pred, caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = LSTMDecoder(256, 50, tokenizer.get_vocab_size(), 1, gpus=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = LSTMDecoder2(256, 178, tokenizer.get_vocab_size(), 1, gpus=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get inputs\n",
    "batch_caption = []\n",
    "batch_features = []\n",
    "\n",
    "for cls, template in enumerate(unique_templates):\n",
    "    caption = tokenizer.encode_caption(template)\n",
    "    caption = torch.from_numpy(np.array(caption)).long()\n",
    "        \n",
    "    one_hot = np.zeros(178, 'float32')\n",
    "    one_hot[cls] = 1.\n",
    "    features = torch.from_numpy(one_hot)\n",
    "    # cls * torch.ones((1)).long()\n",
    "    \n",
    "    batch_caption.append(caption)\n",
    "    batch_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_caption = torch.stack(batch_caption, dim=0)\n",
    "batch_features = torch.stack(batch_features, dim=0)\n",
    "\n",
    "# Convert to variable\n",
    "batch_caption = Variable(batch_caption)\n",
    "batch_features = Variable(batch_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net2 = net2.cuda()\n",
    "loss = loss.cuda()\n",
    "\n",
    "optimizer = Adam(net2.parameters(), lr=0.001)\n",
    "\n",
    "batch_caption = batch_caption.cuda().long()\n",
    "batch_features = batch_features.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def token_level_accuracy(captions, predictions, num_tokens=None):\n",
    "    equal_values = captions[:, 0:num_tokens].eq(\n",
    "        predictions[:, 0:num_tokens])\n",
    "    accuracy = equal_values.float().mean().data.numpy()[0] * 100.0\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "   12   162   227  ...      1     1     1\n",
       "   17   162   202  ...      1     1     1\n",
       "   25   162   159  ...      1     1     1\n",
       "       ...          â‹±          ...       \n",
       "  162    41   227  ...      1     1     1\n",
       "  162    65    95  ...      1     1     1\n",
       "  162    65    95  ...      1     1     1\n",
       "[torch.cuda.LongTensor of size 178x18 (GPU 0)]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 0 - Loss = 0.00039788338472135365 - Acc = 99.25093650817871\n",
      "****************************************************************************************************\n",
      "Valid epoch 0 - Loss = 0.0022917857859283686 - Acc = 99.25093650817871\n",
      "****************************************************************************************************\n",
      "Train epoch 1 - Loss = 0.00039605548954568803 - Acc = 99.25093650817871\n",
      "Train epoch 2 - Loss = 0.0003942335315514356 - Acc = 99.25093650817871\n",
      "Train epoch 3 - Loss = 0.0003924175980500877 - Acc = 99.25093650817871\n",
      "Train epoch 4 - Loss = 0.0003906078345607966 - Acc = 99.25093650817871\n",
      "Train epoch 5 - Loss = 0.00038880392094142735 - Acc = 99.25093650817871\n",
      "****************************************************************************************************\n",
      "Valid epoch 5 - Loss = 0.0022651341278105974 - Acc = 99.25093650817871\n",
      "****************************************************************************************************\n",
      "Train epoch 6 - Loss = 0.00038700614823028445 - Acc = 99.25093650817871\n",
      "Train epoch 7 - Loss = 0.0003852144000120461 - Acc = 99.25093650817871\n",
      "Train epoch 8 - Loss = 0.00038342890911735594 - Acc = 99.25093650817871\n",
      "Train epoch 9 - Loss = 0.0003816494136117399 - Acc = 99.25093650817871\n",
      "Train epoch 10 - Loss = 0.0003798760299105197 - Acc = 99.25093650817871\n",
      "****************************************************************************************************\n",
      "Valid epoch 10 - Loss = 0.0022592719178646803 - Acc = 99.25093650817871\n",
      "****************************************************************************************************\n",
      "Train epoch 11 - Loss = 0.0003781085251830518 - Acc = 99.25093650817871\n",
      "Train epoch 12 - Loss = 0.00037634785985574126 - Acc = 99.25093650817871\n",
      "Train epoch 13 - Loss = 0.00037459333543665707 - Acc = 99.25093650817871\n",
      "Train epoch 14 - Loss = 0.00037284515565261245 - Acc = 99.25093650817871\n",
      "Train epoch 15 - Loss = 0.00037110349512659013 - Acc = 99.25093650817871\n",
      "****************************************************************************************************\n",
      "Valid epoch 15 - Loss = 0.0022535426542162895 - Acc = 99.25093650817871\n",
      "****************************************************************************************************\n",
      "Train epoch 16 - Loss = 0.00036936800461262465 - Acc = 99.25093650817871\n",
      "Train epoch 17 - Loss = 0.00036763862590305507 - Acc = 99.25093650817871\n",
      "Train epoch 18 - Loss = 0.0003659157082438469 - Acc = 99.25093650817871\n",
      "Train epoch 19 - Loss = 0.0003641988441813737 - Acc = 99.25093650817871\n",
      "Train epoch 20 - Loss = 0.0003624885866884142 - Acc = 99.25093650817871\n",
      "****************************************************************************************************\n",
      "Valid epoch 20 - Loss = 0.002254014601930976 - Acc = 99.25093650817871\n",
      "****************************************************************************************************\n",
      "Train epoch 21 - Loss = 0.0003607844118960202 - Acc = 99.25093650817871\n",
      "Train epoch 22 - Loss = 0.00035908634890802205 - Acc = 99.25093650817871\n",
      "Train epoch 23 - Loss = 0.00035739460145123303 - Acc = 99.25093650817871\n",
      "Train epoch 24 - Loss = 0.0003557091986294836 - Acc = 99.34456944465637\n",
      "Train epoch 25 - Loss = 0.0003540298785082996 - Acc = 99.34456944465637\n",
      "****************************************************************************************************\n",
      "Valid epoch 25 - Loss = 0.0021344725973904133 - Acc = 99.34456944465637\n",
      "****************************************************************************************************\n",
      "Train epoch 26 - Loss = 0.0003523567575030029 - Acc = 99.34456944465637\n",
      "Train epoch 27 - Loss = 0.00035068998113274574 - Acc = 99.43820238113403\n",
      "Train epoch 28 - Loss = 0.0003490292001515627 - Acc = 99.43820238113403\n",
      "Train epoch 29 - Loss = 0.00034737473470158875 - Acc = 99.43820238113403\n",
      "Train epoch 30 - Loss = 0.0003457256534602493 - Acc = 99.43820238113403\n",
      "****************************************************************************************************\n",
      "Valid epoch 30 - Loss = 0.001925174961797893 - Acc = 99.43820238113403\n",
      "****************************************************************************************************\n",
      "Train epoch 31 - Loss = 0.00034408317878842354 - Acc = 99.43820238113403\n",
      "Train epoch 32 - Loss = 0.00034244716516695917 - Acc = 99.43820238113403\n",
      "Train epoch 33 - Loss = 0.0003408171469345689 - Acc = 99.43820238113403\n",
      "Train epoch 34 - Loss = 0.0003391936479602009 - Acc = 99.43820238113403\n",
      "Train epoch 35 - Loss = 0.00033757605706341565 - Acc = 99.43820238113403\n",
      "****************************************************************************************************\n",
      "Valid epoch 35 - Loss = 0.001992100151255727 - Acc = 99.43820238113403\n",
      "****************************************************************************************************\n",
      "Train epoch 36 - Loss = 0.00033596469438634813 - Acc = 99.43820238113403\n",
      "Train epoch 37 - Loss = 0.0003343595308251679 - Acc = 99.43820238113403\n",
      "Train epoch 38 - Loss = 0.00033276036265306175 - Acc = 99.43820238113403\n",
      "Train epoch 39 - Loss = 0.0003311675682198256 - Acc = 99.43820238113403\n",
      "Train epoch 40 - Loss = 0.00032958085648715496 - Acc = 99.43820238113403\n",
      "****************************************************************************************************\n",
      "Valid epoch 40 - Loss = 0.0019863059278577566 - Acc = 99.43820238113403\n",
      "****************************************************************************************************\n",
      "Train epoch 41 - Loss = 0.0003280001401435584 - Acc = 99.43820238113403\n",
      "Train epoch 42 - Loss = 0.0003264256229158491 - Acc = 99.43820238113403\n",
      "Train epoch 43 - Loss = 0.00032485718838870525 - Acc = 99.43820238113403\n",
      "Train epoch 44 - Loss = 0.00032329498208127916 - Acc = 99.43820238113403\n",
      "Train epoch 45 - Loss = 0.00032173882937058806 - Acc = 99.5006263256073\n",
      "****************************************************************************************************\n",
      "Valid epoch 45 - Loss = 0.001826890162192285 - Acc = 99.5006263256073\n",
      "****************************************************************************************************\n",
      "Train epoch 46 - Loss = 0.0003201887011528015 - Acc = 99.5006263256073\n",
      "Train epoch 47 - Loss = 0.00031864430638961494 - Acc = 99.56304430961609\n",
      "Train epoch 48 - Loss = 0.00031710605253465474 - Acc = 99.59425926208496\n",
      "Train epoch 49 - Loss = 0.0003155742888338864 - Acc = 99.59425926208496\n",
      "Train epoch 50 - Loss = 0.00031404884066432714 - Acc = 99.59425926208496\n",
      "****************************************************************************************************\n",
      "Valid epoch 50 - Loss = 0.0015496781561523676 - Acc = 99.59425926208496\n",
      "****************************************************************************************************\n",
      "Train epoch 51 - Loss = 0.00031252935878001153 - Acc = 99.59425926208496\n",
      "Train epoch 52 - Loss = 0.00031101610511541367 - Acc = 99.59425926208496\n",
      "Train epoch 53 - Loss = 0.0003095089632552117 - Acc = 99.59425926208496\n",
      "Train epoch 54 - Loss = 0.0003080080496147275 - Acc = 99.59425926208496\n",
      "Train epoch 55 - Loss = 0.0003065131022594869 - Acc = 99.59425926208496\n",
      "****************************************************************************************************\n",
      "Valid epoch 55 - Loss = 0.0015432280488312244 - Acc = 99.59425926208496\n",
      "****************************************************************************************************\n",
      "Train epoch 56 - Loss = 0.0003050242958124727 - Acc = 99.59425926208496\n",
      "Train epoch 57 - Loss = 0.0003035416593775153 - Acc = 99.59425926208496\n",
      "Train epoch 58 - Loss = 0.0003020652220584452 - Acc = 99.59425926208496\n",
      "Train epoch 59 - Loss = 0.0003005946346092969 - Acc = 99.59425926208496\n",
      "Train epoch 60 - Loss = 0.00029913007165305316 - Acc = 99.59425926208496\n",
      "****************************************************************************************************\n",
      "Valid epoch 60 - Loss = 0.0015368591994047165 - Acc = 99.59425926208496\n",
      "****************************************************************************************************\n",
      "Train epoch 61 - Loss = 0.0002976717078126967 - Acc = 99.59425926208496\n",
      "Train epoch 62 - Loss = 0.00029621936846524477 - Acc = 99.59425926208496\n",
      "Train epoch 63 - Loss = 0.0002947729080915451 - Acc = 99.59425926208496\n",
      "Train epoch 64 - Loss = 0.00029333229758776724 - Acc = 99.59425926208496\n",
      "Train epoch 65 - Loss = 0.00029189750785008073 - Acc = 99.59425926208496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Valid epoch 65 - Loss = 0.001530561363324523 - Acc = 99.59425926208496\n",
      "****************************************************************************************************\n",
      "Train epoch 66 - Loss = 0.0002904685970861465 - Acc = 99.59425926208496\n",
      "Train epoch 67 - Loss = 0.0002890459727495909 - Acc = 99.59425926208496\n",
      "Train epoch 68 - Loss = 0.00028762928559444845 - Acc = 99.59425926208496\n",
      "Train epoch 69 - Loss = 0.00028621856472454965 - Acc = 99.59425926208496\n",
      "Train epoch 70 - Loss = 0.00028481357730925083 - Acc = 99.59425926208496\n",
      "****************************************************************************************************\n",
      "Valid epoch 70 - Loss = 0.0015243350062519312 - Acc = 99.59425926208496\n",
      "****************************************************************************************************\n",
      "Train epoch 71 - Loss = 0.00028341446886770427 - Acc = 99.59425926208496\n",
      "Train epoch 72 - Loss = 0.0002820211520884186 - Acc = 99.59425926208496\n",
      "Train epoch 73 - Loss = 0.00028063374338671565 - Acc = 99.59425926208496\n",
      "Train epoch 74 - Loss = 0.0002792518644127995 - Acc = 99.59425926208496\n",
      "Train epoch 75 - Loss = 0.000277875893516466 - Acc = 99.59425926208496\n",
      "****************************************************************************************************\n",
      "Valid epoch 75 - Loss = 0.0015182021306827664 - Acc = 99.59425926208496\n",
      "****************************************************************************************************\n",
      "Train epoch 76 - Loss = 0.0002765055396594107 - Acc = 99.59425926208496\n",
      "Train epoch 77 - Loss = 0.00027514074463397264 - Acc = 99.59425926208496\n",
      "Train epoch 78 - Loss = 0.0002737815084401518 - Acc = 99.62546825408936\n",
      "Train epoch 79 - Loss = 0.0002724282385315746 - Acc = 99.62546825408936\n",
      "Train epoch 80 - Loss = 0.00027108044014312327 - Acc = 99.62546825408936\n",
      "****************************************************************************************************\n",
      "Valid epoch 80 - Loss = 0.0013846073998138309 - Acc = 99.62546825408936\n",
      "****************************************************************************************************\n",
      "Train epoch 81 - Loss = 0.00026973820058628917 - Acc = 99.62546825408936\n",
      "Train epoch 82 - Loss = 0.00026840163627639413 - Acc = 99.62546825408936\n",
      "Train epoch 83 - Loss = 0.0002670705725904554 - Acc = 99.62546825408936\n",
      "Train epoch 84 - Loss = 0.00026574506773613393 - Acc = 99.62546825408936\n",
      "Train epoch 85 - Loss = 0.0002644249761942774 - Acc = 99.62546825408936\n",
      "****************************************************************************************************\n",
      "Valid epoch 85 - Loss = 0.0013788130600005388 - Acc = 99.62546825408936\n",
      "****************************************************************************************************\n",
      "Train epoch 86 - Loss = 0.00026311029796488583 - Acc = 99.62546825408936\n",
      "Train epoch 87 - Loss = 0.00026180068380199373 - Acc = 99.62546825408936\n",
      "Train epoch 88 - Loss = 0.00026049718144349754 - Acc = 99.62546825408936\n",
      "Train epoch 89 - Loss = 0.00025919900508597493 - Acc = 99.62546825408936\n",
      "Train epoch 90 - Loss = 0.0002579064457677305 - Acc = 99.62546825408936\n",
      "****************************************************************************************************\n",
      "Valid epoch 90 - Loss = 0.0013731453800573945 - Acc = 99.62546825408936\n",
      "****************************************************************************************************\n",
      "Train epoch 91 - Loss = 0.0002566193579696119 - Acc = 99.62546825408936\n",
      "Train epoch 92 - Loss = 0.00025533774169161916 - Acc = 99.62546825408936\n",
      "Train epoch 93 - Loss = 0.0002540616551414132 - Acc = 99.62546825408936\n",
      "Train epoch 94 - Loss = 0.00025279104011133313 - Acc = 99.62546825408936\n",
      "Train epoch 95 - Loss = 0.00025152601301670074 - Acc = 99.62546825408936\n",
      "****************************************************************************************************\n",
      "Valid epoch 95 - Loss = 0.0013932184083387256 - Acc = 99.62546825408936\n",
      "****************************************************************************************************\n",
      "Train epoch 96 - Loss = 0.0002502659917809069 - Acc = 99.62546825408936\n",
      "Train epoch 97 - Loss = 0.0002490118204150349 - Acc = 99.62546825408936\n",
      "Train epoch 98 - Loss = 0.0002477632078807801 - Acc = 99.65667724609375\n",
      "Train epoch 99 - Loss = 0.0002465200377628207 - Acc = 99.65667724609375\n",
      "Train epoch 100 - Loss = 0.00024528257199563086 - Acc = 99.65667724609375\n",
      "****************************************************************************************************\n",
      "Valid epoch 100 - Loss = 0.001303314114920795 - Acc = 99.65667724609375\n",
      "****************************************************************************************************\n",
      "Train epoch 101 - Loss = 0.00024405041767749935 - Acc = 99.65667724609375\n",
      "Train epoch 102 - Loss = 0.000242823371081613 - Acc = 99.65667724609375\n",
      "Train epoch 103 - Loss = 0.0002416024508420378 - Acc = 99.65667724609375\n",
      "Train epoch 104 - Loss = 0.0002403870312264189 - Acc = 99.68789219856262\n",
      "Train epoch 105 - Loss = 0.00023917722865007818 - Acc = 99.68789219856262\n",
      "****************************************************************************************************\n",
      "Valid epoch 105 - Loss = 0.0011490358738228679 - Acc = 99.68789219856262\n",
      "****************************************************************************************************\n",
      "Train epoch 106 - Loss = 0.0002379731013206765 - Acc = 99.71910119056702\n",
      "Train epoch 107 - Loss = 0.00023677457647863775 - Acc = 99.71910119056702\n",
      "Train epoch 108 - Loss = 0.00023558136308565736 - Acc = 99.75031018257141\n",
      "Train epoch 109 - Loss = 0.0002343938685953617 - Acc = 99.75031018257141\n",
      "Train epoch 110 - Loss = 0.00023321216576732695 - Acc = 99.75031018257141\n",
      "****************************************************************************************************\n",
      "Valid epoch 110 - Loss = 0.0010365217458456755 - Acc = 99.75031018257141\n",
      "****************************************************************************************************\n",
      "Train epoch 111 - Loss = 0.0002320361090824008 - Acc = 99.75031018257141\n",
      "Train epoch 112 - Loss = 0.00023086564033292234 - Acc = 99.75031018257141\n",
      "Train epoch 113 - Loss = 0.00022970081772655249 - Acc = 99.75031018257141\n",
      "Train epoch 114 - Loss = 0.00022854158305563033 - Acc = 99.78152513504028\n",
      "Train epoch 115 - Loss = 0.00022738814004696906 - Acc = 99.78152513504028\n",
      "****************************************************************************************************\n",
      "Valid epoch 115 - Loss = 0.000978483003564179 - Acc = 99.78152513504028\n",
      "****************************************************************************************************\n",
      "Train epoch 116 - Loss = 0.00022624035773333162 - Acc = 99.78152513504028\n",
      "Train epoch 117 - Loss = 0.00022509810514748096 - Acc = 99.78152513504028\n",
      "Train epoch 118 - Loss = 0.00022396167332772166 - Acc = 99.78152513504028\n",
      "Train epoch 119 - Loss = 0.0002228307566838339 - Acc = 99.78152513504028\n",
      "Train epoch 120 - Loss = 0.00022170550073496997 - Acc = 99.78152513504028\n",
      "****************************************************************************************************\n",
      "Valid epoch 120 - Loss = 0.0009732847684063017 - Acc = 99.78152513504028\n",
      "****************************************************************************************************\n",
      "Train epoch 121 - Loss = 0.00022058589092921466 - Acc = 99.78152513504028\n",
      "Train epoch 122 - Loss = 0.00021947192726656795 - Acc = 99.81273412704468\n",
      "Train epoch 123 - Loss = 0.00021836356609128416 - Acc = 99.81273412704468\n",
      "Train epoch 124 - Loss = 0.00021726074919570237 - Acc = 99.81273412704468\n",
      "Train epoch 125 - Loss = 0.00021616336016450077 - Acc = 99.81273412704468\n",
      "****************************************************************************************************\n",
      "Valid epoch 125 - Loss = 0.0007364705670624971 - Acc = 99.81273412704468\n",
      "****************************************************************************************************\n",
      "Train epoch 126 - Loss = 0.00021507134079001844 - Acc = 99.81273412704468\n",
      "Train epoch 127 - Loss = 0.00021398456010501832 - Acc = 99.81273412704468\n",
      "Train epoch 128 - Loss = 0.00021290345466695726 - Acc = 99.81273412704468\n",
      "Train epoch 129 - Loss = 0.00021182796626817435 - Acc = 99.81273412704468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 130 - Loss = 0.00021075787662994117 - Acc = 99.81273412704468\n",
      "****************************************************************************************************\n",
      "Valid epoch 130 - Loss = 0.0006970902322791517 - Acc = 99.81273412704468\n",
      "****************************************************************************************************\n",
      "Train epoch 131 - Loss = 0.00020969321485608816 - Acc = 99.84394311904907\n",
      "Train epoch 132 - Loss = 0.00020863373356405646 - Acc = 99.84394311904907\n",
      "Train epoch 133 - Loss = 0.00020757952006533742 - Acc = 99.84394311904907\n",
      "Train epoch 134 - Loss = 0.00020653055980801582 - Acc = 99.87515807151794\n",
      "Train epoch 135 - Loss = 0.00020548691099975258 - Acc = 99.87515807151794\n",
      "****************************************************************************************************\n",
      "Valid epoch 135 - Loss = 0.0004896358586847782 - Acc = 99.87515807151794\n",
      "****************************************************************************************************\n",
      "Train epoch 136 - Loss = 0.00020444829715415835 - Acc = 99.87515807151794\n",
      "Train epoch 137 - Loss = 0.00020341492199804634 - Acc = 99.87515807151794\n",
      "Train epoch 138 - Loss = 0.00020238665456417948 - Acc = 99.87515807151794\n",
      "Train epoch 139 - Loss = 0.00020136353850830346 - Acc = 99.87515807151794\n",
      "Train epoch 140 - Loss = 0.00020034554472658783 - Acc = 99.87515807151794\n",
      "****************************************************************************************************\n",
      "Valid epoch 140 - Loss = 0.0004847166419494897 - Acc = 99.87515807151794\n",
      "****************************************************************************************************\n",
      "Train epoch 141 - Loss = 0.00019933251314796507 - Acc = 99.87515807151794\n",
      "Train epoch 142 - Loss = 0.00019832445832435042 - Acc = 99.87515807151794\n",
      "Train epoch 143 - Loss = 0.00019732148211915046 - Acc = 99.87515807151794\n",
      "Train epoch 144 - Loss = 0.00019632346811704338 - Acc = 99.87515807151794\n",
      "Train epoch 145 - Loss = 0.0001953302271431312 - Acc = 99.87515807151794\n",
      "****************************************************************************************************\n",
      "Valid epoch 145 - Loss = 0.0004799137532245368 - Acc = 99.87515807151794\n",
      "****************************************************************************************************\n",
      "Train epoch 146 - Loss = 0.0001943413371918723 - Acc = 99.87515807151794\n",
      "Train epoch 147 - Loss = 0.00019335820979904383 - Acc = 99.87515807151794\n",
      "Train epoch 148 - Loss = 0.00019237979722674936 - Acc = 99.87515807151794\n",
      "Train epoch 149 - Loss = 0.00019140649237670004 - Acc = 99.87515807151794\n",
      "Train epoch 150 - Loss = 0.00019043793145101517 - Acc = 99.87515807151794\n",
      "****************************************************************************************************\n",
      "Valid epoch 150 - Loss = 0.00047521988744847476 - Acc = 99.87515807151794\n",
      "****************************************************************************************************\n",
      "Train epoch 151 - Loss = 0.0001894741435535252 - Acc = 99.87515807151794\n",
      "Train epoch 152 - Loss = 0.00018851521599572152 - Acc = 99.87515807151794\n",
      "Train epoch 153 - Loss = 0.00018756110512185842 - Acc = 99.87515807151794\n",
      "Train epoch 154 - Loss = 0.00018661167996469885 - Acc = 99.87515807151794\n",
      "Train epoch 155 - Loss = 0.00018566696962807328 - Acc = 99.87515807151794\n",
      "****************************************************************************************************\n",
      "Valid epoch 155 - Loss = 0.00047062450903467834 - Acc = 99.87515807151794\n",
      "****************************************************************************************************\n",
      "Train epoch 156 - Loss = 0.0001847270323196426 - Acc = 99.87515807151794\n",
      "Train epoch 157 - Loss = 0.00018379166431259364 - Acc = 99.87515807151794\n",
      "Train epoch 158 - Loss = 0.00018286099657416344 - Acc = 99.87515807151794\n",
      "Train epoch 159 - Loss = 0.00018193501455243677 - Acc = 99.87515807151794\n",
      "Train epoch 160 - Loss = 0.00018101368914358318 - Acc = 99.87515807151794\n",
      "****************************************************************************************************\n",
      "Valid epoch 160 - Loss = 0.0004661193524952978 - Acc = 99.87515807151794\n",
      "****************************************************************************************************\n",
      "Train epoch 161 - Loss = 0.0001800969330361113 - Acc = 99.87515807151794\n",
      "Train epoch 162 - Loss = 0.0001791847898857668 - Acc = 99.87515807151794\n",
      "Train epoch 163 - Loss = 0.00017827712872531265 - Acc = 99.87515807151794\n",
      "Train epoch 164 - Loss = 0.00017737386224325746 - Acc = 99.87515807151794\n",
      "Train epoch 165 - Loss = 0.0001764753833413124 - Acc = 99.87515807151794\n",
      "****************************************************************************************************\n",
      "Valid epoch 165 - Loss = 0.000461704155895859 - Acc = 99.87515807151794\n",
      "****************************************************************************************************\n",
      "Train epoch 166 - Loss = 0.00017558166291564703 - Acc = 99.87515807151794\n",
      "Train epoch 167 - Loss = 0.0001746923808241263 - Acc = 99.87515807151794\n",
      "Train epoch 168 - Loss = 0.00017380763893015683 - Acc = 99.90636706352234\n",
      "Train epoch 169 - Loss = 0.0001729274372337386 - Acc = 99.90636706352234\n",
      "Train epoch 170 - Loss = 0.00017205174663104117 - Acc = 99.90636706352234\n",
      "****************************************************************************************************\n",
      "Valid epoch 170 - Loss = 0.00039260275661945343 - Acc = 99.90636706352234\n",
      "****************************************************************************************************\n",
      "Train epoch 171 - Loss = 0.000171180086908862 - Acc = 99.90636706352234\n",
      "Train epoch 172 - Loss = 0.0001703134912531823 - Acc = 99.90636706352234\n",
      "Train epoch 173 - Loss = 0.0001694514212431386 - Acc = 99.90636706352234\n",
      "Train epoch 174 - Loss = 0.00016859396419022232 - Acc = 99.93757605552673\n",
      "Train epoch 175 - Loss = 0.000167740901815705 - Acc = 99.93757605552673\n",
      "****************************************************************************************************\n",
      "Valid epoch 175 - Loss = 0.0002884266141336411 - Acc = 99.93757605552673\n",
      "****************************************************************************************************\n",
      "Train epoch 176 - Loss = 0.00016689243784639984 - Acc = 99.93757605552673\n",
      "Train epoch 177 - Loss = 0.0001660484413150698 - Acc = 99.93757605552673\n",
      "Train epoch 178 - Loss = 0.00016520881035830826 - Acc = 99.93757605552673\n",
      "Train epoch 179 - Loss = 0.0001643736322876066 - Acc = 99.93757605552673\n",
      "Train epoch 180 - Loss = 0.0001635429507587105 - Acc = 99.93757605552673\n",
      "****************************************************************************************************\n",
      "Valid epoch 180 - Loss = 0.0002843746042344719 - Acc = 99.93757605552673\n",
      "****************************************************************************************************\n",
      "Train epoch 181 - Loss = 0.00016271659114863724 - Acc = 99.93757605552673\n",
      "Train epoch 182 - Loss = 0.00016189469897653908 - Acc = 99.93757605552673\n",
      "Train epoch 183 - Loss = 0.0001610771578270942 - Acc = 99.93757605552673\n",
      "Train epoch 184 - Loss = 0.00016026389494072646 - Acc = 99.93757605552673\n",
      "Train epoch 185 - Loss = 0.00015945495397318155 - Acc = 99.93757605552673\n",
      "****************************************************************************************************\n",
      "Valid epoch 185 - Loss = 0.00028042792109772563 - Acc = 99.93757605552673\n",
      "****************************************************************************************************\n",
      "Train epoch 186 - Loss = 0.00015865026216488332 - Acc = 99.93757605552673\n",
      "Train epoch 187 - Loss = 0.00015784974675625563 - Acc = 99.93757605552673\n",
      "Train epoch 188 - Loss = 0.0001570537278894335 - Acc = 99.93757605552673\n",
      "Train epoch 189 - Loss = 0.00015626195818185806 - Acc = 99.93757605552673\n",
      "Train epoch 190 - Loss = 0.00015547436487395316 - Acc = 99.93757605552673\n",
      "****************************************************************************************************\n",
      "Valid epoch 190 - Loss = 0.00027658394537866116 - Acc = 99.93757605552673\n",
      "****************************************************************************************************\n",
      "Train epoch 191 - Loss = 0.00015469107893295586 - Acc = 99.93757605552673\n",
      "Train epoch 192 - Loss = 0.00015391195483971387 - Acc = 99.93757605552673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 193 - Loss = 0.00015313691983465105 - Acc = 99.93757605552673\n",
      "Train epoch 194 - Loss = 0.00015236616309266537 - Acc = 99.93757605552673\n",
      "Train epoch 195 - Loss = 0.00015159934991970658 - Acc = 99.93757605552673\n",
      "****************************************************************************************************\n",
      "Valid epoch 195 - Loss = 0.0002728379622567445 - Acc = 99.93757605552673\n",
      "****************************************************************************************************\n",
      "Train epoch 196 - Loss = 0.00015083637845236808 - Acc = 99.93757605552673\n",
      "Train epoch 197 - Loss = 0.00015007768524810672 - Acc = 99.93757605552673\n",
      "Train epoch 198 - Loss = 0.00014932321209926158 - Acc = 99.93757605552673\n",
      "Train epoch 199 - Loss = 0.00014857282803859562 - Acc = 99.93757605552673\n",
      "Train epoch 200 - Loss = 0.00014782653306610882 - Acc = 99.93757605552673\n",
      "****************************************************************************************************\n",
      "Valid epoch 200 - Loss = 0.0002691871195565909 - Acc = 99.93757605552673\n",
      "****************************************************************************************************\n",
      "Train epoch 201 - Loss = 0.000147084123454988 - Acc = 99.93757605552673\n",
      "Train epoch 202 - Loss = 0.0001463458320358768 - Acc = 99.93757605552673\n",
      "Train epoch 203 - Loss = 0.0001456114841857925 - Acc = 99.93757605552673\n",
      "Train epoch 204 - Loss = 0.00014488105080090463 - Acc = 99.93757605552673\n",
      "Train epoch 205 - Loss = 0.0001441545318812132 - Acc = 99.93757605552673\n",
      "****************************************************************************************************\n",
      "Valid epoch 205 - Loss = 0.00026562914717942476 - Acc = 99.93757605552673\n",
      "****************************************************************************************************\n",
      "Train epoch 206 - Loss = 0.0001434319419786334 - Acc = 99.93757605552673\n",
      "Train epoch 207 - Loss = 0.00014271326654125005 - Acc = 99.93757605552673\n",
      "Train epoch 208 - Loss = 0.00014199837460182607 - Acc = 99.93757605552673\n",
      "Train epoch 209 - Loss = 0.0001412873825756833 - Acc = 99.93757605552673\n",
      "Train epoch 210 - Loss = 0.0001405802322551608 - Acc = 99.93757605552673\n",
      "****************************************************************************************************\n",
      "Valid epoch 210 - Loss = 0.0002621627354528755 - Acc = 99.93757605552673\n",
      "****************************************************************************************************\n",
      "Train epoch 211 - Loss = 0.00013987679267302155 - Acc = 99.93757605552673\n",
      "Train epoch 212 - Loss = 0.00013917718024458736 - Acc = 99.93757605552673\n",
      "Train epoch 213 - Loss = 0.00013848136586602777 - Acc = 99.93757605552673\n",
      "Train epoch 214 - Loss = 0.00013778921857010573 - Acc = 99.93757605552673\n",
      "Train epoch 215 - Loss = 0.00013710079656448215 - Acc = 99.93757605552673\n",
      "****************************************************************************************************\n",
      "Valid epoch 215 - Loss = 0.000258786603808403 - Acc = 99.93757605552673\n",
      "****************************************************************************************************\n",
      "Train epoch 216 - Loss = 0.00013641614350490272 - Acc = 99.93757605552673\n",
      "Train epoch 217 - Loss = 0.00013573517207987607 - Acc = 99.93757605552673\n",
      "Train epoch 218 - Loss = 0.0001350574748357758 - Acc = 99.93757605552673\n",
      "Train epoch 219 - Loss = 0.0001343837648164481 - Acc = 99.93757605552673\n",
      "Train epoch 220 - Loss = 0.00013371372187975794 - Acc = 99.93757605552673\n",
      "****************************************************************************************************\n",
      "Valid epoch 220 - Loss = 0.0002554990351200104 - Acc = 99.93757605552673\n",
      "****************************************************************************************************\n",
      "Train epoch 221 - Loss = 0.00013304738968145102 - Acc = 99.93757605552673\n",
      "Train epoch 222 - Loss = 0.00013238462270237505 - Acc = 99.9687910079956\n",
      "Train epoch 223 - Loss = 0.0001317255082540214 - Acc = 100.0\n",
      "Train epoch 224 - Loss = 0.00013106992992106825 - Acc = 100.0\n",
      "Train epoch 225 - Loss = 0.0001304179459111765 - Acc = 100.0\n",
      "****************************************************************************************************\n",
      "Valid epoch 225 - Loss = 0.00012976949801668525 - Acc = 100.0\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "valid_num = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    net2.zero_grad()\n",
    "    # Forward pass\n",
    "    probs = net2.forward(batch_features, batch_caption, use_teacher_forcing=True)\n",
    "    l = loss(probs, batch_caption)\n",
    "    # Backward\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    # Print\n",
    "    l = l.cpu().data.numpy()[0]\n",
    "    _, preds = torch.max(probs, dim=2)\n",
    "    acc = token_level_accuracy(batch_caption.cpu(), preds.cpu())\n",
    "    print('Train epoch {} - Loss = {} - Acc = {}'.format(epoch, l, acc))\n",
    "    \n",
    "    if epoch % valid_num == 0:\n",
    "        pred = net2.forward(batch_features, batch_caption, use_teacher_forcing=False)\n",
    "        l = loss(pred, batch_caption)    \n",
    "        # Print\n",
    "        l = l.cpu().data.numpy()[0]\n",
    "        _, preds = torch.max(probs, dim=2)\n",
    "        acc = token_level_accuracy(batch_caption.cpu(), preds.cpu())\n",
    "        print('*' * 100)\n",
    "        print('Valid epoch {} - Loss = {} - Acc = {}'.format(epoch, l, acc))\n",
    "        print('*' * 100)\n",
    "        \n",
    "        if acc == 100.:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"/home/farzaneh/PycharmProjects/pretrained_nets/jester_net_on_smtsmt_20171031/model.checkpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('logsoftmax.linear.weight', \n",
       "              -5.9498e+00 -1.6424e-01 -4.5323e+00  ...  -4.1166e-02 -2.7420e+00 -4.3519e+00\n",
       "              -1.0498e+00 -1.2226e-01 -6.0664e+00  ...  -2.9235e-02 -2.8050e-01 -9.1082e-01\n",
       "              -1.5031e+00 -1.6010e-02 -7.6805e+00  ...  -1.7197e-02 -1.0701e+00 -1.5469e+00\n",
       "                              ...                   â‹±                   ...                \n",
       "              -1.2371e+00 -1.6942e-01 -4.2709e+00  ...  -6.0752e-04 -9.3195e-01 -1.6218e+00\n",
       "              -2.7794e+00 -1.6826e-01 -1.7114e+00  ...  -4.4442e-02 -8.1058e-01 -3.2101e-01\n",
       "              -1.6837e+00 -1.9701e-01 -8.8867e-01  ...   2.2288e-03 -1.4974e+00 -6.3800e-01\n",
       "              [torch.cuda.FloatTensor of size 178x1024 (GPU 0)]),\n",
       "             ('logsoftmax.linear.bias', \n",
       "              -0.1786\n",
       "              -0.1345\n",
       "               0.1546\n",
       "               0.1494\n",
       "              -0.0258\n",
       "              -0.2088\n",
       "               0.2472\n",
       "              -0.1185\n",
       "              -0.2913\n",
       "              -0.4243\n",
       "              -0.4247\n",
       "              -0.4224\n",
       "              -0.3594\n",
       "              -0.1742\n",
       "               0.3209\n",
       "               0.3406\n",
       "              -0.1528\n",
       "               0.0181\n",
       "               0.4478\n",
       "               0.1994\n",
       "               0.2223\n",
       "              -0.4985\n",
       "               0.0553\n",
       "              -0.1801\n",
       "               0.1161\n",
       "              -0.5745\n",
       "              -0.4582\n",
       "               0.1958\n",
       "              -0.2360\n",
       "              -0.1063\n",
       "               0.0917\n",
       "              -0.0847\n",
       "              -0.3666\n",
       "              -0.7312\n",
       "              -0.5978\n",
       "              -0.0940\n",
       "               0.0494\n",
       "              -0.5234\n",
       "              -0.6558\n",
       "              -0.5315\n",
       "              -0.5757\n",
       "              -0.5662\n",
       "               0.0249\n",
       "              -0.1992\n",
       "              -0.4076\n",
       "              -0.2975\n",
       "               0.1029\n",
       "              -0.4621\n",
       "              -0.3903\n",
       "               0.5177\n",
       "               0.2989\n",
       "              -0.4703\n",
       "              -0.1621\n",
       "              -0.4172\n",
       "              -0.0767\n",
       "               0.8397\n",
       "               0.0642\n",
       "              -0.0087\n",
       "              -0.3865\n",
       "               0.6469\n",
       "               0.3200\n",
       "               0.2973\n",
       "               0.3967\n",
       "              -0.2920\n",
       "              -0.3093\n",
       "               0.2416\n",
       "              -0.2267\n",
       "              -0.1737\n",
       "              -0.0698\n",
       "              -0.6245\n",
       "               0.3631\n",
       "              -0.2409\n",
       "              -0.1910\n",
       "              -0.4873\n",
       "              -0.2514\n",
       "              -0.3320\n",
       "               0.1040\n",
       "              -0.4193\n",
       "              -0.1971\n",
       "               0.1040\n",
       "              -0.1681\n",
       "              -0.2482\n",
       "              -0.3373\n",
       "               0.0019\n",
       "              -0.0254\n",
       "              -0.1916\n",
       "              -0.3377\n",
       "              -0.6166\n",
       "              -0.6133\n",
       "              -0.6054\n",
       "               0.0337\n",
       "               0.4749\n",
       "               0.1618\n",
       "              -0.0821\n",
       "              -0.2370\n",
       "              -0.8028\n",
       "              -0.5288\n",
       "              -0.0469\n",
       "              -0.1797\n",
       "              -0.1646\n",
       "              -0.2042\n",
       "              -0.1594\n",
       "              -0.8112\n",
       "              -0.2891\n",
       "              -0.1304\n",
       "               0.2019\n",
       "              -0.2296\n",
       "              -0.7835\n",
       "               0.1344\n",
       "              -0.3017\n",
       "              -0.3051\n",
       "              -0.1058\n",
       "              -0.2861\n",
       "              -0.0679\n",
       "              -0.3501\n",
       "              -0.1545\n",
       "              -0.3972\n",
       "              -0.1643\n",
       "              -0.2155\n",
       "              -0.5132\n",
       "               0.0068\n",
       "              -0.5376\n",
       "              -0.4731\n",
       "              -0.0174\n",
       "               1.6348\n",
       "               1.1189\n",
       "               0.3306\n",
       "              -0.1447\n",
       "              -0.1555\n",
       "              -0.0325\n",
       "               0.1024\n",
       "               1.0170\n",
       "               0.5457\n",
       "              -0.0804\n",
       "              -0.3952\n",
       "               0.4017\n",
       "               0.2004\n",
       "               0.2206\n",
       "              -0.2331\n",
       "              -0.0721\n",
       "              -0.1795\n",
       "               0.3307\n",
       "               0.2515\n",
       "              -0.1734\n",
       "              -0.4152\n",
       "               0.0007\n",
       "              -0.4100\n",
       "               0.1585\n",
       "               0.0157\n",
       "               0.1908\n",
       "              -0.0878\n",
       "              -0.3674\n",
       "               0.2769\n",
       "              -0.4857\n",
       "              -0.3048\n",
       "              -0.0434\n",
       "              -0.0398\n",
       "              -0.0110\n",
       "              -0.1217\n",
       "              -0.1128\n",
       "              -0.3736\n",
       "              -0.2159\n",
       "               0.1545\n",
       "               0.2403\n",
       "              -0.2250\n",
       "              -0.0262\n",
       "              -0.0185\n",
       "               0.1129\n",
       "               0.3632\n",
       "              -0.3551\n",
       "              -0.1335\n",
       "               0.1996\n",
       "               0.1191\n",
       "              -0.4715\n",
       "              -0.4683\n",
       "              -0.3240\n",
       "              -0.2824\n",
       "              -0.2935\n",
       "              [torch.cuda.FloatTensor of size 178 (GPU 0)]),\n",
       "             ('conv1.conv.weight', \n",
       "              (0 ,0 ,0 ,.,.) = \n",
       "                0.2782 -0.0424 -0.1148\n",
       "                0.0027 -0.3435 -0.1760\n",
       "               -0.0952 -0.3595 -0.1678\n",
       "              \n",
       "              (0 ,0 ,1 ,.,.) = \n",
       "                0.5753  0.3898  0.1741\n",
       "                0.4799 -0.0263 -0.1901\n",
       "                0.1456 -0.3558 -0.3431\n",
       "              \n",
       "              (0 ,0 ,2 ,.,.) = \n",
       "                0.4113  0.1829 -0.0258\n",
       "                0.3324 -0.1706 -0.1853\n",
       "                0.2302 -0.0285  0.0477\n",
       "                      â‹® \n",
       "              \n",
       "              (0 ,1 ,0 ,.,.) = \n",
       "                0.4053 -0.1456 -0.4615\n",
       "                0.1639 -0.6788 -0.7849\n",
       "               -0.3282 -0.6905 -0.6277\n",
       "              \n",
       "              (0 ,1 ,1 ,.,.) = \n",
       "                1.1758  0.3863 -0.0028\n",
       "                1.2885 -0.1503 -0.3270\n",
       "                0.4080 -0.6428 -0.6273\n",
       "              \n",
       "              (0 ,1 ,2 ,.,.) = \n",
       "                0.8894  0.3879 -0.1380\n",
       "                1.1094 -0.0327 -0.2501\n",
       "                0.6822 -0.3234 -0.2816\n",
       "                      â‹® \n",
       "              \n",
       "              (0 ,2 ,0 ,.,.) = \n",
       "                0.3263 -0.2291 -0.0832\n",
       "               -0.0403 -0.5177 -0.5959\n",
       "               -0.2514 -0.4762 -0.3644\n",
       "              \n",
       "              (0 ,2 ,1 ,.,.) = \n",
       "                0.7634  0.1786  0.0556\n",
       "                0.5765 -0.3529 -0.4046\n",
       "               -0.1420 -0.8121 -0.7229\n",
       "              \n",
       "              (0 ,2 ,2 ,.,.) = \n",
       "                0.9322  0.2467  0.1594\n",
       "                0.6941 -0.2618 -0.0744\n",
       "                0.4832 -0.0811 -0.0169\n",
       "                   â‹®  â‹® \n",
       "              \n",
       "              (1 ,0 ,0 ,.,.) = \n",
       "                0.2260  0.5278  0.3222\n",
       "               -0.0748  0.0795 -0.1324\n",
       "               -0.2462 -0.3147 -0.0281\n",
       "              \n",
       "              (1 ,0 ,1 ,.,.) = \n",
       "                0.3808  0.6002  0.4029\n",
       "               -0.0265 -0.0033 -0.0353\n",
       "               -0.3031 -0.4779 -0.4304\n",
       "              \n",
       "              (1 ,0 ,2 ,.,.) = \n",
       "                0.3374  0.7443  0.3049\n",
       "                0.1961  0.2523  0.0327\n",
       "               -0.1153 -0.0665 -0.0767\n",
       "                      â‹® \n",
       "              \n",
       "              (1 ,1 ,0 ,.,.) = \n",
       "               -0.2827 -0.2864 -0.3977\n",
       "               -0.8004 -1.1666 -1.0739\n",
       "               -1.1882 -1.1767 -0.8584\n",
       "              \n",
       "              (1 ,1 ,1 ,.,.) = \n",
       "                0.1969  0.0542 -0.0874\n",
       "               -0.1913 -0.4492 -0.5669\n",
       "               -0.6269 -0.8370 -0.6285\n",
       "              \n",
       "              (1 ,1 ,2 ,.,.) = \n",
       "                0.2267  0.3627 -0.0048\n",
       "                0.1311 -0.2379 -0.2564\n",
       "               -0.1288 -0.0178 -0.1008\n",
       "                      â‹® \n",
       "              \n",
       "              (1 ,2 ,0 ,.,.) = \n",
       "               -0.5807 -0.2120 -0.1559\n",
       "               -0.4868 -0.6391 -0.5702\n",
       "               -0.6802 -0.8398 -0.6579\n",
       "              \n",
       "              (1 ,2 ,1 ,.,.) = \n",
       "                0.1472  0.3160  0.3600\n",
       "               -0.0227 -0.1603 -0.0089\n",
       "               -0.3990 -0.3841 -0.2558\n",
       "              \n",
       "              (1 ,2 ,2 ,.,.) = \n",
       "                0.5607  0.5814  0.6815\n",
       "                0.5092  0.5504  0.3732\n",
       "                0.3238  0.2442  0.4044\n",
       "                   â‹®  â‹® \n",
       "              \n",
       "              (2 ,0 ,0 ,.,.) = \n",
       "               -0.5938 -0.6785 -0.8503\n",
       "               -0.4667 -0.8791 -1.0823\n",
       "               -0.3754 -0.5478 -0.8207\n",
       "              \n",
       "              (2 ,0 ,1 ,.,.) = \n",
       "                0.0784 -0.1272 -0.4964\n",
       "               -0.0166 -0.3493 -0.8711\n",
       "               -0.1106 -0.6134 -0.6339\n",
       "              \n",
       "              (2 ,0 ,2 ,.,.) = \n",
       "                0.1247  0.0425 -0.1914\n",
       "                0.2465 -0.0366 -0.3091\n",
       "                0.0093 -0.0656 -0.3336\n",
       "                      â‹® \n",
       "              \n",
       "              (2 ,1 ,0 ,.,.) = \n",
       "                0.3406  0.1176  0.0259\n",
       "               -0.0476 -0.2900 -0.5327\n",
       "               -0.3024 -0.5890 -0.5681\n",
       "              \n",
       "              (2 ,1 ,1 ,.,.) = \n",
       "                0.6198  0.3819 -0.0762\n",
       "                0.3306 -0.2030 -0.5900\n",
       "                0.0254 -0.4575 -0.6882\n",
       "              \n",
       "              (2 ,1 ,2 ,.,.) = \n",
       "                0.6687  0.5766  0.1142\n",
       "                0.4705  0.0999 -0.3989\n",
       "                0.2579  0.0393 -0.3456\n",
       "                      â‹® \n",
       "              \n",
       "              (2 ,2 ,0 ,.,.) = \n",
       "               -0.2327  0.1068  0.3768\n",
       "               -0.4821 -0.1452 -0.1291\n",
       "               -0.9187 -0.7335 -0.6095\n",
       "              \n",
       "              (2 ,2 ,1 ,.,.) = \n",
       "                0.1096  0.2476  0.4364\n",
       "                0.0661 -0.1853  0.1015\n",
       "               -0.6207 -0.5263 -0.3488\n",
       "              \n",
       "              (2 ,2 ,2 ,.,.) = \n",
       "                0.5863  0.5409  0.7050\n",
       "                0.4948  0.4464  0.3163\n",
       "                0.0527 -0.0988 -0.0271\n",
       "              ...      \n",
       "                   â‹®  â‹® \n",
       "              \n",
       "              (29,0 ,0 ,.,.) = \n",
       "                0.3088  0.6190  0.6547\n",
       "                0.2705  0.7789  0.6953\n",
       "                0.1479  0.5846  0.7630\n",
       "              \n",
       "              (29,0 ,1 ,.,.) = \n",
       "               -0.2558 -0.3714 -0.3295\n",
       "               -0.1643 -0.1768 -0.1470\n",
       "               -0.2499 -0.2126 -0.2762\n",
       "              \n",
       "              (29,0 ,2 ,.,.) = \n",
       "               -0.3622 -0.3722 -0.1696\n",
       "               -0.5120 -0.4022 -0.3047\n",
       "               -0.3315 -0.3376 -0.2185\n",
       "                      â‹® \n",
       "              \n",
       "              (29,1 ,0 ,.,.) = \n",
       "                0.4044  0.7740  0.7568\n",
       "                0.6762  0.8834  0.9775\n",
       "                0.7520  0.8117  0.8009\n",
       "              \n",
       "              (29,1 ,1 ,.,.) = \n",
       "               -0.1704 -0.3381 -0.3031\n",
       "               -0.2062 -0.4381 -0.2742\n",
       "               -0.1439 -0.3357 -0.2328\n",
       "              \n",
       "              (29,1 ,2 ,.,.) = \n",
       "               -0.4653 -0.5909 -0.3612\n",
       "               -0.4252 -0.5798 -0.2918\n",
       "               -0.4761 -0.4126 -0.2319\n",
       "                      â‹® \n",
       "              \n",
       "              (29,2 ,0 ,.,.) = \n",
       "                0.4384  0.5018  0.2205\n",
       "                0.6240  0.5296  0.2577\n",
       "                0.6263  0.5020  0.4243\n",
       "              \n",
       "              (29,2 ,1 ,.,.) = \n",
       "                0.0248 -0.3085 -0.3649\n",
       "               -0.0345 -0.2266 -0.4263\n",
       "               -0.1955 -0.2504 -0.4631\n",
       "              \n",
       "              (29,2 ,2 ,.,.) = \n",
       "                0.0554 -0.1497 -0.1879\n",
       "               -0.1341 -0.3347 -0.3183\n",
       "               -0.1323 -0.3875 -0.5994\n",
       "                   â‹®  â‹® \n",
       "              \n",
       "              (30,0 ,0 ,.,.) = \n",
       "               -0.5181 -0.1802  0.1458\n",
       "               -0.7346 -0.2635  0.5049\n",
       "               -0.6110 -0.4011  0.4042\n",
       "              \n",
       "              (30,0 ,1 ,.,.) = \n",
       "               -0.6986 -0.0960  0.5343\n",
       "               -0.6699  0.0897  0.8328\n",
       "               -0.7550 -0.1879  0.8152\n",
       "              \n",
       "              (30,0 ,2 ,.,.) = \n",
       "               -0.3696  0.3821  0.9990\n",
       "               -0.4328  0.2432  1.1716\n",
       "               -0.6332 -0.0292  0.8734\n",
       "                      â‹® \n",
       "              \n",
       "              (30,1 ,0 ,.,.) = \n",
       "               -0.4794 -0.2134  0.1414\n",
       "               -0.5885 -0.2061  0.3080\n",
       "               -0.5842 -0.4273  0.0053\n",
       "              \n",
       "              (30,1 ,1 ,.,.) = \n",
       "               -0.4165 -0.1477  0.4025\n",
       "               -0.4313 -0.1458  0.6119\n",
       "               -0.5775 -0.4406  0.2704\n",
       "              \n",
       "              (30,1 ,2 ,.,.) = \n",
       "               -0.1563  0.3003  0.9130\n",
       "               -0.0686  0.4340  1.3110\n",
       "               -0.1320 -0.0892  0.6593\n",
       "                      â‹® \n",
       "              \n",
       "              (30,2 ,0 ,.,.) = \n",
       "                0.2004 -0.0311  0.0879\n",
       "               -0.0396 -0.3387  0.1729\n",
       "                0.0168 -0.2434 -0.0504\n",
       "              \n",
       "              (30,2 ,1 ,.,.) = \n",
       "               -0.2115 -0.4541  0.1014\n",
       "               -0.1257 -0.3715  0.1302\n",
       "               -0.3678 -0.3598 -0.0895\n",
       "              \n",
       "              (30,2 ,2 ,.,.) = \n",
       "                0.1055  0.1054  0.3692\n",
       "                0.2056  0.0298  0.3995\n",
       "                0.0726 -0.0753  0.2380\n",
       "                   â‹®  â‹® \n",
       "              \n",
       "              (31,0 ,0 ,.,.) = \n",
       "                0.2345  0.3783  0.2466\n",
       "                0.1044  0.2643  0.2020\n",
       "                0.1945  0.3938  0.2255\n",
       "              \n",
       "              (31,0 ,1 ,.,.) = \n",
       "                0.5061  0.4958  0.4181\n",
       "                0.6759  0.5424  0.4655\n",
       "                0.5817  0.8007  0.5441\n",
       "              \n",
       "              (31,0 ,2 ,.,.) = \n",
       "                0.0033  0.2265  0.2062\n",
       "                0.1079  0.2606  0.0950\n",
       "                0.2852  0.3489  0.0874\n",
       "                      â‹® \n",
       "              \n",
       "              (31,1 ,0 ,.,.) = \n",
       "               -0.4211 -0.3246 -0.5545\n",
       "               -0.4145 -0.5688 -0.6390\n",
       "               -0.1332 -0.2245 -0.2037\n",
       "              \n",
       "              (31,1 ,1 ,.,.) = \n",
       "               -0.3724 -0.4894 -0.4064\n",
       "               -0.7042 -0.8719 -0.8604\n",
       "               -0.2218 -0.3646 -0.2746\n",
       "              \n",
       "              (31,1 ,2 ,.,.) = \n",
       "               -0.7055 -0.5381 -0.6385\n",
       "               -0.6215 -0.7729 -0.7995\n",
       "               -0.4342 -0.4584 -0.3822\n",
       "                      â‹® \n",
       "              \n",
       "              (31,2 ,0 ,.,.) = \n",
       "                0.3138  0.0918  0.2423\n",
       "                0.1121  0.1625  0.1475\n",
       "                0.2877  0.2288  0.5223\n",
       "              \n",
       "              (31,2 ,1 ,.,.) = \n",
       "                0.2104  0.0836  0.1151\n",
       "                0.1142  0.0326  0.1537\n",
       "                0.3733  0.3109  0.5580\n",
       "              \n",
       "              (31,2 ,2 ,.,.) = \n",
       "                0.3647  0.1392  0.1986\n",
       "                0.3605  0.2520  0.1467\n",
       "                0.3067  0.3465  0.4189\n",
       "              [torch.cuda.FloatTensor of size 32x3x3x3x3 (GPU 0)]),\n",
       "             ('conv1.batchnorm.weight', \n",
       "               1.0427\n",
       "               0.5220\n",
       "               0.5706\n",
       "               1.3096\n",
       "               0.3158\n",
       "               2.0173\n",
       "               0.6189\n",
       "               0.4672\n",
       "               0.7662\n",
       "               0.5342\n",
       "               0.5916\n",
       "               0.6028\n",
       "               1.3521\n",
       "               0.6648\n",
       "               0.3916\n",
       "               2.5119\n",
       "               1.2782\n",
       "               0.9789\n",
       "               0.5067\n",
       "               0.5716\n",
       "               1.3382\n",
       "               1.1049\n",
       "               0.4586\n",
       "               0.4632\n",
       "               0.3449\n",
       "               0.9506\n",
       "               1.0676\n",
       "               0.8609\n",
       "               2.3439\n",
       "               0.6921\n",
       "               0.8590\n",
       "               0.2830\n",
       "              [torch.cuda.FloatTensor of size 32 (GPU 0)]),\n",
       "             ('conv1.batchnorm.bias', \n",
       "              -0.5561\n",
       "              -0.5895\n",
       "              -0.6134\n",
       "               0.7050\n",
       "              -0.2978\n",
       "               1.0341\n",
       "              -0.2021\n",
       "              -0.3432\n",
       "               0.2505\n",
       "               0.1353\n",
       "               0.1163\n",
       "               0.1835\n",
       "               0.2973\n",
       "              -0.6177\n",
       "              -0.7061\n",
       "               0.6791\n",
       "               0.2173\n",
       "               0.2852\n",
       "              -0.4724\n",
       "              -0.6024\n",
       "              -0.9530\n",
       "               0.4977\n",
       "              -0.6591\n",
       "              -0.5013\n",
       "              -0.6624\n",
       "               0.1289\n",
       "               0.3034\n",
       "               0.3280\n",
       "               0.4834\n",
       "               0.1467\n",
       "               0.3364\n",
       "              -0.5591\n",
       "              [torch.cuda.FloatTensor of size 32 (GPU 0)]),\n",
       "             ('conv1.batchnorm.running_mean', \n",
       "               -0.2509\n",
       "              -15.7716\n",
       "              -17.9523\n",
       "                0.0915\n",
       "              -17.9955\n",
       "               -0.8806\n",
       "               -0.5164\n",
       "              -11.4281\n",
       "               -0.5583\n",
       "                0.2435\n",
       "                0.4715\n",
       "                0.5623\n",
       "               -0.7913\n",
       "               21.5145\n",
       "               -2.3825\n",
       "               -0.6060\n",
       "               -0.2480\n",
       "               -0.2514\n",
       "               -1.2444\n",
       "               12.0680\n",
       "               -0.4880\n",
       "                0.1926\n",
       "                3.1569\n",
       "              -15.2968\n",
       "               -9.1988\n",
       "               -0.0570\n",
       "               -0.1200\n",
       "                0.3178\n",
       "               -0.9176\n",
       "               -0.4387\n",
       "               -0.0144\n",
       "                3.5800\n",
       "              [torch.cuda.FloatTensor of size 32 (GPU 0)]),\n",
       "             ('conv1.batchnorm.running_var', \n",
       "                28.7735\n",
       "               116.5067\n",
       "               145.4718\n",
       "                25.3371\n",
       "               137.5505\n",
       "                19.3426\n",
       "                 2.9887\n",
       "                64.2031\n",
       "                31.5107\n",
       "                52.6595\n",
       "                49.2454\n",
       "                50.6194\n",
       "                44.6077\n",
       "               167.3143\n",
       "                44.5657\n",
       "                22.4636\n",
       "                54.1959\n",
       "                26.2083\n",
       "                28.0882\n",
       "                93.1146\n",
       "                27.9159\n",
       "                31.3767\n",
       "                16.1703\n",
       "                91.7947\n",
       "                37.0677\n",
       "                 3.0997\n",
       "                21.0181\n",
       "                22.9858\n",
       "                29.9190\n",
       "                45.9813\n",
       "                27.3750\n",
       "                27.2363\n",
       "              [torch.cuda.FloatTensor of size 32 (GPU 0)]),\n",
       "             ('conv2.conv.weight', \n",
       "              (0 ,0 ,0 ,.,.) = \n",
       "               -2.4395e-01  3.7298e-01 -3.8372e-01\n",
       "               -3.5195e-01 -5.6280e-01 -6.0003e-01\n",
       "               -6.1465e-02 -1.8759e-01 -1.6290e-01\n",
       "              \n",
       "              (0 ,0 ,1 ,.,.) = \n",
       "               -3.7645e-01  1.9801e-02 -8.8521e-01\n",
       "               -5.0955e-01 -1.0610e+00 -1.1069e+00\n",
       "               -5.6229e-02 -6.9480e-01 -4.2827e-01\n",
       "              \n",
       "              (0 ,0 ,2 ,.,.) = \n",
       "                8.6757e-02  9.1692e-01 -3.1535e-01\n",
       "                2.1464e-01  1.8830e-01 -5.6968e-01\n",
       "                4.7690e-01  3.6414e-01  4.1868e-01\n",
       "                      â‹® \n",
       "              \n",
       "              (0 ,1 ,0 ,.,.) = \n",
       "                2.0249e-01  2.6375e-01 -1.3236e-01\n",
       "                3.1348e-01  9.9533e-02 -1.3614e-01\n",
       "               -1.7029e-01 -1.9042e-01 -4.8453e-01\n",
       "              \n",
       "              (0 ,1 ,1 ,.,.) = \n",
       "                2.9298e-01  3.6144e-01 -9.4942e-02\n",
       "                4.4048e-01  1.4731e-01 -1.4777e-01\n",
       "               -7.6457e-02 -2.9293e-01 -3.5083e-01\n",
       "              \n",
       "              (0 ,1 ,2 ,.,.) = \n",
       "                2.6342e-01  1.4975e-01 -6.1937e-02\n",
       "                3.3592e-01 -1.2637e-01 -3.7897e-01\n",
       "               -2.7380e-01 -5.7577e-01 -5.8205e-01\n",
       "                      â‹® \n",
       "              \n",
       "              (0 ,2 ,0 ,.,.) = \n",
       "               -1.0270e-01 -1.7730e-02 -3.4809e-01\n",
       "               -3.1841e-02 -1.9558e-01 -4.8490e-01\n",
       "               -3.8196e-01 -5.8110e-01 -8.1784e-01\n",
       "              \n",
       "              (0 ,2 ,1 ,.,.) = \n",
       "                1.7471e-01  4.6120e-02 -1.9740e-01\n",
       "                2.1095e-01 -1.0949e-01 -3.0616e-01\n",
       "               -2.2473e-01 -5.8803e-01 -6.3947e-01\n",
       "              \n",
       "              (0 ,2 ,2 ,.,.) = \n",
       "                1.5379e-01 -2.1192e-01 -3.4533e-01\n",
       "               -1.1691e-02 -4.6491e-01 -6.2690e-01\n",
       "               -4.1931e-01 -9.7385e-01 -9.8053e-01\n",
       "                 ...   \n",
       "                      â‹® \n",
       "              \n",
       "              (0 ,29,0 ,.,.) = \n",
       "                4.7477e-01  1.6342e-01  3.0993e-01\n",
       "                4.5202e-01 -2.9951e-01  1.9406e-01\n",
       "                3.5985e-01 -2.9032e-01  1.9773e-01\n",
       "              \n",
       "              (0 ,29,1 ,.,.) = \n",
       "               -1.3682e+00 -1.5068e+00 -7.3248e-01\n",
       "               -2.0328e+00 -1.8468e+00 -7.6371e-01\n",
       "               -1.6030e+00 -1.5268e+00 -6.4939e-01\n",
       "              \n",
       "              (0 ,29,2 ,.,.) = \n",
       "               -1.7550e-01  1.0445e-01 -2.4412e-01\n",
       "                3.5792e-02  4.1878e-01 -1.4402e-01\n",
       "                1.1265e-01  2.3491e-01 -3.0704e-01\n",
       "                      â‹® \n",
       "              \n",
       "              (0 ,30,0 ,.,.) = \n",
       "               -2.4684e-01  3.1868e-02  5.7361e-03\n",
       "               -5.1685e-01  1.5806e-01 -1.6242e-01\n",
       "               -2.3834e-01  9.4878e-03 -3.0907e-01\n",
       "              \n",
       "              (0 ,30,1 ,.,.) = \n",
       "               -1.0949e-01 -6.5095e-02 -2.1390e-01\n",
       "               -3.5995e-01  1.1961e-01 -3.2682e-01\n",
       "               -1.9070e-01 -1.4014e-01 -4.5153e-01\n",
       "              \n",
       "              (0 ,30,2 ,.,.) = \n",
       "               -4.5234e-01 -2.9731e-01  8.7311e-02\n",
       "               -1.0149e+00  3.7094e-02 -4.1565e-02\n",
       "               -5.3842e-01 -2.3642e-01 -1.8361e-01\n",
       "                      â‹® \n",
       "              \n",
       "              (0 ,31,0 ,.,.) = \n",
       "                5.0684e-01 -1.0320e-01 -6.7455e-01\n",
       "                5.5545e-01  6.6977e-02 -4.1245e-01\n",
       "                4.9487e-01  3.6377e-02 -4.3744e-01\n",
       "              \n",
       "              (0 ,31,1 ,.,.) = \n",
       "               -1.6774e-02 -5.7769e-01 -9.5416e-01\n",
       "                7.8412e-02 -4.7238e-01 -9.1211e-01\n",
       "                5.6873e-05 -4.3891e-01 -8.0157e-01\n",
       "              \n",
       "              (0 ,31,2 ,.,.) = \n",
       "                1.3463e-01 -4.1388e-01 -7.9287e-01\n",
       "                1.0370e-01 -1.9542e-01 -6.9482e-01\n",
       "                2.7211e-02 -3.9021e-01 -7.5897e-01\n",
       "                   â‹®  â‹® \n",
       "              \n",
       "              (1 ,0 ,0 ,.,.) = \n",
       "                1.5031e-01  2.6296e-01  3.8362e-01\n",
       "               -4.4459e-01 -4.0513e-01 -2.3845e-01\n",
       "               -3.7700e-02  1.2160e-01  2.6789e-01\n",
       "              \n",
       "              (1 ,0 ,1 ,.,.) = \n",
       "                3.4638e-01  4.4638e-01  4.5993e-01\n",
       "               -7.2839e-01 -3.3601e-01 -4.8709e-01\n",
       "                1.6642e-01  3.2189e-01  2.0332e-01\n",
       "              \n",
       "              (1 ,0 ,2 ,.,.) = \n",
       "                1.0933e-01  1.9528e-01  2.7981e-01\n",
       "               -8.2894e-01 -3.9590e-01 -7.2054e-01\n",
       "                1.8220e-01  3.9544e-01  3.9981e-01\n",
       "                      â‹® \n",
       "              \n",
       "              (1 ,1 ,0 ,.,.) = \n",
       "                3.4278e-01  6.4839e-01  2.8834e-01\n",
       "               -1.6762e-01  1.5664e-01 -1.1663e-01\n",
       "               -7.4375e-01 -1.1384e-01 -6.3260e-01\n",
       "              \n",
       "              (1 ,1 ,1 ,.,.) = \n",
       "                2.8515e-01  7.8636e-01  3.5573e-01\n",
       "               -1.5321e-02  4.5957e-01  8.2122e-02\n",
       "               -3.2305e-01 -3.0866e-02 -3.3091e-01\n",
       "              \n",
       "              (1 ,1 ,2 ,.,.) = \n",
       "                1.8232e-01  6.0120e-01  7.1680e-02\n",
       "               -1.6649e-01  1.9327e-01 -1.6500e-01\n",
       "               -5.3127e-01 -7.1464e-02 -4.9382e-01\n",
       "                      â‹® \n",
       "              \n",
       "              (1 ,2 ,0 ,.,.) = \n",
       "                5.0245e-01  7.6673e-01  4.5712e-01\n",
       "                2.9555e-02  4.0718e-01  1.1527e-02\n",
       "               -4.3761e-01 -8.2381e-03 -4.8620e-01\n",
       "              \n",
       "              (1 ,2 ,1 ,.,.) = \n",
       "                5.9805e-01  7.7368e-01  6.4889e-01\n",
       "                3.3004e-01  5.7174e-01  3.1844e-01\n",
       "               -1.9036e-01  2.7637e-01 -1.7065e-01\n",
       "              \n",
       "              (1 ,2 ,2 ,.,.) = \n",
       "                6.6985e-01  9.7183e-01  5.9298e-01\n",
       "                2.6276e-01  4.9694e-01  2.4338e-01\n",
       "               -4.9965e-02  2.1214e-01 -8.4084e-02\n",
       "                 ...   \n",
       "                      â‹® \n",
       "              \n",
       "              (1 ,29,0 ,.,.) = \n",
       "               -3.9967e-01 -9.8743e-02 -1.7306e-01\n",
       "               -3.1654e-01  7.6663e-03 -3.2440e-02\n",
       "               -4.7044e-01 -3.4786e-02 -3.8956e-01\n",
       "              \n",
       "              (1 ,29,1 ,.,.) = \n",
       "               -1.6993e-02  9.5769e-02 -8.9960e-03\n",
       "                2.8234e-02  2.8088e-01  1.6267e-01\n",
       "                5.5676e-02  1.8302e-01 -4.0037e-03\n",
       "              \n",
       "              (1 ,29,2 ,.,.) = \n",
       "                1.5106e-01  3.9232e-01  1.9052e-01\n",
       "               -1.1536e-01  2.5551e-01  1.3620e-02\n",
       "               -1.9982e-01  2.0010e-01 -1.3287e-01\n",
       "                      â‹® \n",
       "              \n",
       "              (1 ,30,0 ,.,.) = \n",
       "               -9.5704e-05 -1.3228e-02 -1.1308e-01\n",
       "               -1.6557e-01 -1.3545e-01 -2.4802e-01\n",
       "               -2.5640e-01  8.7254e-02 -2.6799e-01\n",
       "              \n",
       "              (1 ,30,1 ,.,.) = \n",
       "               -1.4118e-01  9.9849e-02 -3.0655e-01\n",
       "               -7.2623e-01 -3.2077e-01 -7.3445e-01\n",
       "               -6.6496e-01 -2.1725e-01 -8.5499e-01\n",
       "              \n",
       "              (1 ,30,2 ,.,.) = \n",
       "               -5.2416e-01 -1.1578e-01 -6.2859e-01\n",
       "               -9.5001e-01 -2.8362e-01 -7.5645e-01\n",
       "               -9.5421e-01 -7.7593e-02 -6.7451e-01\n",
       "                      â‹® \n",
       "              \n",
       "              (1 ,31,0 ,.,.) = \n",
       "               -5.5974e-01 -5.6903e-01 -5.9476e-01\n",
       "               -7.4543e-01 -6.3297e-01 -3.2773e-01\n",
       "               -6.8200e-01 -7.2349e-01 -6.0494e-01\n",
       "              \n",
       "              (1 ,31,1 ,.,.) = \n",
       "               -4.6857e-01 -5.2844e-01 -4.9587e-01\n",
       "               -5.9366e-01 -5.1559e-01 -3.3789e-01\n",
       "               -6.6984e-01 -4.8918e-01 -4.8367e-01\n",
       "              \n",
       "              (1 ,31,2 ,.,.) = \n",
       "               -4.9526e-01 -6.0197e-01 -7.3709e-01\n",
       "               -6.0206e-01 -6.3428e-01 -6.2757e-01\n",
       "               -7.0698e-01 -6.5937e-01 -6.4639e-01\n",
       "                   â‹®  â‹® \n",
       "              \n",
       "              (2 ,0 ,0 ,.,.) = \n",
       "               -1.8202e-01 -4.5487e-01 -2.0421e-01\n",
       "               -4.2740e-01 -3.6542e-01 -1.2183e-01\n",
       "               -1.4881e-01 -3.1133e-01 -1.1351e-01\n",
       "              \n",
       "              (2 ,0 ,1 ,.,.) = \n",
       "               -2.2016e-02 -2.7773e-01 -9.6224e-02\n",
       "               -1.7015e-01  9.2082e-02  2.1983e-02\n",
       "               -3.3487e-02  1.0714e-01  2.6482e-02\n",
       "              \n",
       "              (2 ,0 ,2 ,.,.) = \n",
       "               -6.5667e-01 -5.5764e-01 -4.1418e-01\n",
       "               -1.0874e+00 -2.5538e-01 -1.6831e-01\n",
       "               -8.1750e-01 -8.5796e-02 -3.6417e-01\n",
       "                      â‹® \n",
       "              \n",
       "              (2 ,1 ,0 ,.,.) = \n",
       "               -2.5766e-01 -1.1064e-01  3.8869e-01\n",
       "               -1.6422e-01 -2.7332e-01  1.8065e-01\n",
       "               -3.1441e-02 -3.1611e-01 -2.2231e-01\n",
       "              \n",
       "              (2 ,1 ,1 ,.,.) = \n",
       "               -1.3374e-02  1.5150e-01  6.0728e-01\n",
       "                2.9777e-01  2.1044e-01  4.4203e-01\n",
       "                1.7412e-01 -2.6903e-02  6.5596e-02\n",
       "              \n",
       "              (2 ,1 ,2 ,.,.) = \n",
       "                2.8872e-01  2.2128e-01  7.6333e-01\n",
       "                4.0146e-01  3.1201e-01  4.5409e-01\n",
       "                3.9534e-01  8.5509e-02  2.7172e-01\n",
       "                      â‹® \n",
       "              \n",
       "              (2 ,2 ,0 ,.,.) = \n",
       "               -5.4674e-01 -3.1911e-01  3.9986e-02\n",
       "               -2.2213e-01 -2.1586e-01 -3.3765e-02\n",
       "               -2.7002e-01 -5.3803e-01 -5.1543e-01\n",
       "              \n",
       "              (2 ,2 ,1 ,.,.) = \n",
       "               -1.8357e-01  9.1692e-02  3.3451e-01\n",
       "                9.9975e-02  8.4488e-02  2.5351e-01\n",
       "                4.1166e-02 -1.1990e-01 -1.4256e-01\n",
       "              \n",
       "              (2 ,2 ,2 ,.,.) = \n",
       "                6.5540e-02  2.4144e-01  1.8547e-01\n",
       "                2.2804e-01  7.4829e-02  2.3400e-01\n",
       "                2.1359e-01  6.8814e-02  5.8305e-02\n",
       "                 ...   \n",
       "                      â‹® \n",
       "              \n",
       "              (2 ,29,0 ,.,.) = \n",
       "                1.7215e-01  5.0877e-01  1.3762e-04\n",
       "                2.7101e-01  6.7972e-01  3.0531e-01\n",
       "                2.4523e-01  5.1027e-01  3.3118e-01\n",
       "              \n",
       "              (2 ,29,1 ,.,.) = \n",
       "               -1.4359e-02  1.0181e-01 -1.8808e-01\n",
       "                1.4661e-01  3.2653e-02 -1.8100e-01\n",
       "                1.9218e-01  4.0063e-02 -2.9174e-01\n",
       "              \n",
       "              (2 ,29,2 ,.,.) = \n",
       "               -1.3802e+00 -1.9393e+00 -9.2382e-01\n",
       "               -1.5744e+00 -2.1306e+00 -1.0439e+00\n",
       "               -1.0607e+00 -1.3013e+00 -6.1197e-01\n",
       "                      â‹® \n",
       "              \n",
       "              (2 ,30,0 ,.,.) = \n",
       "               -1.0667e-01 -6.2711e-01  2.0560e-01\n",
       "               -2.2265e-01 -9.6887e-01  1.1917e-01\n",
       "               -5.0774e-01 -2.9545e-01 -1.9078e-01\n",
       "              \n",
       "              (2 ,30,1 ,.,.) = \n",
       "               -2.3081e-01 -6.7058e-02  1.9582e-01\n",
       "                9.2930e-02 -9.4353e-02  4.3144e-01\n",
       "               -2.7182e-01  1.7397e-01  1.5162e-01\n",
       "              \n",
       "              (2 ,30,2 ,.,.) = \n",
       "                1.1811e-01  2.2808e-01  3.1579e-01\n",
       "                3.2564e-01  1.7855e-01  3.9567e-01\n",
       "               -6.2042e-03  2.6208e-01  1.4250e-01\n",
       "                      â‹® \n",
       "              \n",
       "              (2 ,31,0 ,.,.) = \n",
       "               -1.4156e-01 -1.3079e-01  9.4945e-02\n",
       "               -3.8155e-01 -3.3465e-01 -1.3693e-01\n",
       "               -1.8709e-01 -2.7764e-01 -2.0415e-01\n",
       "              \n",
       "              (2 ,31,1 ,.,.) = \n",
       "               -5.5006e-02 -1.0057e-01  1.0934e-01\n",
       "               -1.4754e-01 -1.4508e-01 -1.0829e-02\n",
       "               -9.5971e-02 -1.6131e-01 -7.4952e-02\n",
       "              \n",
       "              (2 ,31,2 ,.,.) = \n",
       "               -6.0394e-02  1.5164e-02  2.0785e-01\n",
       "               -8.4709e-02 -1.7442e-01  9.8604e-02\n",
       "                5.5055e-02 -1.6792e-01  7.3207e-02\n",
       "              ...      \n",
       "                   â‹®  â‹® \n",
       "              \n",
       "              (61,0 ,0 ,.,.) = \n",
       "               -1.5637e-01  1.6107e-01  3.5392e-01\n",
       "               -4.7968e-01 -9.4885e-02  5.8989e-02\n",
       "               -4.2228e-01 -5.4993e-02  1.0664e-01\n",
       "              \n",
       "              (61,0 ,1 ,.,.) = \n",
       "                4.3766e-02  2.6569e-01  2.8469e-01\n",
       "               -1.2725e-01 -1.6324e-01 -1.6145e-01\n",
       "               -8.5027e-02 -1.4197e-02 -7.2988e-02\n",
       "              \n",
       "              (61,0 ,2 ,.,.) = \n",
       "                1.4568e-01  2.6106e-01  1.5162e-01\n",
       "               -1.9245e-01 -2.4245e-01 -1.5963e-01\n",
       "               -2.1575e-01 -6.9469e-02 -1.5113e-01\n",
       "                      â‹® \n",
       "              \n",
       "              (61,1 ,0 ,.,.) = \n",
       "                1.3715e-01  1.1809e-01  1.0601e-02\n",
       "               -1.3956e-01  3.2003e-02  7.3292e-02\n",
       "               -1.8934e-01 -6.5806e-02 -9.7418e-02\n",
       "              \n",
       "              (61,1 ,1 ,.,.) = \n",
       "               -1.0737e-01  1.9742e-02  2.0719e-01\n",
       "               -2.4056e-01 -6.0214e-02  2.9013e-01\n",
       "               -2.4385e-01 -2.7453e-02 -2.3450e-02\n",
       "              \n",
       "              (61,1 ,2 ,.,.) = \n",
       "               -4.3454e-01  1.2147e-01  4.0985e-01\n",
       "               -6.7485e-01  2.4221e-02  4.3035e-01\n",
       "               -5.0665e-01 -2.3623e-01  2.6993e-01\n",
       "                      â‹® \n",
       "              \n",
       "              (61,2 ,0 ,.,.) = \n",
       "               -1.5954e-01 -1.4660e-01 -1.4681e-01\n",
       "               -2.3403e-01 -1.7597e-02  3.4160e-02\n",
       "               -2.5544e-01 -4.2059e-02  1.1767e-03\n",
       "              \n",
       "              (61,2 ,1 ,.,.) = \n",
       "               -3.9892e-01 -1.6957e-01 -1.1196e-01\n",
       "               -3.8443e-01 -1.2045e-01  1.5092e-01\n",
       "               -4.0288e-01 -1.3955e-01  1.2116e-01\n",
       "              \n",
       "              (61,2 ,2 ,.,.) = \n",
       "               -7.1113e-01 -3.0636e-01  7.1009e-02\n",
       "               -7.3632e-01 -2.4214e-01  2.8634e-01\n",
       "               -6.0777e-01 -3.2437e-01  1.8797e-01\n",
       "                 ...   \n",
       "                      â‹® \n",
       "              \n",
       "              (61,29,0 ,.,.) = \n",
       "               -3.8879e-01  1.1469e-01 -1.8010e-04\n",
       "               -6.7534e-01  1.0818e-02  1.5456e-01\n",
       "               -4.0705e-01 -1.0810e-01  1.8956e-01\n",
       "              \n",
       "              (61,29,1 ,.,.) = \n",
       "               -4.3888e-02  7.8116e-02  1.9207e-01\n",
       "               -6.3999e-01 -9.2233e-02  4.9872e-01\n",
       "               -8.0980e-01 -2.4094e-01  4.9690e-01\n",
       "              \n",
       "              (61,29,2 ,.,.) = \n",
       "                4.8570e-01 -2.8906e-01 -9.5856e-01\n",
       "                9.0429e-01  2.2347e-01 -1.0385e+00\n",
       "                6.6081e-01  2.7861e-01 -5.8184e-01\n",
       "                      â‹® \n",
       "              \n",
       "              (61,30,0 ,.,.) = \n",
       "                1.0974e-01 -6.5052e-01 -8.4779e-01\n",
       "                3.0780e-01 -6.0731e-01 -9.7427e-01\n",
       "                3.4047e-01 -2.1769e-01 -8.7908e-01\n",
       "              \n",
       "              (61,30,1 ,.,.) = \n",
       "               -7.8896e-02 -1.6499e-01  9.9042e-03\n",
       "                3.0674e-02 -2.6196e-01  2.7916e-03\n",
       "                4.1556e-01 -5.5155e-02 -3.3736e-02\n",
       "              \n",
       "              (61,30,2 ,.,.) = \n",
       "                4.6013e-01  3.2672e-01  2.2472e-01\n",
       "                2.7469e-01  3.1160e-01  3.2001e-01\n",
       "                6.4407e-01  1.6520e-01  2.8764e-01\n",
       "                      â‹® \n",
       "              \n",
       "              (61,31,0 ,.,.) = \n",
       "               -1.8200e-01  1.6527e-01  2.0497e-01\n",
       "               -6.5467e-02  1.7933e-01  3.5928e-01\n",
       "               -5.7798e-02  1.6279e-01  6.9910e-02\n",
       "              \n",
       "              (61,31,1 ,.,.) = \n",
       "               -4.1306e-02  1.7581e-01  3.8790e-01\n",
       "                1.7052e-02  2.2579e-01  4.2703e-01\n",
       "                3.0637e-04  8.3357e-02  2.6790e-01\n",
       "              \n",
       "              (61,31,2 ,.,.) = \n",
       "               -5.2212e-02  2.0267e-01  3.1265e-01\n",
       "               -4.2728e-02  2.2588e-01  3.8278e-01\n",
       "               -1.5260e-01  2.5141e-02  2.1026e-01\n",
       "                   â‹®  â‹® \n",
       "              \n",
       "              (62,0 ,0 ,.,.) = \n",
       "               -2.9820e-01  1.2321e-01  2.5757e-01\n",
       "                2.2275e-01  4.1245e-01  5.8924e-01\n",
       "                2.6450e-01  4.8242e-01  5.8572e-01\n",
       "              \n",
       "              (62,0 ,1 ,.,.) = \n",
       "               -2.9990e-01  1.4601e-01  6.4482e-01\n",
       "               -7.0487e-02  1.6702e-01  4.4815e-01\n",
       "               -2.1669e-03  3.6190e-01  6.9958e-01\n",
       "              \n",
       "              (62,0 ,2 ,.,.) = \n",
       "               -7.0586e-01 -5.6112e-01 -3.6236e-01\n",
       "               -6.7057e-01 -4.8982e-01 -3.8560e-01\n",
       "               -7.7873e-01 -5.2880e-01 -1.8106e-01\n",
       "                      â‹® \n",
       "              \n",
       "              (62,1 ,0 ,.,.) = \n",
       "               -3.1444e-01 -6.7100e-01 -6.4644e-01\n",
       "               -2.3482e-01 -7.4955e-01 -8.3315e-01\n",
       "               -1.4522e-01 -2.8621e-01 -4.7497e-01\n",
       "              \n",
       "              (62,1 ,1 ,.,.) = \n",
       "                2.0394e-02 -1.1920e-01 -8.4908e-02\n",
       "                7.2659e-02 -5.4400e-02 -2.1478e-01\n",
       "                9.7166e-02 -1.1874e-02  2.7037e-02\n",
       "              \n",
       "              (62,1 ,2 ,.,.) = \n",
       "                1.7255e-01  3.7562e-01  3.7568e-01\n",
       "                1.7417e-01  3.5857e-01  3.8177e-01\n",
       "                1.7547e-01  3.3811e-01  3.3586e-01\n",
       "                      â‹® \n",
       "              \n",
       "              (62,2 ,0 ,.,.) = \n",
       "               -3.9531e-01 -5.4843e-01 -5.9795e-01\n",
       "               -2.7180e-01 -5.4765e-01 -6.7538e-01\n",
       "               -2.0262e-01 -3.4357e-01 -2.7561e-01\n",
       "              \n",
       "              (62,2 ,1 ,.,.) = \n",
       "               -5.8624e-02  2.8608e-02 -9.3355e-02\n",
       "                1.7819e-02 -8.0807e-02 -1.5356e-01\n",
       "                7.3721e-02  2.1630e-01  8.9123e-02\n",
       "              \n",
       "              (62,2 ,2 ,.,.) = \n",
       "                8.6975e-03  4.5979e-01  4.8682e-01\n",
       "                2.3271e-01  4.5011e-01  4.2255e-01\n",
       "                2.7526e-01  4.1102e-01  4.4932e-01\n",
       "                 ...   \n",
       "                      â‹® \n",
       "              \n",
       "              (62,29,0 ,.,.) = \n",
       "               -3.8251e-01  3.6683e-01  1.6528e-02\n",
       "               -4.3470e-02  9.8981e-01  3.4466e-01\n",
       "               -4.9206e-01  2.7212e-01 -1.0003e-02\n",
       "              \n",
       "              (62,29,1 ,.,.) = \n",
       "               -5.4914e-01  7.0843e-01  2.9067e-01\n",
       "               -2.2063e-01  1.2994e+00  7.1641e-01\n",
       "               -5.0114e-01  4.2064e-01  8.4967e-02\n",
       "              \n",
       "              (62,29,2 ,.,.) = \n",
       "               -9.1822e-01 -2.1852e-01  2.9171e-02\n",
       "               -7.9036e-01  2.1748e-01  4.4125e-01\n",
       "               -5.8834e-01 -1.2255e-01  4.8492e-02\n",
       "                      â‹® \n",
       "              \n",
       "              (62,30,0 ,.,.) = \n",
       "                1.0505e-01 -1.4633e-01 -4.5932e-01\n",
       "                9.6958e-02 -4.0671e-01 -9.4099e-01\n",
       "                5.0585e-02 -1.8751e-01 -4.5033e-01\n",
       "              \n",
       "              (62,30,1 ,.,.) = \n",
       "               -4.4199e-04 -2.2352e-01  3.2388e-02\n",
       "                1.0468e-01 -4.5290e-01 -2.3797e-01\n",
       "                1.5316e-01 -7.3156e-02 -9.9671e-02\n",
       "              \n",
       "              (62,30,2 ,.,.) = \n",
       "               -1.3505e-01 -8.9125e-02  3.5558e-01\n",
       "               -1.4076e-01 -1.6977e-01  5.3046e-01\n",
       "               -1.4741e-02  1.3822e-02  2.6320e-01\n",
       "                      â‹® \n",
       "              \n",
       "              (62,31,0 ,.,.) = \n",
       "               -4.7871e-01 -5.9147e-01 -5.4226e-01\n",
       "               -5.1500e-01 -4.6812e-01 -4.2534e-01\n",
       "               -3.9523e-01 -4.0492e-01 -4.3681e-01\n",
       "              \n",
       "              (62,31,1 ,.,.) = \n",
       "               -4.0056e-01 -3.2426e-01 -3.1099e-01\n",
       "               -2.9838e-01 -3.1487e-01 -2.3324e-01\n",
       "               -2.6681e-01 -2.5544e-01 -6.6074e-02\n",
       "              \n",
       "              (62,31,2 ,.,.) = \n",
       "               -2.1358e-01 -1.0651e-01 -1.2901e-02\n",
       "               -1.1095e-01  4.3759e-02  1.2075e-01\n",
       "                1.0949e-02  1.1599e-01  1.2713e-01\n",
       "                   â‹®  â‹® \n",
       "              \n",
       "              (63,0 ,0 ,.,.) = \n",
       "                4.5226e-01  7.4919e-01  6.1159e-01\n",
       "                1.6100e-01  2.3870e-01  4.1561e-01\n",
       "               -1.3931e-01 -3.5744e-01 -9.5481e-02\n",
       "              \n",
       "              (63,0 ,1 ,.,.) = \n",
       "                4.9729e-01  4.5662e-01  2.4194e-01\n",
       "                4.9604e-02  4.4558e-02  2.9464e-01\n",
       "                1.5022e-02 -1.0150e-01  2.0972e-02\n",
       "              \n",
       "              (63,0 ,2 ,.,.) = \n",
       "                5.7411e-01  2.1257e-01 -3.1508e-01\n",
       "               -2.0469e-01 -6.6804e-01 -4.9927e-01\n",
       "               -1.6588e-01 -4.6522e-01 -3.5668e-01\n",
       "                      â‹® \n",
       "              \n",
       "              (63,1 ,0 ,.,.) = \n",
       "               -1.9055e-01  7.6939e-02  2.3908e-01\n",
       "                1.7166e-01  6.2134e-01  6.8062e-01\n",
       "                3.6806e-01  7.2066e-01  7.8138e-01\n",
       "              \n",
       "              (63,1 ,1 ,.,.) = \n",
       "                2.1100e-01  3.2034e-01  3.0810e-01\n",
       "                4.5967e-01  9.2668e-01  9.6726e-01\n",
       "                1.0429e+00  1.3893e+00  1.5020e+00\n",
       "              \n",
       "              (63,1 ,2 ,.,.) = \n",
       "               -1.2444e-01 -1.0226e-01 -3.1376e-01\n",
       "                1.1024e-01  5.7277e-01  4.0254e-01\n",
       "                5.7091e-01  1.0120e+00  1.0664e+00\n",
       "                      â‹® \n",
       "              \n",
       "              (63,2 ,0 ,.,.) = \n",
       "               -6.3559e-02 -1.7670e-01  3.1511e-01\n",
       "                2.4008e-01  2.9935e-01  6.1698e-01\n",
       "                7.3110e-01  9.0839e-01  8.3961e-01\n",
       "              \n",
       "              (63,2 ,1 ,.,.) = \n",
       "                5.0747e-02  1.8443e-01  4.9696e-01\n",
       "                2.2868e-02  3.7565e-02  3.1720e-01\n",
       "                7.1656e-01  1.1856e+00  1.1351e+00\n",
       "              \n",
       "              (63,2 ,2 ,.,.) = \n",
       "               -5.1300e-01 -4.7271e-01 -4.9790e-01\n",
       "               -4.5926e-01 -5.4054e-01 -2.6780e-01\n",
       "                6.8015e-02  5.7330e-01  5.8014e-01\n",
       "                 ...   \n",
       "                      â‹® \n",
       "              \n",
       "              (63,29,0 ,.,.) = \n",
       "               -4.8690e-01 -9.5158e-01 -8.9022e-01\n",
       "               -4.2071e-02 -6.8787e-01 -6.5590e-01\n",
       "                1.6243e-03 -1.4789e-01 -7.0100e-02\n",
       "              \n",
       "              (63,29,1 ,.,.) = \n",
       "                1.0714e-01  1.6308e-02 -1.9583e-01\n",
       "                6.8162e-02 -1.1763e-01 -7.1832e-02\n",
       "               -1.2183e-01 -2.8018e-01 -1.6916e-01\n",
       "              \n",
       "              (63,29,2 ,.,.) = \n",
       "                2.3391e-01  3.8525e-01  1.7825e-01\n",
       "                1.8603e-01  5.0217e-01  3.1377e-01\n",
       "                3.9602e-03 -5.1049e-02  8.1611e-04\n",
       "                      â‹® \n",
       "              \n",
       "              (63,30,0 ,.,.) = \n",
       "                3.8835e-01  7.9790e-01 -4.4548e-01\n",
       "                2.4197e-01  8.2995e-01 -3.0095e-01\n",
       "                4.5915e-03  1.2686e-01 -6.2001e-01\n",
       "              \n",
       "              (63,30,1 ,.,.) = \n",
       "                8.6372e-02  2.2795e-01 -1.2165e+00\n",
       "                5.0006e-02  2.3119e-01 -1.1971e+00\n",
       "                1.6553e-02 -1.1947e-02 -9.5176e-01\n",
       "              \n",
       "              (63,30,2 ,.,.) = \n",
       "               -2.8082e-01 -2.1862e-01 -1.2077e+00\n",
       "               -2.9352e-01 -4.7864e-01 -1.3681e+00\n",
       "               -2.7122e-01 -3.8226e-01 -1.1310e+00\n",
       "                      â‹® \n",
       "              \n",
       "              (63,31,0 ,.,.) = \n",
       "                5.8687e-01  1.0827e+00  8.7648e-01\n",
       "                7.0665e-01  1.3230e+00  9.0702e-01\n",
       "                4.2240e-01  9.8109e-01  5.6301e-01\n",
       "              \n",
       "              (63,31,1 ,.,.) = \n",
       "                5.5531e-01  1.1694e+00  8.3226e-01\n",
       "                7.1845e-01  1.4048e+00  9.6591e-01\n",
       "                4.4485e-01  1.1268e+00  6.9915e-01\n",
       "              \n",
       "              (63,31,2 ,.,.) = \n",
       "                3.8981e-01  1.1089e+00  7.2532e-01\n",
       "                6.2266e-01  1.2345e+00  8.0715e-01\n",
       "                3.4513e-01  9.6959e-01  5.3550e-01\n",
       "              [torch.cuda.FloatTensor of size 64x32x3x3x3 (GPU 0)]),\n",
       "             ('conv2.batchnorm.weight', \n",
       "               1.0461\n",
       "               0.7782\n",
       "               1.8535\n",
       "               0.7121\n",
       "               0.5169\n",
       "               0.6608\n",
       "               0.6092\n",
       "               0.7863\n",
       "               0.6298\n",
       "               0.9840\n",
       "               1.3344\n",
       "               1.5610\n",
       "               0.6849\n",
       "               0.8279\n",
       "               0.9641\n",
       "               1.0664\n",
       "               0.5506\n",
       "               0.7251\n",
       "               1.1067\n",
       "               1.0330\n",
       "               0.7174\n",
       "               0.9474\n",
       "               1.6049\n",
       "               1.0651\n",
       "               0.5208\n",
       "               0.7454\n",
       "               0.8823\n",
       "               1.4843\n",
       "               1.4822\n",
       "               1.3517\n",
       "               0.8526\n",
       "               1.1339\n",
       "               0.7562\n",
       "               1.6046\n",
       "               1.4633\n",
       "               0.9332\n",
       "               1.3956\n",
       "               0.7628\n",
       "               0.9432\n",
       "               1.2498\n",
       "               0.9370\n",
       "               0.9481\n",
       "               0.7279\n",
       "               0.8636\n",
       "               0.8508\n",
       "               0.9176\n",
       "               1.4755\n",
       "               1.4633\n",
       "               0.6936\n",
       "               0.8285\n",
       "               1.4701\n",
       "               0.6355\n",
       "               1.4767\n",
       "               0.9676\n",
       "               0.6489\n",
       "               0.6793\n",
       "               0.7402\n",
       "               1.2111\n",
       "               1.5083\n",
       "               1.2431\n",
       "               1.4349\n",
       "               1.2229\n",
       "               1.7774\n",
       "               0.6157\n",
       "              [torch.cuda.FloatTensor of size 64 (GPU 0)]),\n",
       "             ('conv2.batchnorm.bias', \n",
       "              -0.4910\n",
       "              -0.7396\n",
       "              -0.1471\n",
       "              -0.1525\n",
       "              -0.7899\n",
       "              -0.2654\n",
       "              -0.3946\n",
       "              -0.4405\n",
       "               0.2509\n",
       "              -0.6770\n",
       "               0.4248\n",
       "              -0.3661\n",
       "              -0.2052\n",
       "              -0.6560\n",
       "              -0.3416\n",
       "              -0.2432\n",
       "              -0.6840\n",
       "              -0.3124\n",
       "              -0.0103\n",
       "              -0.2509\n",
       "              -0.6875\n",
       "              -0.2377\n",
       "              -0.5284\n",
       "              -0.2079\n",
       "               0.1468\n",
       "              -0.3764\n",
       "              -0.9545\n",
       "              -0.3086\n",
       "              -0.5081\n",
       "              -0.1366\n",
       "              -0.5883\n",
       "              -0.2255\n",
       "               0.5439\n",
       "              -0.0070\n",
       "              -0.2683\n",
       "              -0.5202\n",
       "              -0.1158\n",
       "              -0.5007\n",
       "              -0.1578\n",
       "              -0.4956\n",
       "              -0.3817\n",
       "              -0.2951\n",
       "              -0.6487\n",
       "              -0.5483\n",
       "              -0.2646\n",
       "              -0.6383\n",
       "              -0.0548\n",
       "              -0.0764\n",
       "              -0.2743\n",
       "              -0.6040\n",
       "              -0.4693\n",
       "              -0.4103\n",
       "              -0.2196\n",
       "              -0.1216\n",
       "              -0.4033\n",
       "               0.0265\n",
       "              -0.2701\n",
       "              -0.0354\n",
       "              -0.0801\n",
       "              -1.0866\n",
       "              -0.1307\n",
       "              -0.3615\n",
       "               0.1383\n",
       "              -0.6712\n",
       "              [torch.cuda.FloatTensor of size 64 (GPU 0)]),\n",
       "             ('conv2.batchnorm.running_mean', \n",
       "               -41.7668\n",
       "               -76.3958\n",
       "               -35.4821\n",
       "               -50.6466\n",
       "                17.8668\n",
       "              -109.7227\n",
       "               -32.7570\n",
       "               -26.2371\n",
       "                 1.2602\n",
       "               -46.5525\n",
       "               -33.7573\n",
       "               -28.8240\n",
       "               -42.0804\n",
       "               -25.7454\n",
       "               -51.6036\n",
       "               -24.9369\n",
       "                 1.6629\n",
       "               -31.2785\n",
       "               -18.7405\n",
       "               -49.1986\n",
       "                -8.3868\n",
       "               -35.8768\n",
       "               -32.8095\n",
       "               -10.2010\n",
       "               -75.1307\n",
       "               -50.6811\n",
       "                10.6507\n",
       "               -23.8502\n",
       "               -33.0380\n",
       "               -22.3036\n",
       "               -16.3606\n",
       "               -53.8081\n",
       "               -17.5009\n",
       "               -16.1033\n",
       "               -21.4453\n",
       "                -0.9401\n",
       "               -24.7189\n",
       "               -13.9834\n",
       "               -16.3132\n",
       "               -42.1491\n",
       "               -80.3764\n",
       "               -43.6756\n",
       "               -12.2622\n",
       "                -0.6028\n",
       "               -67.0611\n",
       "               -57.8880\n",
       "               -21.5878\n",
       "               -19.2785\n",
       "                -8.1883\n",
       "               -58.9366\n",
       "               -42.8586\n",
       "                -0.6665\n",
       "               -28.4210\n",
       "               -60.4151\n",
       "               -74.5037\n",
       "               -16.8651\n",
       "               -39.2533\n",
       "               -14.3635\n",
       "               -10.3346\n",
       "               -12.3251\n",
       "               -15.0338\n",
       "               -13.3544\n",
       "               -13.6778\n",
       "                -4.7231\n",
       "              [torch.cuda.FloatTensor of size 64 (GPU 0)]),\n",
       "             ('conv2.batchnorm.running_var', \n",
       "               1374.5237\n",
       "               1290.1685\n",
       "               1884.4597\n",
       "               1314.7086\n",
       "                523.4650\n",
       "               2314.2463\n",
       "                802.1924\n",
       "               1026.6185\n",
       "                572.2568\n",
       "                853.8540\n",
       "                911.3957\n",
       "                700.8965\n",
       "               1697.3600\n",
       "                819.4248\n",
       "               1182.2556\n",
       "                593.3503\n",
       "                481.2034\n",
       "                908.9099\n",
       "                633.2943\n",
       "               1010.3677\n",
       "                610.6522\n",
       "                677.1891\n",
       "                594.1509\n",
       "               1020.6110\n",
       "               2145.8535\n",
       "               1408.4836\n",
       "                539.3391\n",
       "                499.6320\n",
       "                687.3514\n",
       "                761.3973\n",
       "                648.8400\n",
       "               1238.3757\n",
       "                554.8024\n",
       "                437.1747\n",
       "                682.0092\n",
       "                245.9813\n",
       "               1650.5579\n",
       "                509.3034\n",
       "                227.8340\n",
       "                857.9226\n",
       "               1908.4865\n",
       "               1393.2434\n",
       "                874.8400\n",
       "                484.0443\n",
       "               3158.3574\n",
       "               1467.7126\n",
       "                445.3492\n",
       "                272.9898\n",
       "                143.5984\n",
       "               1366.1681\n",
       "                936.8835\n",
       "                384.3637\n",
       "               2024.9600\n",
       "               2130.0991\n",
       "               1373.5022\n",
       "                357.5379\n",
       "               1111.9532\n",
       "                325.8914\n",
       "                266.4372\n",
       "                841.2179\n",
       "                629.8425\n",
       "                307.8111\n",
       "                565.8129\n",
       "                390.3993\n",
       "              [torch.cuda.FloatTensor of size 64 (GPU 0)]),\n",
       "             ('conv3.conv.weight', \n",
       "              ( 0 , 0 , 0 ,.,.) = \n",
       "               -4.0367e-01 -5.8808e-01 -5.6547e-02\n",
       "               -6.9329e-01 -1.0545e+00 -6.8101e-01\n",
       "               -7.0101e-01 -9.0691e-01 -9.8380e-01\n",
       "              \n",
       "              ( 0 , 0 , 1 ,.,.) = \n",
       "               -4.3843e-01 -9.2278e-01 -3.5309e-01\n",
       "               -7.2832e-01 -1.3950e+00 -1.1693e+00\n",
       "               -5.7635e-01 -1.1746e+00 -1.4026e+00\n",
       "              \n",
       "              ( 0 , 0 , 2 ,.,.) = \n",
       "                2.3990e-01  1.0952e-02  8.0734e-02\n",
       "                7.3489e-02 -9.8445e-02 -4.9693e-02\n",
       "               -9.0536e-02 -1.4836e-01 -3.4501e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 0 , 1 , 0 ,.,.) = \n",
       "               -7.2855e-01 -9.6185e-01 -3.8440e-01\n",
       "               -7.2909e-01 -7.4454e-01 -1.9291e-01\n",
       "               -3.5135e-01 -5.5962e-01 -8.9870e-02\n",
       "              \n",
       "              ( 0 , 1 , 1 ,.,.) = \n",
       "               -8.7821e-01 -1.0994e+00 -6.4683e-01\n",
       "               -1.0171e+00 -1.1876e+00 -6.7244e-01\n",
       "               -6.9803e-01 -9.8547e-01 -6.0821e-01\n",
       "              \n",
       "              ( 0 , 1 , 2 ,.,.) = \n",
       "               -8.5313e-01 -1.0307e+00 -5.1185e-01\n",
       "               -7.7357e-01 -9.7428e-01 -4.2783e-01\n",
       "               -4.5917e-01 -7.4344e-01 -4.2030e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 0 , 2 , 0 ,.,.) = \n",
       "                3.8154e-01  3.7040e-01  3.1935e-01\n",
       "               -6.1642e-02 -2.9183e-01 -1.6143e-01\n",
       "               -2.8616e-01 -6.4564e-01 -4.9630e-01\n",
       "              \n",
       "              ( 0 , 2 , 1 ,.,.) = \n",
       "               -2.8210e-01 -3.9978e-01 -1.5340e-01\n",
       "               -9.3430e-01 -9.8041e-01 -5.6042e-01\n",
       "               -9.0448e-01 -9.3013e-01 -6.9122e-01\n",
       "              \n",
       "              ( 0 , 2 , 2 ,.,.) = \n",
       "               -3.8294e-01 -5.3736e-01 -7.2995e-01\n",
       "               -4.3972e-01 -6.6961e-01 -8.3620e-01\n",
       "               -4.3504e-01 -4.8456e-01 -5.4350e-01\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              ( 0 ,61 , 0 ,.,.) = \n",
       "               -6.0701e-01 -8.8288e-01 -8.5465e-01\n",
       "               -7.5178e-01 -9.5269e-01 -9.9792e-01\n",
       "               -5.6252e-01 -9.9024e-01 -1.0802e+00\n",
       "              \n",
       "              ( 0 ,61 , 1 ,.,.) = \n",
       "               -1.7058e-01 -2.1232e-01 -3.9815e-01\n",
       "               -1.4917e-01  1.2691e-02 -3.6538e-01\n",
       "               -1.7246e-01 -4.6187e-01 -4.1498e-01\n",
       "              \n",
       "              ( 0 ,61 , 2 ,.,.) = \n",
       "                1.5421e-01  7.4368e-01 -5.0811e-02\n",
       "                2.2584e-01  7.2646e-01  3.0354e-01\n",
       "                1.2704e-01  3.9782e-01  3.8241e-02\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 0 ,62 , 0 ,.,.) = \n",
       "               -4.4223e-01 -8.9285e-01 -1.0653e+00\n",
       "               -3.7942e-02 -6.9239e-01 -6.2679e-01\n",
       "               -4.4026e-01 -6.0713e-01 -6.2738e-01\n",
       "              \n",
       "              ( 0 ,62 , 1 ,.,.) = \n",
       "               -3.1508e-01 -3.6550e-01 -7.0985e-01\n",
       "                4.5179e-01  3.2487e-01 -4.5584e-02\n",
       "                1.2580e-01  3.6006e-01 -4.8814e-01\n",
       "              \n",
       "              ( 0 ,62 , 2 ,.,.) = \n",
       "                1.8265e-01 -4.8228e-02 -5.1147e-01\n",
       "                9.2102e-01  6.2382e-01 -4.1586e-02\n",
       "                6.7187e-01  8.2953e-01  1.1971e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 0 ,63 , 0 ,.,.) = \n",
       "               -2.0301e-01 -5.3765e-01 -6.1094e-01\n",
       "               -1.6900e-01 -4.2589e-01 -4.1002e-01\n",
       "               -2.6677e-01 -2.5520e-01 -3.4662e-02\n",
       "              \n",
       "              ( 0 ,63 , 1 ,.,.) = \n",
       "               -1.7647e-01 -4.7337e-01 -4.0170e-01\n",
       "                2.1309e-02 -3.1565e-01 -4.2129e-01\n",
       "                1.2562e-01 -9.8886e-03 -1.0439e-01\n",
       "              \n",
       "              ( 0 ,63 , 2 ,.,.) = \n",
       "                4.4647e-01  2.0549e-01  1.7094e-02\n",
       "                6.8537e-01  4.4614e-01  3.3037e-01\n",
       "                4.7032e-01  2.2354e-01  3.1933e-01\n",
       "                    â‹®   â‹®  \n",
       "              \n",
       "              ( 1 , 0 , 0 ,.,.) = \n",
       "               -1.2969e-01 -3.6338e-01  1.2505e-01\n",
       "                1.6503e-01  2.1844e-01  2.1609e-02\n",
       "                5.5759e-01 -1.8232e-02  1.8632e-02\n",
       "              \n",
       "              ( 1 , 0 , 1 ,.,.) = \n",
       "               -5.1220e-01 -3.2301e-01 -1.0426e-01\n",
       "                8.8954e-03  4.1887e-01 -5.8488e-03\n",
       "                7.4124e-02  5.8106e-02 -4.1113e-02\n",
       "              \n",
       "              ( 1 , 0 , 2 ,.,.) = \n",
       "               -4.3957e-01  1.2032e-01  1.8884e-01\n",
       "                2.2489e-02  3.9203e-01  5.6190e-02\n",
       "                4.5861e-02  1.9462e-01 -7.2373e-02\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 1 , 1 , 0 ,.,.) = \n",
       "                6.2471e-01  6.8619e-01  6.1522e-01\n",
       "                7.7181e-02 -4.2847e-02 -9.9769e-01\n",
       "               -3.5509e-01  1.3472e-01 -6.6015e-01\n",
       "              \n",
       "              ( 1 , 1 , 1 ,.,.) = \n",
       "                5.3692e-01  5.9380e-01  4.2557e-01\n",
       "                2.3595e-01  1.3197e-01 -7.1836e-01\n",
       "               -3.5398e-01  1.0936e-01 -7.1812e-01\n",
       "              \n",
       "              ( 1 , 1 , 2 ,.,.) = \n",
       "                8.7832e-01  7.4866e-01  7.1308e-01\n",
       "                4.9825e-01  3.5193e-01 -4.3877e-01\n",
       "               -6.8021e-02  2.6375e-01 -3.5169e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 1 , 2 , 0 ,.,.) = \n",
       "               -4.4671e-01  1.2835e-01 -9.3436e-02\n",
       "               -6.6910e-01  4.9761e-01  4.5155e-02\n",
       "               -4.1085e-01  6.0910e-01 -4.2747e-02\n",
       "              \n",
       "              ( 1 , 2 , 1 ,.,.) = \n",
       "               -5.4881e-01  6.4739e-02 -3.4075e-01\n",
       "               -8.1476e-01  3.3022e-01 -2.6899e-01\n",
       "               -5.9848e-01  5.0704e-01 -1.6018e-01\n",
       "              \n",
       "              ( 1 , 2 , 2 ,.,.) = \n",
       "               -3.4055e-01  1.1461e-01 -1.3746e-01\n",
       "               -7.4513e-01  2.7202e-01 -3.2446e-02\n",
       "               -6.2919e-01  4.3060e-01  1.2698e-01\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              ( 1 ,61 , 0 ,.,.) = \n",
       "               -5.0990e-01  2.8040e-01 -1.3525e-01\n",
       "               -6.4430e-01  2.1803e-01 -1.1543e-01\n",
       "               -8.4737e-01  8.5674e-02 -1.7086e-01\n",
       "              \n",
       "              ( 1 ,61 , 1 ,.,.) = \n",
       "               -6.3873e-01  4.2217e-01 -2.7490e-01\n",
       "               -6.8627e-01  4.4062e-01 -1.2039e-01\n",
       "               -1.2944e+00  1.6274e-01 -1.5888e-01\n",
       "              \n",
       "              ( 1 ,61 , 2 ,.,.) = \n",
       "               -6.5594e-01  3.4512e-01 -1.5501e-01\n",
       "               -6.7966e-01  4.9821e-01 -2.5866e-01\n",
       "               -9.5519e-01  3.5930e-01 -3.0854e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 1 ,62 , 0 ,.,.) = \n",
       "               -5.9694e-01 -2.3643e-01 -3.6284e-01\n",
       "               -8.2112e-01  1.4063e-01 -5.0372e-02\n",
       "               -8.4413e-01  2.5806e-01 -5.3426e-02\n",
       "              \n",
       "              ( 1 ,62 , 1 ,.,.) = \n",
       "               -5.3075e-01 -6.2539e-02 -4.4000e-01\n",
       "               -7.4205e-01  1.2673e-01 -1.3747e-01\n",
       "               -5.7977e-01  2.1506e-01  1.2051e-01\n",
       "              \n",
       "              ( 1 ,62 , 2 ,.,.) = \n",
       "               -5.8080e-01 -2.3084e-01 -3.1447e-01\n",
       "               -5.3041e-01  1.6514e-02  1.8797e-01\n",
       "               -4.6789e-01  3.9770e-02  1.1454e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 1 ,63 , 0 ,.,.) = \n",
       "               -8.6793e-01  3.4752e-01  3.9852e-01\n",
       "               -3.9294e-02  7.0948e-01  2.7765e-01\n",
       "               -4.9559e-01  3.9910e-01  1.9042e-01\n",
       "              \n",
       "              ( 1 ,63 , 1 ,.,.) = \n",
       "               -6.5989e-01  1.8074e-01  2.1979e-01\n",
       "                7.1560e-02  5.9443e-01  1.5221e-01\n",
       "               -5.8040e-01  3.6569e-02 -2.2661e-01\n",
       "              \n",
       "              ( 1 ,63 , 2 ,.,.) = \n",
       "               -7.6119e-01 -1.5055e-01  2.1868e-01\n",
       "               -1.2563e-01  1.7812e-01 -6.9398e-02\n",
       "               -1.0934e+00 -5.1819e-01 -6.0172e-01\n",
       "                    â‹®   â‹®  \n",
       "              \n",
       "              ( 2 , 0 , 0 ,.,.) = \n",
       "               -1.9649e-01 -4.6830e-01 -1.2154e-01\n",
       "               -2.7501e-02 -3.6191e-02  3.9378e-01\n",
       "               -3.0446e-02 -2.3486e-01  8.5078e-02\n",
       "              \n",
       "              ( 2 , 0 , 1 ,.,.) = \n",
       "                4.7069e-01  1.0397e+00  1.2217e+00\n",
       "               -2.2910e-01 -1.4521e-02  8.5625e-02\n",
       "                3.5917e-01  5.7065e-01  5.2108e-01\n",
       "              \n",
       "              ( 2 , 0 , 2 ,.,.) = \n",
       "               -6.2108e-01 -6.9002e-01 -1.6945e-01\n",
       "                7.6162e-02  2.1665e-01  3.7958e-01\n",
       "                3.7339e-01  3.5975e-01  2.6084e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 2 , 1 , 0 ,.,.) = \n",
       "                4.6990e-01  3.0244e-01  1.8596e-01\n",
       "                6.7844e-01  4.6268e-01  3.6238e-01\n",
       "                3.1484e-01  2.1263e-01  2.9824e-01\n",
       "              \n",
       "              ( 2 , 1 , 1 ,.,.) = \n",
       "                6.9538e-01  4.6027e-01  3.1885e-01\n",
       "                5.5753e-01  3.7906e-01  2.8175e-01\n",
       "                3.9410e-01  3.1578e-01  2.3786e-01\n",
       "              \n",
       "              ( 2 , 1 , 2 ,.,.) = \n",
       "                3.7294e-01  2.9260e-01  2.8317e-02\n",
       "                7.9301e-01  5.9609e-01  7.7282e-02\n",
       "                6.9950e-01  5.3401e-01  2.8078e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 2 , 2 , 0 ,.,.) = \n",
       "                3.4573e-01  3.3608e-01  5.5799e-01\n",
       "               -4.9611e-01 -1.3822e+00 -1.0409e+00\n",
       "                5.4641e-01  3.4043e-01  6.6918e-02\n",
       "              \n",
       "              ( 2 , 2 , 1 ,.,.) = \n",
       "               -1.7110e-01 -4.8137e-01 -5.9235e-01\n",
       "                4.2810e-01  7.3974e-01  4.0317e-01\n",
       "                1.4863e-01  1.3461e-01  2.0823e-01\n",
       "              \n",
       "              ( 2 , 2 , 2 ,.,.) = \n",
       "               -2.9226e-01 -3.2344e-01 -1.0774e-01\n",
       "               -1.4393e-01 -4.4554e-01 -1.9157e-01\n",
       "               -3.0098e-01 -5.6749e-01 -2.3738e-01\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              ( 2 ,61 , 0 ,.,.) = \n",
       "                2.9040e-01 -2.0738e-01 -2.7632e-01\n",
       "                8.5318e-02  8.4589e-02  7.0407e-01\n",
       "                1.4773e-01 -3.2018e-01  1.8945e-01\n",
       "              \n",
       "              ( 2 ,61 , 1 ,.,.) = \n",
       "                2.0593e-01  3.9298e-01  8.1046e-01\n",
       "               -1.3902e-01 -3.9133e-01 -3.3385e-01\n",
       "                6.4714e-02  3.1836e-01  2.1271e-01\n",
       "              \n",
       "              ( 2 ,61 , 2 ,.,.) = \n",
       "               -3.6109e-01 -9.0619e-01 -7.5760e-01\n",
       "               -2.2039e-01 -2.8225e-01 -6.1319e-02\n",
       "               -2.8318e-01 -5.6383e-01  1.0898e-02\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 2 ,62 , 0 ,.,.) = \n",
       "                1.3202e-01  3.7643e-01  4.6204e-01\n",
       "               -6.0873e-01 -6.8077e-01 -6.1072e-01\n",
       "               -8.3488e-02  2.9514e-01  1.8514e-01\n",
       "              \n",
       "              ( 2 ,62 , 1 ,.,.) = \n",
       "               -6.6824e-01 -1.0198e+00 -1.4071e+00\n",
       "                2.5522e-01  8.7751e-01  2.7489e-01\n",
       "               -2.8415e-01  6.6925e-02  1.7625e-01\n",
       "              \n",
       "              ( 2 ,62 , 2 ,.,.) = \n",
       "                5.3195e-02  1.1182e-01  1.8554e-01\n",
       "               -1.9191e-01 -1.5484e-01  8.1504e-02\n",
       "               -1.2820e-01 -1.9990e-01 -4.5594e-02\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 2 ,63 , 0 ,.,.) = \n",
       "                3.0486e-01  4.4327e-01  6.7900e-01\n",
       "                4.7187e-01  4.7550e-01  7.5818e-01\n",
       "                3.0000e-01  1.9555e-01  7.3282e-01\n",
       "              \n",
       "              ( 2 ,63 , 1 ,.,.) = \n",
       "                5.0713e-01  4.3587e-01  6.3966e-01\n",
       "                6.4844e-02 -6.6304e-02  6.8535e-02\n",
       "               -1.2148e-01 -2.2368e-01  7.6882e-02\n",
       "              \n",
       "              ( 2 ,63 , 2 ,.,.) = \n",
       "                3.5389e-01  1.8823e-01  3.1347e-01\n",
       "               -4.0425e-01 -6.0762e-01 -3.8994e-01\n",
       "               -3.2096e-01 -5.3546e-01 -1.4014e-01\n",
       "              ...         \n",
       "                    â‹®   â‹®  \n",
       "              \n",
       "              (125, 0 , 0 ,.,.) = \n",
       "                9.5276e-02  4.5557e-02 -1.6162e-01\n",
       "                4.1874e-01  6.0929e-01  9.9170e-02\n",
       "                5.4968e-02  2.2691e-01  6.9856e-02\n",
       "              \n",
       "              (125, 0 , 1 ,.,.) = \n",
       "                5.7159e-01  8.3930e-01  6.2017e-01\n",
       "                7.0457e-02  8.2840e-01  8.8884e-01\n",
       "               -3.2896e-01  6.4614e-02  5.9341e-01\n",
       "              \n",
       "              (125, 0 , 2 ,.,.) = \n",
       "                4.3385e-02  1.6894e-01  5.8030e-01\n",
       "               -8.0699e-01 -3.5471e-01  1.6270e-01\n",
       "               -1.1702e+00 -1.1012e+00 -6.7499e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (125, 1 , 0 ,.,.) = \n",
       "               -4.0790e-01 -3.1583e-01  4.2560e-03\n",
       "               -4.6182e-01 -2.2882e-01 -1.7916e-02\n",
       "               -5.3833e-01 -1.6114e-01  3.1623e-01\n",
       "              \n",
       "              (125, 1 , 1 ,.,.) = \n",
       "               -3.4351e-01 -4.1029e-01  5.7558e-02\n",
       "               -1.4550e-01 -2.2996e-02  4.8613e-02\n",
       "               -6.6784e-01 -4.9064e-01 -4.4953e-02\n",
       "              \n",
       "              (125, 1 , 2 ,.,.) = \n",
       "               -5.2230e-01 -5.1025e-01 -1.0106e-01\n",
       "               -4.0127e-01 -3.0071e-01 -1.7212e-01\n",
       "               -7.9056e-01 -6.7036e-01 -1.0691e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (125, 2 , 0 ,.,.) = \n",
       "                4.3506e-01  7.6944e-01  1.0568e+00\n",
       "               -4.6653e-02  9.9771e-02  5.7261e-01\n",
       "               -5.1484e-01 -8.2393e-01 -3.4721e-01\n",
       "              \n",
       "              (125, 2 , 1 ,.,.) = \n",
       "               -1.8009e-01  2.0270e-01  7.9892e-01\n",
       "               -9.5755e-02 -4.4482e-01  1.7820e-01\n",
       "               -2.4365e-01 -7.0721e-01 -8.2445e-01\n",
       "              \n",
       "              (125, 2 , 2 ,.,.) = \n",
       "               -7.1541e-01 -6.4876e-01 -4.4975e-01\n",
       "               -2.6985e-01 -5.5703e-01 -5.6262e-01\n",
       "               -2.3809e-02 -1.5542e-02 -1.7655e-01\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              (125,61 , 0 ,.,.) = \n",
       "                5.7915e-01  2.9167e-01  1.7499e-01\n",
       "                1.9587e-01  2.9508e-01  5.8804e-02\n",
       "               -5.1794e-01 -4.4979e-01 -6.3280e-01\n",
       "              \n",
       "              (125,61 , 1 ,.,.) = \n",
       "                4.8194e-01  6.4823e-01  1.0602e+00\n",
       "               -1.1482e-01  3.5806e-01  7.1706e-01\n",
       "               -8.3108e-01 -4.9203e-01 -4.0683e-01\n",
       "              \n",
       "              (125,61 , 2 ,.,.) = \n",
       "               -2.3516e-01 -1.7185e-01  3.1924e-01\n",
       "               -7.2495e-01 -4.8777e-01 -2.1947e-01\n",
       "               -1.3457e+00 -9.6196e-01 -1.4846e+00\n",
       "                        â‹®  \n",
       "              \n",
       "              (125,62 , 0 ,.,.) = \n",
       "                9.1715e-01  1.0592e+00  1.0275e+00\n",
       "               -1.0763e-01  1.6754e-01  6.0724e-01\n",
       "               -6.7837e-01 -5.8008e-01 -1.7379e-01\n",
       "              \n",
       "              (125,62 , 1 ,.,.) = \n",
       "               -4.0977e-01 -1.4127e-01  3.5528e-02\n",
       "                6.3246e-02 -1.2504e-01 -5.4486e-02\n",
       "                1.1051e-01  3.4226e-01 -3.2642e-01\n",
       "              \n",
       "              (125,62 , 2 ,.,.) = \n",
       "               -3.5468e-01 -3.4425e-01 -9.5020e-01\n",
       "                1.2319e-01  9.9148e-02 -4.7430e-01\n",
       "                1.7285e-01  3.9713e-01  2.4537e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (125,63 , 0 ,.,.) = \n",
       "                1.0431e+00  1.2837e-01  1.7965e-01\n",
       "               -3.6886e-02 -6.8098e-02  3.7614e-01\n",
       "                8.6832e-02 -2.7283e-01  1.7659e-01\n",
       "              \n",
       "              (125,63 , 1 ,.,.) = \n",
       "                1.0949e+00  2.8101e-01  5.6021e-01\n",
       "               -1.4326e-01 -5.7019e-01 -1.5431e-01\n",
       "               -1.3930e-01 -6.4163e-01 -3.3435e-01\n",
       "              \n",
       "              (125,63 , 2 ,.,.) = \n",
       "                8.5030e-01  2.0930e-01  4.5868e-01\n",
       "               -2.2782e-01 -6.5790e-01 -3.7891e-01\n",
       "               -2.7996e-01 -6.9848e-01 -4.0863e-01\n",
       "                    â‹®   â‹®  \n",
       "              \n",
       "              (126, 0 , 0 ,.,.) = \n",
       "               -1.8152e-01  2.3962e-01  2.5052e-01\n",
       "                3.1940e-01  2.7911e-01  9.4652e-02\n",
       "                4.1698e-01 -6.0481e-02  4.4600e-01\n",
       "              \n",
       "              (126, 0 , 1 ,.,.) = \n",
       "               -4.5153e-01  2.5936e-01 -1.1430e-01\n",
       "               -3.1225e-02  1.8089e-01 -1.8291e-01\n",
       "                2.0619e-01 -1.4362e-01  9.7488e-02\n",
       "              \n",
       "              (126, 0 , 2 ,.,.) = \n",
       "               -2.7048e-01  1.9718e-01  9.4753e-03\n",
       "               -1.7674e-01  9.3773e-02 -3.3861e-01\n",
       "               -7.1281e-02 -6.2067e-01 -1.6187e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (126, 1 , 0 ,.,.) = \n",
       "                5.4093e-01  3.7068e-01 -2.6043e-01\n",
       "                3.9878e-01  5.9115e-01  9.7774e-02\n",
       "                8.6860e-01  7.6832e-01  2.9561e-01\n",
       "              \n",
       "              (126, 1 , 1 ,.,.) = \n",
       "                7.1531e-01  6.8029e-01  2.9243e-01\n",
       "                7.4560e-01  7.8820e-01  3.7678e-01\n",
       "                1.1109e+00  7.9067e-01  5.1560e-01\n",
       "              \n",
       "              (126, 1 , 2 ,.,.) = \n",
       "                4.9159e-01  2.9142e-01 -1.0281e-01\n",
       "                3.9568e-01  3.4534e-01 -2.3937e-01\n",
       "                7.4847e-01  5.2058e-01  1.3397e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (126, 2 , 0 ,.,.) = \n",
       "               -2.1886e-01  2.6483e-01  3.2654e-02\n",
       "               -1.9697e-01  3.0697e-01  2.8856e-01\n",
       "               -3.4945e-02  2.6417e-01  1.1097e-01\n",
       "              \n",
       "              (126, 2 , 1 ,.,.) = \n",
       "               -3.5929e-01  2.5388e-01  1.3846e-01\n",
       "               -3.2432e-01  3.9381e-01  4.1958e-01\n",
       "               -8.9998e-02  3.8694e-01  4.6119e-01\n",
       "              \n",
       "              (126, 2 , 2 ,.,.) = \n",
       "               -3.0648e-01  2.7811e-01  2.3973e-01\n",
       "               -4.8430e-01  2.3816e-01  5.5936e-01\n",
       "               -4.8766e-01  1.6808e-01  5.9449e-01\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              (126,61 , 0 ,.,.) = \n",
       "                2.3232e-01  1.9404e-01 -1.6928e-02\n",
       "                3.2835e-01  1.1676e-01 -2.0002e-01\n",
       "                2.8574e-01  9.5778e-02 -2.0276e-01\n",
       "              \n",
       "              (126,61 , 1 ,.,.) = \n",
       "                1.4441e-01  3.4958e-01 -5.1732e-02\n",
       "                1.9012e-01  1.4510e-01  9.5527e-02\n",
       "                1.9464e-01  3.4097e-01  4.1266e-01\n",
       "              \n",
       "              (126,61 , 2 ,.,.) = \n",
       "               -1.8783e-01  3.1149e-01 -2.7058e-01\n",
       "               -4.2463e-02 -2.7383e-02 -2.1729e-01\n",
       "               -1.6698e-02 -1.2957e-01  3.9091e-02\n",
       "                        â‹®  \n",
       "              \n",
       "              (126,62 , 0 ,.,.) = \n",
       "                3.3984e-01  4.5367e-01  2.6515e-01\n",
       "                3.6701e-01  2.8108e-01  4.8621e-01\n",
       "                2.7840e-01  4.9553e-01  5.6965e-01\n",
       "              \n",
       "              (126,62 , 1 ,.,.) = \n",
       "                2.3104e-01  3.0055e-01  1.4649e-02\n",
       "                1.4883e-01  2.7755e-01  4.1668e-01\n",
       "               -4.3535e-02  2.6823e-01  6.1631e-01\n",
       "              \n",
       "              (126,62 , 2 ,.,.) = \n",
       "                3.7945e-02  5.7222e-03 -4.8750e-02\n",
       "               -2.2772e-01  1.5813e-01  2.3166e-01\n",
       "               -7.7834e-01  5.1879e-02  3.4868e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (126,63 , 0 ,.,.) = \n",
       "                1.3898e-01 -3.8796e-01 -1.2987e+00\n",
       "                1.3938e-01 -5.8532e-01 -8.8558e-01\n",
       "                6.8690e-02 -3.4581e-01 -1.5160e-01\n",
       "              \n",
       "              (126,63 , 1 ,.,.) = \n",
       "                3.3397e-01 -2.8259e-01 -1.3590e+00\n",
       "                3.5537e-01 -4.3705e-01 -6.4079e-01\n",
       "                2.9532e-01 -2.7376e-01  1.8792e-02\n",
       "              \n",
       "              (126,63 , 2 ,.,.) = \n",
       "               -6.1306e-03 -2.5500e-01 -1.2975e+00\n",
       "                8.7972e-04 -5.0056e-01 -6.7502e-01\n",
       "               -2.6468e-01 -3.6607e-01 -3.6261e-01\n",
       "                    â‹®   â‹®  \n",
       "              \n",
       "              (127, 0 , 0 ,.,.) = \n",
       "                5.1692e-01  2.2106e-01  1.5358e-01\n",
       "                2.6252e-02 -1.4169e-01 -2.0038e-01\n",
       "               -3.8536e-01  3.0097e-01 -5.7308e-02\n",
       "              \n",
       "              (127, 0 , 1 ,.,.) = \n",
       "               -2.9343e-02 -7.9814e-02 -8.5818e-02\n",
       "               -1.6376e-01  4.1399e-02 -3.0022e-01\n",
       "               -2.1094e-01  9.4674e-02 -1.8950e-01\n",
       "              \n",
       "              (127, 0 , 2 ,.,.) = \n",
       "               -1.5210e-01 -2.0324e-01 -1.6687e-01\n",
       "               -4.0496e-01 -1.7619e-01 -7.3308e-01\n",
       "               -1.0644e-01  3.9376e-01  8.4544e-02\n",
       "                        â‹®  \n",
       "              \n",
       "              (127, 1 , 0 ,.,.) = \n",
       "                2.9855e-01  1.1619e-01  2.0565e-01\n",
       "               -2.2846e-01  1.2967e-01  3.4366e-01\n",
       "               -2.1469e-01  1.0287e-01  2.8630e-01\n",
       "              \n",
       "              (127, 1 , 1 ,.,.) = \n",
       "                2.9404e-01  7.8965e-02  1.2663e-02\n",
       "               -1.6188e-01  1.6780e-01  5.8986e-01\n",
       "                1.0650e-02  3.0301e-01  6.5824e-01\n",
       "              \n",
       "              (127, 1 , 2 ,.,.) = \n",
       "                3.4300e-01  2.0038e-02  3.2320e-01\n",
       "               -8.2819e-02  2.5902e-01  7.8922e-01\n",
       "                9.3124e-02  4.1758e-01  8.0504e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (127, 2 , 0 ,.,.) = \n",
       "               -2.1711e-01  2.2064e-02 -1.5642e-01\n",
       "                1.7238e-01 -4.0380e-03 -6.4060e-02\n",
       "                6.9633e-01  1.0180e-01  9.0882e-02\n",
       "              \n",
       "              (127, 2 , 1 ,.,.) = \n",
       "                7.2491e-02  5.0085e-01  2.7641e-02\n",
       "                1.4847e-01 -2.3659e-01 -4.0869e-01\n",
       "                7.1212e-01  1.6153e-01  1.8314e-01\n",
       "              \n",
       "              (127, 2 , 2 ,.,.) = \n",
       "                5.6892e-02  3.9629e-01  1.3996e-01\n",
       "                2.7583e-01 -5.5583e-03 -1.7811e-01\n",
       "                4.3792e-01 -1.3623e-01 -2.3638e-01\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              (127,61 , 0 ,.,.) = \n",
       "               -1.8611e-01 -3.6799e-03  4.3085e-02\n",
       "                2.3394e-02 -2.3122e-01 -4.6213e-01\n",
       "               -3.4093e-01 -4.5146e-01 -4.6494e-01\n",
       "              \n",
       "              (127,61 , 1 ,.,.) = \n",
       "               -5.3418e-01 -3.5831e-01 -1.2934e-01\n",
       "               -3.5763e-02 -1.0755e-01  3.7153e-02\n",
       "               -4.2017e-01  1.0997e-02 -1.0772e-01\n",
       "              \n",
       "              (127,61 , 2 ,.,.) = \n",
       "               -5.7923e-01 -4.0654e-01 -6.1431e-01\n",
       "               -1.4533e-01 -5.1746e-01 -6.9462e-01\n",
       "               -4.7872e-01 -2.3008e-01 -3.5257e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (127,62 , 0 ,.,.) = \n",
       "                1.6914e-01  3.5850e-01  3.5619e-01\n",
       "                4.5454e-02 -4.2966e-02  6.4973e-02\n",
       "               -8.1751e-02 -4.7558e-01 -7.2767e-02\n",
       "              \n",
       "              (127,62 , 1 ,.,.) = \n",
       "                1.4163e-01  2.3681e-01  4.8215e-01\n",
       "               -2.9438e-01 -3.9905e-01 -2.1868e-01\n",
       "               -1.2011e-01 -8.5007e-02 -5.1503e-02\n",
       "              \n",
       "              (127,62 , 2 ,.,.) = \n",
       "               -3.1790e-02 -2.9990e-02  1.8606e-01\n",
       "                7.5403e-02  1.6748e-02 -5.7975e-02\n",
       "                2.6767e-02 -8.1193e-02 -4.4388e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (127,63 , 0 ,.,.) = \n",
       "               -4.8651e-01  5.3172e-01  6.7233e-01\n",
       "                2.1561e-01  7.2400e-01  2.2960e-01\n",
       "                1.5135e-01 -1.3338e-01 -5.3873e-01\n",
       "              \n",
       "              (127,63 , 1 ,.,.) = \n",
       "                7.2441e-02  1.0228e+00  1.0280e+00\n",
       "                9.7413e-01  1.6398e+00  1.1447e+00\n",
       "                7.6555e-01  1.0108e+00  4.8980e-01\n",
       "              \n",
       "              (127,63 , 2 ,.,.) = \n",
       "               -1.5067e-01  9.6975e-01  1.0654e+00\n",
       "                5.1469e-01  1.0721e+00  1.0011e+00\n",
       "                4.5066e-01  6.1688e-01  2.1991e-01\n",
       "              [torch.cuda.FloatTensor of size 128x64x3x3x3 (GPU 0)]),\n",
       "             ('conv3.batchnorm.weight', \n",
       "               0.5229\n",
       "               0.8730\n",
       "               1.5982\n",
       "               0.7144\n",
       "               0.9874\n",
       "               0.8126\n",
       "               0.8586\n",
       "               0.9523\n",
       "               0.8025\n",
       "               1.0135\n",
       "               0.8702\n",
       "               1.2142\n",
       "               0.8147\n",
       "               0.8493\n",
       "               0.9419\n",
       "               1.2327\n",
       "               0.8929\n",
       "               0.8275\n",
       "               1.6231\n",
       "               1.0650\n",
       "               1.2191\n",
       "               0.9366\n",
       "               0.8350\n",
       "               0.8080\n",
       "               1.1469\n",
       "               0.9748\n",
       "               0.5668\n",
       "               1.0772\n",
       "               0.9349\n",
       "               0.6532\n",
       "               1.0093\n",
       "               0.8144\n",
       "               0.6858\n",
       "               1.3372\n",
       "               0.7450\n",
       "               1.6370\n",
       "               1.0241\n",
       "               0.9343\n",
       "               1.1958\n",
       "               0.8898\n",
       "               0.7548\n",
       "               1.6268\n",
       "               0.6536\n",
       "               0.6245\n",
       "               1.4092\n",
       "               0.7997\n",
       "               0.9297\n",
       "               0.9780\n",
       "               0.8944\n",
       "               1.0457\n",
       "               0.9184\n",
       "               1.3527\n",
       "               0.6431\n",
       "               0.7225\n",
       "               1.0125\n",
       "               1.0076\n",
       "               0.8727\n",
       "               0.8047\n",
       "               0.7284\n",
       "               1.0285\n",
       "               1.2518\n",
       "               0.7932\n",
       "               1.0442\n",
       "               0.7816\n",
       "               0.9061\n",
       "               1.0566\n",
       "               1.5765\n",
       "               0.3837\n",
       "               1.0634\n",
       "               1.2014\n",
       "               0.7308\n",
       "               0.7904\n",
       "               1.2326\n",
       "               0.8475\n",
       "               1.2668\n",
       "               0.9684\n",
       "               0.9201\n",
       "               0.5438\n",
       "               0.6760\n",
       "               0.3659\n",
       "               1.0525\n",
       "               1.4376\n",
       "               0.4948\n",
       "               0.6225\n",
       "               0.8996\n",
       "               0.8806\n",
       "               1.4919\n",
       "               0.7610\n",
       "               0.7054\n",
       "               0.8307\n",
       "               1.8673\n",
       "               0.7572\n",
       "               1.0650\n",
       "               0.6278\n",
       "               0.8488\n",
       "               1.0320\n",
       "               0.9647\n",
       "               0.8717\n",
       "               0.6939\n",
       "               0.9612\n",
       "               0.7415\n",
       "               0.8221\n",
       "               0.7642\n",
       "               0.7901\n",
       "               0.8788\n",
       "               0.6610\n",
       "               0.8702\n",
       "               1.0746\n",
       "               0.7330\n",
       "               1.0519\n",
       "               1.2522\n",
       "               0.8654\n",
       "               0.7280\n",
       "               1.1871\n",
       "               0.7795\n",
       "               0.7869\n",
       "               0.9745\n",
       "               1.2744\n",
       "               0.9317\n",
       "               0.8825\n",
       "               0.6328\n",
       "               0.4363\n",
       "               0.7444\n",
       "               0.8786\n",
       "               0.7129\n",
       "               0.9186\n",
       "               0.7629\n",
       "               0.7352\n",
       "              [torch.cuda.FloatTensor of size 128 (GPU 0)]),\n",
       "             ('conv3.batchnorm.bias', \n",
       "              -0.0518\n",
       "              -0.3410\n",
       "              -0.6175\n",
       "              -0.2939\n",
       "              -0.3281\n",
       "              -0.8316\n",
       "              -0.3989\n",
       "              -0.6774\n",
       "              -0.2814\n",
       "              -0.5281\n",
       "              -0.3809\n",
       "              -0.6483\n",
       "              -0.7980\n",
       "              -0.6293\n",
       "              -0.6903\n",
       "              -0.2603\n",
       "              -0.7458\n",
       "              -0.0676\n",
       "              -0.4935\n",
       "              -0.5052\n",
       "              -0.5495\n",
       "              -0.4181\n",
       "              -0.4943\n",
       "              -1.1249\n",
       "              -0.8831\n",
       "              -0.5578\n",
       "               0.1963\n",
       "              -0.2887\n",
       "              -0.6291\n",
       "              -0.4267\n",
       "              -0.6190\n",
       "              -0.4828\n",
       "              -0.4549\n",
       "              -0.6209\n",
       "              -0.6610\n",
       "              -0.5545\n",
       "              -0.4268\n",
       "              -0.4069\n",
       "              -0.7242\n",
       "              -0.4804\n",
       "              -0.3066\n",
       "              -0.5714\n",
       "              -0.4271\n",
       "              -0.1701\n",
       "              -0.3574\n",
       "              -0.2606\n",
       "              -0.3065\n",
       "              -0.8135\n",
       "              -0.2141\n",
       "              -0.3007\n",
       "              -0.1357\n",
       "              -0.6548\n",
       "              -0.0577\n",
       "              -0.5343\n",
       "              -0.7512\n",
       "              -0.5316\n",
       "              -0.2754\n",
       "              -0.5416\n",
       "              -0.5376\n",
       "              -0.6245\n",
       "              -0.7365\n",
       "              -0.8549\n",
       "              -0.2009\n",
       "              -0.5577\n",
       "              -0.5919\n",
       "              -0.7982\n",
       "              -0.7073\n",
       "               0.2490\n",
       "              -0.7010\n",
       "              -0.4120\n",
       "              -0.1242\n",
       "              -0.4943\n",
       "              -0.4133\n",
       "              -0.5249\n",
       "              -0.5628\n",
       "              -0.4045\n",
       "              -0.4580\n",
       "              -0.1311\n",
       "              -0.4537\n",
       "               0.0083\n",
       "              -0.3197\n",
       "              -0.4513\n",
       "               0.3310\n",
       "              -0.4415\n",
       "              -0.4912\n",
       "              -0.5396\n",
       "              -0.4425\n",
       "              -0.5985\n",
       "              -0.8544\n",
       "              -0.2582\n",
       "              -0.6004\n",
       "              -0.7610\n",
       "              -0.3362\n",
       "              -0.2532\n",
       "              -0.7072\n",
       "              -0.5132\n",
       "              -0.6175\n",
       "              -0.2431\n",
       "               0.0972\n",
       "              -0.6582\n",
       "              -0.6454\n",
       "              -0.7832\n",
       "              -0.4075\n",
       "              -0.5707\n",
       "              -0.6665\n",
       "              -0.3125\n",
       "              -0.6942\n",
       "              -0.6801\n",
       "              -0.5182\n",
       "              -0.2963\n",
       "              -0.5816\n",
       "              -0.6370\n",
       "              -0.3243\n",
       "               0.1590\n",
       "              -0.4572\n",
       "              -0.2439\n",
       "              -0.4217\n",
       "              -0.3585\n",
       "              -0.4929\n",
       "              -0.7970\n",
       "              -0.1226\n",
       "               0.1185\n",
       "              -0.1222\n",
       "              -0.3755\n",
       "              -0.1537\n",
       "              -0.6584\n",
       "              -0.4337\n",
       "              -0.6376\n",
       "              [torch.cuda.FloatTensor of size 128 (GPU 0)]),\n",
       "             ('conv3.batchnorm.running_mean', \n",
       "               -7.5642\n",
       "              -38.8206\n",
       "              -32.5019\n",
       "               -8.8417\n",
       "              -27.5892\n",
       "               11.4531\n",
       "              -40.3879\n",
       "              -17.6857\n",
       "              -37.7742\n",
       "              -15.6772\n",
       "              -34.8334\n",
       "              -37.9934\n",
       "               32.2404\n",
       "               -7.7539\n",
       "              -11.8099\n",
       "              -18.9263\n",
       "               -8.7586\n",
       "              -24.6021\n",
       "              -20.5811\n",
       "               -7.7816\n",
       "              -29.8485\n",
       "              -10.5923\n",
       "               -2.1406\n",
       "               58.4860\n",
       "              -16.2740\n",
       "                7.0661\n",
       "              -64.4779\n",
       "              -34.7292\n",
       "              -20.2899\n",
       "              -12.8042\n",
       "              -28.4659\n",
       "               -9.2616\n",
       "              -19.5285\n",
       "              -13.5375\n",
       "               -1.9714\n",
       "              -14.1488\n",
       "              -31.3960\n",
       "              -19.8678\n",
       "              -17.8887\n",
       "              -28.4990\n",
       "              -11.9031\n",
       "              -12.9660\n",
       "               -8.9834\n",
       "              -22.5509\n",
       "              -24.2534\n",
       "              -29.0939\n",
       "              -23.7747\n",
       "              -17.6842\n",
       "              -15.1733\n",
       "                0.2306\n",
       "              -36.6264\n",
       "              -25.2709\n",
       "              -36.5941\n",
       "              -14.5026\n",
       "              -11.6569\n",
       "              -17.7429\n",
       "              -49.1906\n",
       "              -26.9935\n",
       "               -5.3850\n",
       "              -34.6161\n",
       "               -1.1498\n",
       "                3.5120\n",
       "              -24.0839\n",
       "              -18.2103\n",
       "               -6.8257\n",
       "              -14.6361\n",
       "              -19.9177\n",
       "                2.8460\n",
       "               -8.9369\n",
       "              -27.6378\n",
       "              -37.2960\n",
       "              -33.1697\n",
       "              -13.7278\n",
       "              -19.7942\n",
       "               -9.3979\n",
       "              -22.4231\n",
       "              -39.4692\n",
       "              -40.7515\n",
       "              -25.1522\n",
       "              -22.5478\n",
       "              -13.6022\n",
       "              -26.6925\n",
       "              -17.9488\n",
       "              -24.6595\n",
       "              -18.1755\n",
       "              -29.1472\n",
       "               -3.3977\n",
       "              -21.1342\n",
       "               34.3791\n",
       "              -15.1641\n",
       "              -14.8491\n",
       "              -63.5823\n",
       "              -25.0833\n",
       "              -15.6006\n",
       "              -10.3969\n",
       "              -14.9584\n",
       "              -15.7246\n",
       "              -15.1487\n",
       "                4.9444\n",
       "              -50.4412\n",
       "              -22.0741\n",
       "              -24.6900\n",
       "               -7.2917\n",
       "              -43.4161\n",
       "               -7.2203\n",
       "              -29.8290\n",
       "               -5.4336\n",
       "               -1.3958\n",
       "               -2.0028\n",
       "              -13.8313\n",
       "               -8.9787\n",
       "              -16.1786\n",
       "               -2.8906\n",
       "              -29.1380\n",
       "              -16.3865\n",
       "              -17.6897\n",
       "              -35.3374\n",
       "              -12.9691\n",
       "              -20.6262\n",
       "              -20.4487\n",
       "              -29.2066\n",
       "               -9.3441\n",
       "                1.4844\n",
       "              -13.4771\n",
       "              -26.0386\n",
       "              -20.4441\n",
       "              -21.9285\n",
       "               -3.8805\n",
       "              [torch.cuda.FloatTensor of size 128 (GPU 0)]),\n",
       "             ('conv3.batchnorm.running_var', \n",
       "                505.5920\n",
       "                987.5056\n",
       "                739.9285\n",
       "                521.2904\n",
       "                994.1960\n",
       "                522.8428\n",
       "               1482.4680\n",
       "                575.4823\n",
       "               1099.7394\n",
       "                886.6329\n",
       "               1224.9918\n",
       "                546.5513\n",
       "                323.6771\n",
       "                359.4384\n",
       "                432.2529\n",
       "                603.4612\n",
       "                332.2287\n",
       "                512.6277\n",
       "               1315.8118\n",
       "                498.5668\n",
       "                712.5997\n",
       "                547.9933\n",
       "                715.2573\n",
       "                498.8522\n",
       "                548.0159\n",
       "                641.5605\n",
       "               1148.7081\n",
       "                955.0954\n",
       "                330.6011\n",
       "                299.2403\n",
       "                632.3590\n",
       "                480.5991\n",
       "               1257.9135\n",
       "                660.9293\n",
       "                541.9479\n",
       "                529.3093\n",
       "               1144.4601\n",
       "               1046.5046\n",
       "                343.8174\n",
       "                686.1405\n",
       "                436.2061\n",
       "                631.3484\n",
       "                856.8494\n",
       "                589.4847\n",
       "               1110.3386\n",
       "               1279.5557\n",
       "                674.1973\n",
       "                285.0065\n",
       "                479.8976\n",
       "                423.7509\n",
       "               1097.0680\n",
       "                693.7073\n",
       "               1472.9056\n",
       "                314.5117\n",
       "                754.6209\n",
       "                424.7329\n",
       "               1642.6458\n",
       "                554.0228\n",
       "                245.4383\n",
       "                504.4009\n",
       "                465.9758\n",
       "                451.9803\n",
       "               1093.7025\n",
       "                362.1875\n",
       "                566.4360\n",
       "                547.6505\n",
       "                669.6398\n",
       "               1246.9088\n",
       "                661.0374\n",
       "                614.6485\n",
       "               1954.4941\n",
       "               1309.1941\n",
       "                478.8317\n",
       "                655.6900\n",
       "                378.1988\n",
       "                786.0670\n",
       "                855.7893\n",
       "               1965.5300\n",
       "                755.5279\n",
       "                915.7240\n",
       "                614.0555\n",
       "               1384.5977\n",
       "               1048.6973\n",
       "                767.8669\n",
       "                457.4915\n",
       "                615.2731\n",
       "                386.0503\n",
       "                442.5357\n",
       "                373.8402\n",
       "                729.4284\n",
       "                797.2063\n",
       "                666.3073\n",
       "                621.8661\n",
       "                677.2295\n",
       "                415.5580\n",
       "                583.6381\n",
       "                488.7183\n",
       "                622.5368\n",
       "                550.5446\n",
       "                681.9307\n",
       "                742.7769\n",
       "                481.4999\n",
       "                457.5820\n",
       "               1004.8578\n",
       "                489.8458\n",
       "                836.2946\n",
       "                591.0248\n",
       "                605.9395\n",
       "                440.4319\n",
       "                590.7300\n",
       "                478.9418\n",
       "                348.8436\n",
       "                442.2927\n",
       "               1207.0793\n",
       "                529.1614\n",
       "                811.8061\n",
       "                897.2447\n",
       "                636.4717\n",
       "                742.3406\n",
       "                409.5887\n",
       "               1231.6263\n",
       "                775.4177\n",
       "                302.6289\n",
       "                613.9775\n",
       "               1589.7496\n",
       "                680.6823\n",
       "                861.1116\n",
       "                396.7705\n",
       "              [torch.cuda.FloatTensor of size 128 (GPU 0)]),\n",
       "             ('conv4.conv.weight', \n",
       "              ( 0 , 0 , 0 ,.,.) = \n",
       "                1.0257e-01 -1.0106e-02 -5.3457e-02\n",
       "               -4.0800e-02 -2.3509e-01 -3.4279e-01\n",
       "                2.7269e-01 -2.6971e-01 -2.9411e-01\n",
       "              \n",
       "              ( 0 , 0 , 1 ,.,.) = \n",
       "               -2.6000e-01 -3.4905e-01 -2.2362e-01\n",
       "               -2.3539e-01 -4.8891e-01 -2.5500e-01\n",
       "                2.2825e-01 -1.5895e-01  9.1351e-02\n",
       "              \n",
       "              ( 0 , 0 , 2 ,.,.) = \n",
       "               -4.3847e-02 -9.8893e-02 -2.5953e-01\n",
       "                7.7700e-02 -1.4176e-01 -2.4951e-01\n",
       "                4.9156e-01  8.7626e-02 -1.7377e-02\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 0 , 1 , 0 ,.,.) = \n",
       "                2.2571e-01  5.0850e-02  4.0252e-01\n",
       "                2.1862e-01 -7.9211e-01 -1.8617e-01\n",
       "                3.8142e-01 -5.9451e-01 -2.5373e-01\n",
       "              \n",
       "              ( 0 , 1 , 1 ,.,.) = \n",
       "                4.0003e-01  2.5102e-01  5.4081e-01\n",
       "                2.2112e-01 -6.1228e-01  3.0687e-02\n",
       "                4.8338e-01 -6.1321e-01 -2.0874e-01\n",
       "              \n",
       "              ( 0 , 1 , 2 ,.,.) = \n",
       "                4.0809e-01  5.1816e-01  5.9774e-01\n",
       "                2.8866e-01 -9.0975e-02  1.8423e-01\n",
       "                4.1667e-01 -2.5094e-01 -3.0930e-02\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 0 , 2 , 0 ,.,.) = \n",
       "                6.2708e-01  3.4740e-01 -2.2166e-02\n",
       "                5.8681e-01  2.4542e-01 -3.1780e-01\n",
       "                8.4839e-01  4.2289e-01  2.5225e-02\n",
       "              \n",
       "              ( 0 , 2 , 1 ,.,.) = \n",
       "                6.2052e-01  1.3405e-01 -9.1568e-02\n",
       "                6.3468e-01  1.7406e-01 -4.2404e-01\n",
       "                1.0331e+00  5.9395e-01 -2.2079e-02\n",
       "              \n",
       "              ( 0 , 2 , 2 ,.,.) = \n",
       "                2.8587e-01 -2.9680e-01 -6.3680e-01\n",
       "                4.5070e-01 -1.6465e-01 -8.1114e-01\n",
       "                9.7503e-01  2.4865e-01 -3.1758e-01\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              ( 0 ,125, 0 ,.,.) = \n",
       "               -4.4181e-01 -4.4498e-01  3.6864e-02\n",
       "               -3.3362e-01 -5.3252e-01  9.4189e-02\n",
       "                1.0677e-01  2.4275e-01  4.9146e-01\n",
       "              \n",
       "              ( 0 ,125, 1 ,.,.) = \n",
       "               -5.2477e-01 -4.4887e-01  2.4849e-01\n",
       "               -4.7003e-01 -6.4733e-01  1.0129e-01\n",
       "               -1.6609e-01 -3.3345e-01  2.2214e-01\n",
       "              \n",
       "              ( 0 ,125, 2 ,.,.) = \n",
       "               -4.5661e-01 -5.6944e-01 -8.5537e-04\n",
       "               -4.8267e-01 -9.0590e-01 -1.0856e-01\n",
       "               -1.4210e-01 -4.2000e-01  1.1318e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 0 ,126, 0 ,.,.) = \n",
       "               -2.2911e-01 -1.5856e-01 -3.4021e-02\n",
       "               -5.3079e-01 -3.1863e-01  8.7770e-02\n",
       "               -8.4039e-01 -5.3625e-01 -3.0515e-01\n",
       "              \n",
       "              ( 0 ,126, 1 ,.,.) = \n",
       "               -3.6677e-01 -1.9899e-01 -6.5070e-02\n",
       "               -5.1006e-01 -3.3677e-01  6.6034e-02\n",
       "               -7.9401e-01 -6.7337e-01 -3.8334e-01\n",
       "              \n",
       "              ( 0 ,126, 2 ,.,.) = \n",
       "               -2.7979e-01 -3.0729e-02 -1.2158e-01\n",
       "               -2.5067e-01 -5.8348e-02  1.8045e-02\n",
       "               -5.1708e-01 -2.8207e-01 -4.3482e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 0 ,127, 0 ,.,.) = \n",
       "               -2.5434e-01 -2.3045e-01  3.8301e-01\n",
       "                3.5384e-01  1.5805e-01  1.6865e-01\n",
       "                5.3673e-01  1.4406e-01  8.5173e-02\n",
       "              \n",
       "              ( 0 ,127, 1 ,.,.) = \n",
       "               -8.1590e-01 -8.9009e-01 -3.8217e-02\n",
       "               -1.8820e-01 -3.6058e-01 -1.1427e-01\n",
       "               -6.4042e-03 -5.0832e-01 -1.9795e-01\n",
       "              \n",
       "              ( 0 ,127, 2 ,.,.) = \n",
       "               -6.7619e-01 -9.2337e-01 -1.9417e-01\n",
       "                1.5484e-01 -3.9688e-02 -4.0036e-02\n",
       "                1.7291e-01 -2.7276e-01 -6.0357e-02\n",
       "                    â‹®   â‹®  \n",
       "              \n",
       "              ( 1 , 0 , 0 ,.,.) = \n",
       "                6.0669e-02  3.0504e-01  1.1826e-01\n",
       "                2.7416e-01  1.5779e-01 -5.7012e-02\n",
       "                3.0937e-01 -2.0733e-01 -2.3178e-01\n",
       "              \n",
       "              ( 1 , 0 , 1 ,.,.) = \n",
       "               -1.9146e-01 -6.9632e-02 -1.3457e-01\n",
       "               -2.6921e-01 -2.2256e-01 -3.5685e-01\n",
       "               -2.6559e-01 -6.6410e-01 -6.2915e-01\n",
       "              \n",
       "              ( 1 , 0 , 2 ,.,.) = \n",
       "                2.8294e-01  3.8040e-01  4.1949e-01\n",
       "               -4.6545e-02 -2.2794e-02  1.8631e-01\n",
       "                3.0838e-01  8.9816e-02  2.0936e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 1 , 1 , 0 ,.,.) = \n",
       "                2.1031e-02 -4.3732e-01 -5.4712e-01\n",
       "                4.1175e-01  1.0152e-01  5.7903e-02\n",
       "                3.8216e-01  8.6641e-02 -1.3127e-01\n",
       "              \n",
       "              ( 1 , 1 , 1 ,.,.) = \n",
       "                1.2525e-01 -1.2739e-01 -1.9672e-01\n",
       "                4.9227e-01  3.8366e-01  2.0426e-01\n",
       "                3.8004e-01  3.6152e-01 -3.7334e-02\n",
       "              \n",
       "              ( 1 , 1 , 2 ,.,.) = \n",
       "                1.8084e-01 -9.1431e-02 -5.1476e-02\n",
       "                5.7820e-01  5.3247e-01  4.0339e-01\n",
       "                4.1480e-01  4.2422e-01 -4.6693e-02\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 1 , 2 , 0 ,.,.) = \n",
       "               -6.7268e-01 -6.5588e-01 -8.1896e-01\n",
       "               -4.9816e-01 -4.8593e-01 -9.0471e-01\n",
       "               -7.7449e-01 -5.4912e-01 -7.5867e-01\n",
       "              \n",
       "              ( 1 , 2 , 1 ,.,.) = \n",
       "               -8.7560e-01 -8.3804e-01 -9.5365e-01\n",
       "               -7.4262e-01 -7.7836e-01 -9.4128e-01\n",
       "               -1.1686e+00 -8.6451e-01 -1.1165e+00\n",
       "              \n",
       "              ( 1 , 2 , 2 ,.,.) = \n",
       "               -8.2345e-01 -7.3125e-01 -6.9826e-01\n",
       "               -5.9329e-01 -5.5433e-01 -6.5755e-01\n",
       "               -9.3323e-01 -7.5334e-01 -8.3518e-01\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              ( 1 ,125, 0 ,.,.) = \n",
       "                4.8928e-01 -1.9335e-01  4.2142e-02\n",
       "                2.8987e-01 -4.6747e-01 -2.0947e-01\n",
       "                4.9298e-01 -1.9812e-01 -6.2171e-01\n",
       "              \n",
       "              ( 1 ,125, 1 ,.,.) = \n",
       "                2.0653e-01 -3.0871e-01  1.7709e-01\n",
       "               -1.1508e-01 -4.0879e-01 -6.4340e-02\n",
       "                1.5195e-01 -2.5504e-01 -4.4553e-01\n",
       "              \n",
       "              ( 1 ,125, 2 ,.,.) = \n",
       "                2.3748e-01 -1.6564e-01  3.0407e-01\n",
       "                6.4661e-03 -2.2555e-01 -4.5032e-02\n",
       "                3.2066e-01 -1.6206e-01 -4.6346e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 1 ,126, 0 ,.,.) = \n",
       "                4.2803e-02 -2.3501e-01 -3.0303e-01\n",
       "                4.3200e-02 -3.6184e-01 -5.1269e-01\n",
       "               -2.7025e-01 -5.2016e-01 -4.5644e-01\n",
       "              \n",
       "              ( 1 ,126, 1 ,.,.) = \n",
       "               -1.4097e-01 -2.1977e-01 -3.9335e-01\n",
       "               -1.0938e-01 -2.2153e-01 -4.5583e-01\n",
       "               -3.2155e-01 -3.3288e-01 -4.4962e-01\n",
       "              \n",
       "              ( 1 ,126, 2 ,.,.) = \n",
       "               -2.3019e-01 -4.8277e-01 -7.3766e-01\n",
       "               -1.7858e-01 -4.6407e-01 -7.7920e-01\n",
       "               -4.2146e-01 -4.6323e-01 -7.0871e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 1 ,127, 0 ,.,.) = \n",
       "                2.2445e-02 -3.2622e-01 -5.8290e-01\n",
       "                1.6500e-01  4.5413e-01  4.2112e-01\n",
       "                2.0120e-02  3.9154e-01  5.0134e-01\n",
       "              \n",
       "              ( 1 ,127, 1 ,.,.) = \n",
       "                2.5440e-02 -3.0395e-01 -6.1630e-01\n",
       "                2.9203e-01  5.4482e-01  5.2371e-01\n",
       "                2.1410e-01  4.5565e-01  5.5956e-01\n",
       "              \n",
       "              ( 1 ,127, 2 ,.,.) = \n",
       "                2.4224e-02 -4.3618e-01 -7.2621e-01\n",
       "                8.7262e-02  2.4537e-01  2.9208e-01\n",
       "                1.4297e-01  2.5042e-01  3.4242e-01\n",
       "                    â‹®   â‹®  \n",
       "              \n",
       "              ( 2 , 0 , 0 ,.,.) = \n",
       "                4.5054e-02  1.0804e-01 -2.9271e-01\n",
       "                2.0017e-01  2.7321e-01 -1.2668e-01\n",
       "               -4.4010e-01 -2.2495e-02 -1.7902e-01\n",
       "              \n",
       "              ( 2 , 0 , 1 ,.,.) = \n",
       "               -6.7382e-02  2.6952e-02 -2.8721e-02\n",
       "               -2.2089e-01 -1.9805e-01 -1.5269e-01\n",
       "               -8.5877e-01 -6.2707e-01 -5.1218e-01\n",
       "              \n",
       "              ( 2 , 0 , 2 ,.,.) = \n",
       "                2.8898e-03  1.0578e-01  1.8053e-01\n",
       "               -2.5678e-01 -2.9745e-01 -2.0884e-01\n",
       "               -6.2289e-01 -6.2913e-01 -5.1134e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 2 , 1 , 0 ,.,.) = \n",
       "                7.7608e-01  6.5342e-01  3.7529e-01\n",
       "                4.5402e-01  5.5674e-01 -3.2582e-01\n",
       "                5.7578e-01  5.2711e-01 -6.9127e-01\n",
       "              \n",
       "              ( 2 , 1 , 1 ,.,.) = \n",
       "                6.4236e-01  6.6799e-01  4.1973e-01\n",
       "                3.1249e-01  4.0502e-01 -5.7344e-01\n",
       "                4.4181e-01  2.4308e-01 -1.0684e+00\n",
       "              \n",
       "              ( 2 , 1 , 2 ,.,.) = \n",
       "                5.2032e-01  5.6504e-01  4.3933e-01\n",
       "                2.3428e-01 -1.0651e-01 -8.8954e-01\n",
       "                2.5531e-01 -3.2436e-02 -1.3908e+00\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 2 , 2 , 0 ,.,.) = \n",
       "               -5.5508e-02 -4.6428e-02 -4.1101e-01\n",
       "                4.1500e-01  4.0341e-01  4.0167e-02\n",
       "                7.0384e-01  5.4254e-01 -1.6517e-01\n",
       "              \n",
       "              ( 2 , 2 , 1 ,.,.) = \n",
       "               -1.0322e-01 -1.2585e-01 -4.1764e-01\n",
       "                6.0896e-01  5.0123e-01 -3.0994e-02\n",
       "                7.5710e-01  6.4631e-01  8.1221e-02\n",
       "              \n",
       "              ( 2 , 2 , 2 ,.,.) = \n",
       "                1.1943e-01  1.9208e-01  6.0751e-02\n",
       "                5.7431e-01  6.0836e-01  2.5469e-01\n",
       "                8.3508e-01  6.1674e-01  1.0343e-01\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              ( 2 ,125, 0 ,.,.) = \n",
       "                8.2873e-02  4.7409e-02 -3.1905e-03\n",
       "                2.6291e-01  2.6989e-01  3.5485e-01\n",
       "               -5.3914e-02  3.9698e-01  6.2977e-01\n",
       "              \n",
       "              ( 2 ,125, 1 ,.,.) = \n",
       "                2.6169e-01  4.0732e-01  1.2062e-01\n",
       "                4.3300e-01  6.7311e-01  6.1355e-01\n",
       "               -3.1532e-02  5.4822e-01  6.0721e-01\n",
       "              \n",
       "              ( 2 ,125, 2 ,.,.) = \n",
       "                6.6055e-01  7.6777e-01  3.2398e-01\n",
       "                5.5883e-01  7.7528e-01  5.9572e-01\n",
       "               -1.1848e-01  3.3383e-01  2.9464e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 2 ,126, 0 ,.,.) = \n",
       "                4.8403e-02 -7.4864e-01  1.4829e-01\n",
       "                4.1241e-01 -3.7691e-01  4.9556e-01\n",
       "                1.0421e+00  5.3265e-01  1.0001e+00\n",
       "              \n",
       "              ( 2 ,126, 1 ,.,.) = \n",
       "                2.2326e-01 -2.3189e-01  4.2972e-01\n",
       "                6.3509e-01  1.2526e-01  7.3086e-01\n",
       "                1.4054e+00  9.8494e-01  1.3575e+00\n",
       "              \n",
       "              ( 2 ,126, 2 ,.,.) = \n",
       "               -1.5517e-01 -4.4086e-01  9.3801e-04\n",
       "                3.1148e-01  2.4301e-02  3.7871e-01\n",
       "                1.0677e+00  9.0122e-01  1.0787e+00\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 2 ,127, 0 ,.,.) = \n",
       "                1.9499e-01  7.5828e-01  4.6682e-01\n",
       "                4.7443e-02  2.7141e-01  1.8174e-01\n",
       "                1.0341e-01  4.7799e-01  7.1049e-01\n",
       "              \n",
       "              ( 2 ,127, 1 ,.,.) = \n",
       "                3.0363e-01  8.6740e-01  5.5265e-01\n",
       "                1.6173e-01  4.6199e-01  3.4705e-01\n",
       "                2.3434e-01  5.4090e-01  6.9117e-01\n",
       "              \n",
       "              ( 2 ,127, 2 ,.,.) = \n",
       "                2.0872e-01  5.7043e-01  2.8055e-01\n",
       "                5.6087e-02  2.1452e-01  7.1793e-02\n",
       "               -3.3717e-02  2.2648e-01  4.0482e-01\n",
       "              ...         \n",
       "                    â‹®   â‹®  \n",
       "              \n",
       "              (253, 0 , 0 ,.,.) = \n",
       "                3.8424e-01 -3.8503e-02 -6.2832e-01\n",
       "                6.3032e-01  4.2249e-01 -2.9626e-02\n",
       "                1.1458e-01  1.4490e-01 -3.1956e-01\n",
       "              \n",
       "              (253, 0 , 1 ,.,.) = \n",
       "                7.5362e-01  4.9767e-01  6.7967e-02\n",
       "                6.9613e-01  6.4560e-01  2.3531e-01\n",
       "                2.2803e-01  3.1982e-01 -1.3606e-01\n",
       "              \n",
       "              (253, 0 , 2 ,.,.) = \n",
       "                1.5997e-01  1.4532e-01 -2.4816e-01\n",
       "                6.1094e-02  4.8258e-03 -2.6896e-01\n",
       "               -1.3299e-01 -1.7784e-01 -6.2130e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (253, 1 , 0 ,.,.) = \n",
       "               -8.4939e-03  4.3995e-01  5.2928e-01\n",
       "               -1.7655e-01  5.5191e-01  6.7095e-01\n",
       "               -8.8594e-02  6.9706e-01  7.3333e-01\n",
       "              \n",
       "              (253, 1 , 1 ,.,.) = \n",
       "               -1.3636e-01  4.6145e-01  3.6708e-01\n",
       "               -2.1573e-01  3.2333e-01  3.9552e-01\n",
       "               -9.1211e-02  4.8077e-01  4.6471e-01\n",
       "              \n",
       "              (253, 1 , 2 ,.,.) = \n",
       "               -1.2176e-01  4.6450e-01  3.3375e-01\n",
       "               -1.7056e-01  5.8327e-01  4.4250e-01\n",
       "                1.2207e-01  9.0447e-01  6.1840e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (253, 2 , 0 ,.,.) = \n",
       "                6.6871e-01  4.0176e-01 -1.2862e-01\n",
       "                3.4239e-01  2.0020e-01 -2.8738e-01\n",
       "                1.1113e-01  1.6762e-01 -3.6005e-01\n",
       "              \n",
       "              (253, 2 , 1 ,.,.) = \n",
       "                9.2619e-01  6.7952e-01  2.4690e-01\n",
       "                6.4596e-01  6.0446e-01  8.8072e-02\n",
       "                3.6147e-01  4.7181e-01 -5.1597e-02\n",
       "              \n",
       "              (253, 2 , 2 ,.,.) = \n",
       "                1.1476e+00  9.6214e-01  3.5806e-01\n",
       "                8.1307e-01  8.3304e-01  3.1386e-01\n",
       "                4.6065e-01  5.1310e-01  2.3410e-03\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              (253,125, 0 ,.,.) = \n",
       "               -2.5463e-01  6.0226e-02  7.0083e-01\n",
       "               -2.0622e-01  8.1847e-03  6.7993e-01\n",
       "                3.6759e-01  2.2651e-01  4.7265e-01\n",
       "              \n",
       "              (253,125, 1 ,.,.) = \n",
       "               -2.3717e-01  5.7476e-02  7.4590e-01\n",
       "               -2.2710e-01 -1.0185e-01  6.2199e-01\n",
       "                1.2473e-01  1.3453e-01  6.0066e-01\n",
       "              \n",
       "              (253,125, 2 ,.,.) = \n",
       "               -5.0204e-01 -1.6933e-01  6.0271e-01\n",
       "               -4.7994e-01 -2.4883e-01  6.2266e-01\n",
       "               -4.9381e-02  6.8955e-03  6.9407e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (253,126, 0 ,.,.) = \n",
       "                2.3346e-01 -1.5935e-01 -7.2934e-01\n",
       "               -3.1681e-01 -3.0893e-01 -8.3320e-01\n",
       "               -6.1107e-01 -5.2930e-01 -6.7258e-01\n",
       "              \n",
       "              (253,126, 1 ,.,.) = \n",
       "                1.0067e-01 -1.9078e-01 -6.8111e-01\n",
       "               -3.2679e-01 -3.0165e-01 -8.7837e-01\n",
       "               -4.9812e-01 -5.2621e-01 -5.9453e-01\n",
       "              \n",
       "              (253,126, 2 ,.,.) = \n",
       "                3.6236e-02 -1.6529e-01 -5.0078e-01\n",
       "               -4.3101e-01 -2.9320e-01 -7.1943e-01\n",
       "               -6.1827e-01 -3.9296e-01 -4.7443e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (253,127, 0 ,.,.) = \n",
       "               -3.0237e-01 -6.1238e-02  4.8420e-01\n",
       "               -1.7051e-01 -2.9994e-01  4.4896e-01\n",
       "                1.2636e-01  2.7292e-02  3.1400e-01\n",
       "              \n",
       "              (253,127, 1 ,.,.) = \n",
       "               -4.5974e-01 -9.5012e-02  4.8591e-01\n",
       "               -5.1102e-01 -5.4043e-01  1.9336e-01\n",
       "               -4.0828e-01 -4.9975e-01  3.9836e-02\n",
       "              \n",
       "              (253,127, 2 ,.,.) = \n",
       "               -4.6533e-01 -8.6183e-02  4.3314e-01\n",
       "               -5.3479e-01 -5.6161e-01 -1.7049e-02\n",
       "               -4.8989e-01 -6.1778e-01 -2.4271e-01\n",
       "                    â‹®   â‹®  \n",
       "              \n",
       "              (254, 0 , 0 ,.,.) = \n",
       "               -1.9598e-01  1.2635e-01 -9.8659e-02\n",
       "                2.0206e-01  7.4183e-01  5.2177e-01\n",
       "                3.6355e-01  5.9801e-01  6.0642e-01\n",
       "              \n",
       "              (254, 0 , 1 ,.,.) = \n",
       "               -5.3061e-01 -3.1955e-01 -4.3295e-01\n",
       "               -1.8674e-01  3.1988e-01  2.3078e-01\n",
       "                1.3963e-01  2.5518e-01  4.0330e-01\n",
       "              \n",
       "              (254, 0 , 2 ,.,.) = \n",
       "               -4.8770e-01 -4.0581e-01 -3.9656e-01\n",
       "               -1.6367e-01  2.1896e-01  3.5902e-01\n",
       "                5.5953e-02  2.8267e-01  3.6299e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (254, 1 , 0 ,.,.) = \n",
       "                7.6960e-01  5.1694e-01  3.8610e-01\n",
       "                6.8349e-01 -2.3471e-01 -7.8279e-02\n",
       "                6.3188e-01 -6.7573e-01 -1.1841e-01\n",
       "              \n",
       "              (254, 1 , 1 ,.,.) = \n",
       "                8.4729e-01  6.0636e-01  4.6604e-01\n",
       "                7.3598e-01 -4.7134e-02  1.4407e-01\n",
       "                7.2455e-01 -5.2789e-01  8.8167e-02\n",
       "              \n",
       "              (254, 1 , 2 ,.,.) = \n",
       "                6.4488e-01  3.2039e-01  1.9145e-01\n",
       "                5.6680e-01 -5.8951e-01 -2.0049e-01\n",
       "                5.6417e-01 -7.8304e-01 -2.2955e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (254, 2 , 0 ,.,.) = \n",
       "               -4.3108e-01 -3.9339e-01  3.2802e-01\n",
       "               -7.2783e-01 -7.8363e-01 -2.5486e-01\n",
       "               -6.6641e-01 -5.2728e-01  8.7643e-02\n",
       "              \n",
       "              (254, 2 , 1 ,.,.) = \n",
       "               -3.7750e-01 -3.3095e-01  5.2361e-01\n",
       "               -1.0267e+00 -1.0190e+00 -1.0056e-01\n",
       "               -6.1398e-01 -4.6425e-01  2.7695e-01\n",
       "              \n",
       "              (254, 2 , 2 ,.,.) = \n",
       "                2.8871e-01  3.3433e-01  1.1050e+00\n",
       "               -4.0152e-01 -4.1632e-01  3.4132e-01\n",
       "               -2.9094e-01 -1.9336e-01  6.3322e-01\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              (254,125, 0 ,.,.) = \n",
       "                4.1525e-01  3.7086e-01  2.7284e-02\n",
       "               -2.6393e-01 -1.1143e-01 -1.0691e-01\n",
       "                3.1239e-01  6.1802e-01  1.1756e+00\n",
       "              \n",
       "              (254,125, 1 ,.,.) = \n",
       "                6.4821e-01  5.3583e-01  5.0392e-01\n",
       "                1.6928e-01  1.8876e-01  4.5247e-01\n",
       "                7.6374e-01  9.7372e-01  1.5631e+00\n",
       "              \n",
       "              (254,125, 2 ,.,.) = \n",
       "                6.7150e-01  3.9940e-01  5.1454e-01\n",
       "                1.7857e-01  6.2426e-02  3.1666e-01\n",
       "                8.1657e-01  9.5277e-01  1.5369e+00\n",
       "                        â‹®  \n",
       "              \n",
       "              (254,126, 0 ,.,.) = \n",
       "                6.5466e-02  3.5907e-03  5.2152e-01\n",
       "               -1.3392e-01 -1.7623e-01  1.0663e-01\n",
       "                2.4458e-01  6.9371e-02  3.5660e-01\n",
       "              \n",
       "              (254,126, 1 ,.,.) = \n",
       "                4.8431e-01  3.0232e-01  5.8944e-01\n",
       "                1.3202e-01  1.3812e-01  2.1411e-01\n",
       "                5.3334e-01  2.8819e-01  3.6090e-01\n",
       "              \n",
       "              (254,126, 2 ,.,.) = \n",
       "                5.4229e-01  3.5078e-01  3.5816e-01\n",
       "                1.1690e-01  1.3402e-01  5.0860e-02\n",
       "                4.2042e-01  2.2555e-01  1.3322e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (254,127, 0 ,.,.) = \n",
       "               -7.2746e-01 -1.0532e+00 -1.0075e+00\n",
       "               -9.5275e-01 -6.3376e-01 -1.3290e-01\n",
       "               -3.3223e-01  2.2380e-02  1.5332e-01\n",
       "              \n",
       "              (254,127, 1 ,.,.) = \n",
       "               -4.9369e-01 -7.2873e-01 -6.6095e-01\n",
       "               -7.0128e-01 -3.2680e-01  1.5367e-01\n",
       "               -3.6730e-01  8.7279e-02  3.0394e-01\n",
       "              \n",
       "              (254,127, 2 ,.,.) = \n",
       "               -5.1624e-01 -7.6419e-01 -6.5258e-01\n",
       "               -6.7678e-01 -4.2646e-01  1.2203e-01\n",
       "               -3.4850e-01 -4.1546e-02  1.8101e-01\n",
       "                    â‹®   â‹®  \n",
       "              \n",
       "              (255, 0 , 0 ,.,.) = \n",
       "                1.8738e-01  2.4732e-01 -2.2257e-01\n",
       "                1.0479e-01  5.7828e-02 -3.1835e-01\n",
       "               -6.0177e-02 -1.0353e-01 -3.5396e-01\n",
       "              \n",
       "              (255, 0 , 1 ,.,.) = \n",
       "                7.4723e-02  7.3147e-02 -4.9376e-01\n",
       "               -6.3869e-03  4.6963e-02 -5.3604e-01\n",
       "               -1.5091e-01 -2.1391e-01 -4.3648e-01\n",
       "              \n",
       "              (255, 0 , 2 ,.,.) = \n",
       "               -1.1708e-02  1.8334e-01 -3.1861e-01\n",
       "               -6.3751e-03  1.2403e-01 -3.5517e-01\n",
       "               -2.0971e-01 -3.8607e-01 -3.7634e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (255, 1 , 0 ,.,.) = \n",
       "               -2.0064e-01 -3.8530e-01 -9.2880e-01\n",
       "               -3.3985e-02 -5.8372e-01 -7.7461e-01\n",
       "               -1.2174e-01 -5.2754e-01 -3.9141e-01\n",
       "              \n",
       "              (255, 1 , 1 ,.,.) = \n",
       "               -2.3456e-01 -3.6551e-01 -8.2670e-01\n",
       "               -5.7186e-02 -5.4760e-01 -7.4484e-01\n",
       "               -1.4782e-01 -4.9756e-01 -4.4996e-01\n",
       "              \n",
       "              (255, 1 , 2 ,.,.) = \n",
       "               -2.2634e-01 -4.8019e-01 -9.7443e-01\n",
       "               -1.3564e-02 -5.0207e-01 -6.7509e-01\n",
       "               -1.2407e-01 -3.5699e-01 -3.2826e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (255, 2 , 0 ,.,.) = \n",
       "               -5.7774e-01 -6.6955e-01 -8.3986e-02\n",
       "               -4.8582e-01 -7.0560e-01 -3.1458e-01\n",
       "               -6.3822e-02 -1.6037e-01  8.5111e-02\n",
       "              \n",
       "              (255, 2 , 1 ,.,.) = \n",
       "               -2.8363e-01  8.0067e-02  5.5673e-01\n",
       "               -5.4883e-02  1.5685e-01  2.6068e-01\n",
       "                6.5115e-01  5.4218e-01  4.9204e-01\n",
       "              \n",
       "              (255, 2 , 2 ,.,.) = \n",
       "               -2.7782e-01  1.4935e-01  6.0016e-01\n",
       "                1.7450e-01  4.1182e-01  3.5810e-01\n",
       "                6.7669e-01  4.9195e-01  3.0536e-01\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              (255,125, 0 ,.,.) = \n",
       "               -3.7504e-01 -5.4934e-01 -6.7434e-01\n",
       "               -2.6481e-01 -2.2377e-01 -2.5808e-01\n",
       "               -6.0638e-01 -8.0735e-02 -2.7890e-03\n",
       "              \n",
       "              (255,125, 1 ,.,.) = \n",
       "               -3.4524e-01 -2.7650e-01 -2.3143e-01\n",
       "                3.3958e-02  1.1272e-01  1.2978e-01\n",
       "               -3.1733e-01  6.2978e-03  1.5296e-01\n",
       "              \n",
       "              (255,125, 2 ,.,.) = \n",
       "               -2.7288e-01 -6.2945e-01 -6.0049e-01\n",
       "                1.4639e-01  4.9901e-03  8.9209e-02\n",
       "               -4.7558e-01 -1.1448e-01 -8.8284e-02\n",
       "                        â‹®  \n",
       "              \n",
       "              (255,126, 0 ,.,.) = \n",
       "                8.2815e-01  1.0197e+00  9.7091e-01\n",
       "                6.6898e-01  7.3682e-01  8.1821e-01\n",
       "                6.5821e-01  6.9882e-01  7.2758e-01\n",
       "              \n",
       "              (255,126, 1 ,.,.) = \n",
       "                7.0284e-01  8.2651e-01  8.9613e-01\n",
       "                4.9552e-01  3.4793e-01  6.4975e-01\n",
       "                5.5339e-01  4.2450e-01  4.2130e-01\n",
       "              \n",
       "              (255,126, 2 ,.,.) = \n",
       "                5.8135e-01  5.0032e-01  6.0241e-01\n",
       "                3.8761e-01  1.9607e-01  4.8531e-01\n",
       "                5.4955e-01  5.2358e-01  2.7847e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (255,127, 0 ,.,.) = \n",
       "                2.4965e-02  5.2213e-01 -9.9835e-03\n",
       "                1.0128e-01  4.0484e-01  3.4440e-02\n",
       "               -7.7840e-02 -1.9565e-01 -3.6817e-01\n",
       "              \n",
       "              (255,127, 1 ,.,.) = \n",
       "                1.4471e-01  5.1002e-01 -1.1890e-01\n",
       "                2.8774e-01  4.1098e-01 -5.4017e-02\n",
       "                1.1497e-01  9.2319e-03 -2.4952e-01\n",
       "              \n",
       "              (255,127, 2 ,.,.) = \n",
       "               -3.6741e-02  1.0028e-01 -4.8193e-01\n",
       "                5.0348e-02  6.0566e-02 -2.8409e-01\n",
       "               -3.7388e-01 -3.4628e-01 -4.4605e-01\n",
       "              [torch.cuda.FloatTensor of size 256x128x3x3x3 (GPU 0)]),\n",
       "             ('conv4.batchnorm.weight', \n",
       "               1.1261\n",
       "               0.5412\n",
       "               0.9339\n",
       "               0.9077\n",
       "               0.4138\n",
       "               1.1877\n",
       "               0.7570\n",
       "               1.0890\n",
       "               1.0057\n",
       "               0.9417\n",
       "               1.1233\n",
       "               0.6239\n",
       "               1.3504\n",
       "               1.1196\n",
       "               1.5805\n",
       "               1.3314\n",
       "               0.9991\n",
       "               1.4141\n",
       "               1.0211\n",
       "               1.0387\n",
       "               1.1245\n",
       "               0.9077\n",
       "               0.7249\n",
       "               0.6730\n",
       "               1.3285\n",
       "               1.8116\n",
       "               1.2690\n",
       "               0.5603\n",
       "               1.3735\n",
       "               0.7523\n",
       "               0.4838\n",
       "               1.2516\n",
       "               1.1226\n",
       "               0.9201\n",
       "               0.9973\n",
       "               1.0426\n",
       "               0.7079\n",
       "               0.9396\n",
       "               0.9131\n",
       "               1.2568\n",
       "               1.2118\n",
       "               1.0272\n",
       "               0.9976\n",
       "               1.2808\n",
       "               1.3883\n",
       "               0.8978\n",
       "               0.7964\n",
       "               1.4807\n",
       "               0.9035\n",
       "               0.3030\n",
       "               0.8870\n",
       "               1.0370\n",
       "               0.6421\n",
       "               1.0042\n",
       "               0.8838\n",
       "               0.9538\n",
       "               0.5824\n",
       "               1.2403\n",
       "               1.4433\n",
       "               1.0723\n",
       "               1.4974\n",
       "               1.1813\n",
       "               0.4951\n",
       "               0.9572\n",
       "               1.0135\n",
       "               0.6253\n",
       "               0.6583\n",
       "               1.3331\n",
       "               0.6603\n",
       "               1.1714\n",
       "               0.8998\n",
       "               1.2788\n",
       "               0.6128\n",
       "               0.1481\n",
       "               1.3203\n",
       "               1.1717\n",
       "               0.9036\n",
       "               0.8909\n",
       "               0.5330\n",
       "               1.5755\n",
       "               0.6423\n",
       "               0.6202\n",
       "               0.5676\n",
       "               1.0807\n",
       "               0.8828\n",
       "               0.7329\n",
       "               0.8916\n",
       "               0.9776\n",
       "               0.7860\n",
       "               1.1426\n",
       "               0.8657\n",
       "               1.1187\n",
       "               0.5908\n",
       "               0.9057\n",
       "               0.6248\n",
       "               1.0575\n",
       "               1.0638\n",
       "               1.0008\n",
       "               0.8828\n",
       "               0.7684\n",
       "               0.6494\n",
       "               1.2279\n",
       "               1.1016\n",
       "               1.3636\n",
       "               1.0247\n",
       "               1.2997\n",
       "               1.3717\n",
       "               0.5429\n",
       "               0.9602\n",
       "               0.6874\n",
       "               0.1709\n",
       "               1.0054\n",
       "               0.7965\n",
       "               0.8631\n",
       "               0.1919\n",
       "               1.4163\n",
       "               1.2636\n",
       "               0.9180\n",
       "               1.1709\n",
       "               1.3559\n",
       "               0.9759\n",
       "               1.0351\n",
       "               0.6241\n",
       "               0.6299\n",
       "               1.0584\n",
       "               1.2831\n",
       "               1.2593\n",
       "               1.2278\n",
       "               0.6222\n",
       "               1.3072\n",
       "               1.3494\n",
       "               0.5811\n",
       "               0.8867\n",
       "               1.6287\n",
       "               0.8495\n",
       "               1.1273\n",
       "               1.6001\n",
       "               1.5465\n",
       "               1.1219\n",
       "               1.1682\n",
       "               1.2902\n",
       "               1.3130\n",
       "               0.5378\n",
       "               0.9844\n",
       "               0.9886\n",
       "               0.9226\n",
       "               0.8751\n",
       "               0.8927\n",
       "               1.2481\n",
       "               1.2286\n",
       "               1.2499\n",
       "               0.6665\n",
       "               1.1302\n",
       "               1.7046\n",
       "               0.6374\n",
       "               0.5440\n",
       "               0.8069\n",
       "               0.6315\n",
       "               1.0284\n",
       "               1.0976\n",
       "               0.6897\n",
       "               0.2204\n",
       "               0.9684\n",
       "               0.9538\n",
       "               1.1145\n",
       "               0.8265\n",
       "               0.6010\n",
       "               1.0566\n",
       "               1.2483\n",
       "               0.7787\n",
       "               0.4428\n",
       "               0.7101\n",
       "               0.9655\n",
       "               1.7079\n",
       "               0.8938\n",
       "               1.1872\n",
       "               1.0138\n",
       "               1.1357\n",
       "               0.5685\n",
       "               0.6131\n",
       "               0.9352\n",
       "               0.8493\n",
       "               0.8044\n",
       "               0.8939\n",
       "               1.2291\n",
       "               0.7679\n",
       "               0.7044\n",
       "               0.5485\n",
       "               0.7950\n",
       "               0.7680\n",
       "               1.0235\n",
       "               1.4334\n",
       "               0.4674\n",
       "               0.9230\n",
       "               1.2743\n",
       "               1.1375\n",
       "               1.1310\n",
       "               0.6581\n",
       "               0.9841\n",
       "               1.2105\n",
       "               0.7953\n",
       "               1.4967\n",
       "               1.1096\n",
       "               0.6961\n",
       "               0.9919\n",
       "               1.0830\n",
       "               1.2384\n",
       "               0.5874\n",
       "               0.8553\n",
       "               0.9041\n",
       "               0.5208\n",
       "               0.6021\n",
       "               0.7270\n",
       "               0.9057\n",
       "               1.0718\n",
       "               0.6272\n",
       "               0.6701\n",
       "               1.2859\n",
       "               1.0634\n",
       "               0.9202\n",
       "               1.1207\n",
       "               1.4798\n",
       "               0.5922\n",
       "               1.1144\n",
       "               0.9937\n",
       "               1.7417\n",
       "               1.0148\n",
       "               0.9345\n",
       "               1.3909\n",
       "               1.3924\n",
       "               0.9629\n",
       "               1.4687\n",
       "               0.5806\n",
       "               1.5155\n",
       "               1.0193\n",
       "               1.0262\n",
       "               0.8783\n",
       "               1.2131\n",
       "               0.9641\n",
       "               1.0612\n",
       "               0.4936\n",
       "               1.2062\n",
       "               0.9039\n",
       "               1.2873\n",
       "               0.5465\n",
       "               0.6202\n",
       "               0.6177\n",
       "               0.6800\n",
       "               1.5428\n",
       "               0.5645\n",
       "               1.2474\n",
       "               0.6967\n",
       "               1.1978\n",
       "               1.1196\n",
       "               0.8113\n",
       "               0.8754\n",
       "              [torch.cuda.FloatTensor of size 256 (GPU 0)]),\n",
       "             ('conv4.batchnorm.bias', \n",
       "              -0.3893\n",
       "              -0.4220\n",
       "              -0.7043\n",
       "              -0.6495\n",
       "              -0.2992\n",
       "              -0.6301\n",
       "              -0.5237\n",
       "              -0.3581\n",
       "              -0.5132\n",
       "              -0.5274\n",
       "              -0.5557\n",
       "              -0.4717\n",
       "              -0.4111\n",
       "              -0.6994\n",
       "              -0.5257\n",
       "              -0.7138\n",
       "              -0.4949\n",
       "               0.0892\n",
       "              -0.5212\n",
       "              -0.5075\n",
       "              -0.4206\n",
       "              -0.4216\n",
       "              -0.3583\n",
       "              -0.6123\n",
       "              -0.1330\n",
       "              -0.5182\n",
       "              -0.3326\n",
       "              -0.2599\n",
       "              -0.6708\n",
       "              -0.4193\n",
       "              -0.6015\n",
       "              -0.3313\n",
       "              -0.6626\n",
       "              -0.4948\n",
       "              -0.3733\n",
       "              -0.6350\n",
       "              -0.2638\n",
       "              -0.4599\n",
       "              -0.8114\n",
       "              -0.9582\n",
       "              -0.1010\n",
       "              -0.3716\n",
       "              -0.6950\n",
       "              -0.6679\n",
       "              -0.5925\n",
       "              -0.7105\n",
       "              -0.4978\n",
       "              -0.3019\n",
       "              -0.9214\n",
       "              -0.6329\n",
       "              -0.4532\n",
       "              -0.7891\n",
       "              -0.3909\n",
       "              -0.6373\n",
       "              -0.6432\n",
       "              -0.4397\n",
       "              -0.5746\n",
       "              -0.5739\n",
       "              -0.1442\n",
       "              -0.3720\n",
       "              -0.3990\n",
       "              -0.4918\n",
       "              -0.4650\n",
       "              -0.5382\n",
       "              -0.5255\n",
       "              -0.0915\n",
       "              -0.3715\n",
       "              -0.4167\n",
       "              -0.6534\n",
       "              -0.5154\n",
       "              -0.1971\n",
       "              -0.2297\n",
       "              -0.3818\n",
       "              -0.0320\n",
       "              -0.7258\n",
       "              -0.4978\n",
       "              -0.6595\n",
       "              -0.4805\n",
       "              -0.6478\n",
       "              -0.0612\n",
       "              -0.5562\n",
       "              -0.5943\n",
       "              -0.5646\n",
       "              -0.5791\n",
       "              -0.5459\n",
       "              -0.4157\n",
       "               0.0192\n",
       "              -0.4271\n",
       "              -0.3805\n",
       "              -0.3608\n",
       "              -0.6861\n",
       "              -0.2495\n",
       "              -0.5699\n",
       "              -0.3738\n",
       "              -0.5824\n",
       "              -0.9786\n",
       "              -0.7519\n",
       "              -0.9867\n",
       "              -0.5386\n",
       "              -0.4036\n",
       "              -0.6365\n",
       "              -0.6494\n",
       "              -0.1490\n",
       "              -0.8232\n",
       "              -0.5682\n",
       "              -0.5238\n",
       "              -0.5502\n",
       "              -0.7224\n",
       "              -0.7086\n",
       "              -0.2922\n",
       "              -0.1023\n",
       "              -0.4623\n",
       "              -0.3633\n",
       "              -0.0849\n",
       "              -0.6716\n",
       "              -0.5013\n",
       "              -0.5632\n",
       "              -0.6638\n",
       "              -0.1676\n",
       "              -0.4595\n",
       "              -0.7141\n",
       "              -0.3455\n",
       "              -0.6000\n",
       "              -0.6649\n",
       "              -0.7341\n",
       "              -0.6321\n",
       "              -0.8915\n",
       "              -0.6242\n",
       "              -0.3579\n",
       "              -0.7533\n",
       "              -0.0742\n",
       "              -0.7336\n",
       "              -0.6244\n",
       "              -0.8268\n",
       "              -0.4975\n",
       "              -0.1768\n",
       "              -0.7343\n",
       "              -0.8162\n",
       "              -0.3655\n",
       "              -0.5590\n",
       "              -0.4127\n",
       "              -0.8092\n",
       "              -0.4620\n",
       "              -0.3996\n",
       "              -0.5500\n",
       "              -0.3912\n",
       "              -0.4645\n",
       "               0.1137\n",
       "              -0.5740\n",
       "              -0.3532\n",
       "              -0.3650\n",
       "              -0.6952\n",
       "              -0.6816\n",
       "              -0.1685\n",
       "              -0.1401\n",
       "              -0.4908\n",
       "              -0.4433\n",
       "              -0.4368\n",
       "              -0.3881\n",
       "               0.1512\n",
       "              -0.5757\n",
       "              -0.2886\n",
       "              -0.6948\n",
       "              -0.5818\n",
       "              -0.6261\n",
       "              -0.3028\n",
       "              -0.4656\n",
       "              -0.1961\n",
       "              -0.6719\n",
       "              -0.4594\n",
       "              -0.4170\n",
       "              -0.4582\n",
       "              -0.5485\n",
       "              -0.8520\n",
       "              -0.3770\n",
       "              -0.4823\n",
       "              -0.4391\n",
       "              -0.4154\n",
       "              -0.6123\n",
       "              -0.3013\n",
       "              -0.5013\n",
       "              -0.5564\n",
       "              -0.3753\n",
       "              -0.6202\n",
       "              -1.0121\n",
       "              -0.3264\n",
       "              -0.3717\n",
       "              -0.2461\n",
       "              -0.4930\n",
       "              -0.1035\n",
       "              -0.6935\n",
       "              -0.5214\n",
       "              -0.5412\n",
       "              -0.8993\n",
       "              -0.5324\n",
       "              -0.2666\n",
       "              -0.3561\n",
       "              -0.7019\n",
       "              -0.6041\n",
       "              -0.0767\n",
       "              -0.3430\n",
       "              -0.1021\n",
       "              -0.2400\n",
       "              -0.0715\n",
       "              -0.4894\n",
       "              -0.5997\n",
       "              -0.5916\n",
       "              -0.3331\n",
       "              -0.5731\n",
       "              -0.5565\n",
       "              -0.3105\n",
       "              -0.6301\n",
       "              -0.5673\n",
       "              -0.5034\n",
       "              -0.6914\n",
       "              -0.5410\n",
       "              -0.5524\n",
       "              -0.2152\n",
       "              -0.8684\n",
       "              -0.7874\n",
       "              -0.6157\n",
       "              -1.0285\n",
       "              -0.6149\n",
       "              -0.4894\n",
       "              -0.5963\n",
       "              -0.7831\n",
       "              -0.6016\n",
       "              -0.5062\n",
       "              -0.8252\n",
       "              -0.2228\n",
       "               0.0321\n",
       "              -0.4747\n",
       "              -0.3373\n",
       "               0.3617\n",
       "              -0.5840\n",
       "              -0.7307\n",
       "              -0.5964\n",
       "              -0.1205\n",
       "              -0.2110\n",
       "              -0.3172\n",
       "              -0.3956\n",
       "              -0.6881\n",
       "              -0.8433\n",
       "              -0.6385\n",
       "              -0.5896\n",
       "              -0.4619\n",
       "              -0.6222\n",
       "              -0.5061\n",
       "              -0.8306\n",
       "               0.0003\n",
       "              -0.3325\n",
       "              -0.1938\n",
       "              -0.6895\n",
       "              -0.2354\n",
       "              -0.7269\n",
       "              -0.3431\n",
       "              [torch.cuda.FloatTensor of size 256 (GPU 0)]),\n",
       "             ('conv4.batchnorm.running_mean', \n",
       "               -89.0244\n",
       "               -36.9541\n",
       "                49.0368\n",
       "               -35.5941\n",
       "               -61.2677\n",
       "               -13.6111\n",
       "               -38.3259\n",
       "               -39.3125\n",
       "               -22.3160\n",
       "               -18.0251\n",
       "               -20.1770\n",
       "              -118.8224\n",
       "               -65.3559\n",
       "               -16.7876\n",
       "               -20.0896\n",
       "                 1.2701\n",
       "               -18.9838\n",
       "               -42.3071\n",
       "               -56.4002\n",
       "                -1.1685\n",
       "                -3.5323\n",
       "               -20.4549\n",
       "               -58.9308\n",
       "               -94.0587\n",
       "               -18.5710\n",
       "                -9.7103\n",
       "               -10.5267\n",
       "               -52.7761\n",
       "                -1.4360\n",
       "               -76.5532\n",
       "               -67.3840\n",
       "               -30.2155\n",
       "               -24.2136\n",
       "               -31.6407\n",
       "               -26.7286\n",
       "               -22.3673\n",
       "               -11.4811\n",
       "               -55.3565\n",
       "               -63.8251\n",
       "               -19.5832\n",
       "                -2.6793\n",
       "               -27.6596\n",
       "              -111.4330\n",
       "               -59.5605\n",
       "               -43.6864\n",
       "               -12.5379\n",
       "               -89.2523\n",
       "               -40.2819\n",
       "                 9.8118\n",
       "               -73.2367\n",
       "               -56.4011\n",
       "                58.7818\n",
       "               -66.9449\n",
       "               -44.4196\n",
       "               -63.7144\n",
       "               -27.9123\n",
       "               -90.4603\n",
       "                -2.1043\n",
       "               -15.4782\n",
       "               -29.2612\n",
       "               -27.1277\n",
       "               -20.5902\n",
       "               -26.6033\n",
       "               -12.9845\n",
       "               -35.6540\n",
       "               -47.9010\n",
       "               -38.7666\n",
       "                -7.9124\n",
       "                -4.8171\n",
       "               -39.2250\n",
       "               -38.6476\n",
       "               -10.6358\n",
       "               -62.6334\n",
       "                64.8377\n",
       "               -44.6831\n",
       "                -2.9030\n",
       "               -29.4920\n",
       "               -33.4803\n",
       "               -58.3066\n",
       "               -32.9322\n",
       "               -56.2541\n",
       "               -96.3162\n",
       "               -94.0056\n",
       "               -31.7481\n",
       "               -44.5631\n",
       "               -56.9670\n",
       "               -39.4977\n",
       "                -2.4295\n",
       "               -55.6142\n",
       "               -31.4878\n",
       "               -28.7647\n",
       "               -50.9659\n",
       "               -11.7672\n",
       "               -26.4322\n",
       "                14.8502\n",
       "               -27.5281\n",
       "                 3.7342\n",
       "               -49.9817\n",
       "               -76.1111\n",
       "               -26.9136\n",
       "              -137.2901\n",
       "               -43.6175\n",
       "               -14.2392\n",
       "                14.0473\n",
       "               -62.0506\n",
       "                -9.3642\n",
       "               -27.0360\n",
       "                27.4151\n",
       "                15.5891\n",
       "               -46.3201\n",
       "               -27.6610\n",
       "                12.8324\n",
       "               -57.7116\n",
       "               -59.2773\n",
       "               -80.6835\n",
       "                 0.4129\n",
       "               -12.2081\n",
       "               -61.6598\n",
       "               -15.7479\n",
       "               -24.8743\n",
       "               -20.6339\n",
       "                 0.6369\n",
       "               -86.4328\n",
       "              -127.1767\n",
       "               -43.5317\n",
       "                -6.6430\n",
       "                 1.2040\n",
       "                 2.3611\n",
       "               -51.0531\n",
       "               -22.1494\n",
       "                -9.3871\n",
       "               -26.9214\n",
       "               -16.5312\n",
       "               -23.8783\n",
       "               -78.3163\n",
       "               -81.5929\n",
       "               -17.0440\n",
       "               -13.0264\n",
       "                -8.7215\n",
       "               -16.2028\n",
       "               -14.7623\n",
       "                34.1006\n",
       "               -96.6875\n",
       "               -53.6983\n",
       "               -19.3880\n",
       "               -56.1887\n",
       "               -20.7479\n",
       "               -46.7996\n",
       "               -11.5692\n",
       "               -62.8837\n",
       "               -30.1519\n",
       "              -125.6981\n",
       "               -52.6640\n",
       "               -34.0022\n",
       "               -55.9301\n",
       "               -40.0843\n",
       "               -42.2166\n",
       "               -41.0795\n",
       "               -16.3450\n",
       "               -30.2350\n",
       "                 0.0593\n",
       "                34.5795\n",
       "               -29.2643\n",
       "               -28.3884\n",
       "               -30.7012\n",
       "               -34.8243\n",
       "               -67.1127\n",
       "               -23.7123\n",
       "               -10.3468\n",
       "               -42.7320\n",
       "                83.7929\n",
       "               -75.9129\n",
       "                20.1002\n",
       "                -2.2041\n",
       "                 4.4120\n",
       "               -22.0827\n",
       "                 9.9030\n",
       "               -35.4198\n",
       "              -141.2931\n",
       "               -94.4343\n",
       "               -64.9230\n",
       "               -17.9297\n",
       "               -40.6999\n",
       "                -1.5743\n",
       "                -8.5743\n",
       "               -68.7799\n",
       "               -84.3524\n",
       "               -92.6542\n",
       "                 0.3871\n",
       "               -45.7096\n",
       "                 4.2146\n",
       "               -28.2638\n",
       "               -48.9017\n",
       "                32.4188\n",
       "               -48.6072\n",
       "                -9.0826\n",
       "               -31.7893\n",
       "                94.6686\n",
       "               -30.6000\n",
       "               -27.2835\n",
       "               -57.6272\n",
       "               -42.1325\n",
       "               -10.5649\n",
       "               -31.4666\n",
       "                 1.3468\n",
       "               -12.9614\n",
       "               -10.2201\n",
       "               -64.9821\n",
       "               -35.7888\n",
       "               -39.4912\n",
       "               -83.3853\n",
       "               -76.0833\n",
       "               -13.4143\n",
       "               -53.3231\n",
       "                31.6140\n",
       "               -49.7823\n",
       "               -34.6098\n",
       "               -18.5050\n",
       "                -0.8674\n",
       "               -26.8558\n",
       "               -48.8346\n",
       "               -21.7758\n",
       "               -22.8217\n",
       "               -30.5628\n",
       "                16.2892\n",
       "                -5.7869\n",
       "               -10.9330\n",
       "               -50.4144\n",
       "               -16.3038\n",
       "               -38.0429\n",
       "               -33.8966\n",
       "               -16.1948\n",
       "               -66.7324\n",
       "               -35.1976\n",
       "                -2.4708\n",
       "               -13.2607\n",
       "               -46.0885\n",
       "                15.6660\n",
       "               -44.3891\n",
       "               -60.7393\n",
       "               -51.6347\n",
       "               -25.4515\n",
       "               -45.3229\n",
       "               -35.3076\n",
       "               -43.5186\n",
       "               -52.1965\n",
       "              -166.5919\n",
       "               -36.1351\n",
       "               -10.4692\n",
       "               -73.7826\n",
       "               -38.1098\n",
       "               -83.8071\n",
       "               -15.0065\n",
       "               -12.8899\n",
       "                23.8712\n",
       "               -18.6698\n",
       "              [torch.cuda.FloatTensor of size 256 (GPU 0)]),\n",
       "             ('conv4.batchnorm.running_var', \n",
       "                2695.4678\n",
       "                3935.5327\n",
       "                1551.5327\n",
       "                3409.3481\n",
       "                5683.0181\n",
       "                 981.3203\n",
       "                4652.3184\n",
       "                2026.7621\n",
       "                5680.8750\n",
       "                2181.2410\n",
       "                1226.8207\n",
       "                3573.1067\n",
       "                1580.3792\n",
       "                1409.5962\n",
       "                1739.0673\n",
       "                1056.0829\n",
       "                1424.2229\n",
       "                2698.7407\n",
       "                3721.1560\n",
       "                1458.9202\n",
       "                1401.6255\n",
       "                1739.0045\n",
       "                2245.4709\n",
       "                9812.9912\n",
       "                1142.0425\n",
       "                 931.0495\n",
       "                1056.2906\n",
       "                4926.9595\n",
       "                1804.4584\n",
       "                3537.5542\n",
       "                8863.0342\n",
       "                1661.2091\n",
       "                1230.3199\n",
       "                1652.6665\n",
       "                1391.8821\n",
       "                1120.3485\n",
       "                2537.2117\n",
       "                5177.0317\n",
       "                3199.3425\n",
       "                1396.5571\n",
       "                1349.7155\n",
       "                1866.6652\n",
       "                3482.7161\n",
       "                2052.6667\n",
       "                2156.2771\n",
       "                2216.9495\n",
       "                3556.9331\n",
       "                2773.3088\n",
       "                2418.5361\n",
       "                6541.3379\n",
       "                2604.6355\n",
       "                1265.0293\n",
       "                9537.7529\n",
       "                2227.6453\n",
       "                2938.1865\n",
       "                1805.8702\n",
       "                7513.7397\n",
       "                1577.0586\n",
       "                2041.8217\n",
       "                1860.0475\n",
       "                2293.3269\n",
       "                1686.6667\n",
       "                1595.0059\n",
       "                1690.7040\n",
       "                6347.0615\n",
       "                2619.1052\n",
       "                8822.2295\n",
       "                 774.4111\n",
       "                4281.0107\n",
       "                1225.5962\n",
       "                2221.4939\n",
       "                1117.4264\n",
       "               11240.8857\n",
       "                4195.1665\n",
       "                1744.1068\n",
       "                1519.0062\n",
       "                2682.4861\n",
       "                2377.4309\n",
       "                8056.6143\n",
       "                2755.0364\n",
       "                2491.8667\n",
       "                8179.9355\n",
       "                9279.4053\n",
       "                1326.9430\n",
       "                3614.4780\n",
       "                4101.0454\n",
       "                1701.5212\n",
       "                 979.4263\n",
       "                3531.4487\n",
       "                1450.2347\n",
       "                1836.0547\n",
       "                3052.6467\n",
       "                4687.6597\n",
       "                1775.4404\n",
       "                1668.6021\n",
       "                1297.1018\n",
       "                 907.4451\n",
       "                2596.6438\n",
       "                2798.2703\n",
       "                2830.5715\n",
       "               19122.8809\n",
       "                2122.7124\n",
       "                 917.4899\n",
       "                1406.5171\n",
       "                2479.0837\n",
       "                1515.4546\n",
       "                1168.5203\n",
       "                1639.3867\n",
       "                1029.8395\n",
       "                2254.4204\n",
       "                6743.7520\n",
       "                1861.7858\n",
       "                2078.2144\n",
       "                2821.0579\n",
       "                7798.1865\n",
       "                1355.2648\n",
       "                1416.7445\n",
       "                1996.9385\n",
       "                1728.0763\n",
       "                 977.8463\n",
       "                2562.5171\n",
       "                1624.2214\n",
       "                6753.8115\n",
       "               12675.4229\n",
       "                2229.2515\n",
       "                1253.9884\n",
       "                1541.1223\n",
       "                1280.4772\n",
       "                3020.9556\n",
       "                1174.8008\n",
       "                1785.5054\n",
       "                6436.4536\n",
       "                 977.4645\n",
       "                1356.0508\n",
       "                2094.5752\n",
       "                2658.2002\n",
       "                1181.7269\n",
       "                1693.5286\n",
       "                 906.9937\n",
       "                1234.1654\n",
       "                1313.1666\n",
       "                1586.6289\n",
       "                3247.6924\n",
       "                3282.2810\n",
       "                1499.3475\n",
       "                3107.5583\n",
       "                2573.4099\n",
       "                2143.2739\n",
       "                1661.9323\n",
       "                1812.5005\n",
       "                1556.1415\n",
       "               14447.2646\n",
       "                2021.4921\n",
       "                2404.5559\n",
       "                3049.1138\n",
       "                6138.5181\n",
       "                1952.6740\n",
       "                5572.8628\n",
       "                1492.1208\n",
       "                1715.0551\n",
       "                2683.2578\n",
       "                2660.8853\n",
       "                1594.4016\n",
       "                1109.8510\n",
       "                1160.9960\n",
       "                2405.3464\n",
       "                7931.3594\n",
       "                2439.7761\n",
       "                2183.0049\n",
       "                3083.3281\n",
       "                4061.0322\n",
       "                2440.7605\n",
       "                1220.2795\n",
       "                 686.5679\n",
       "                1445.3672\n",
       "                2855.1880\n",
       "                1371.4177\n",
       "                1656.3624\n",
       "               17909.2871\n",
       "                6601.1084\n",
       "                2428.7891\n",
       "                2025.4912\n",
       "                3790.5679\n",
       "                1827.5199\n",
       "                 901.0036\n",
       "                5588.1304\n",
       "                4680.7949\n",
       "                3041.5974\n",
       "                1933.7513\n",
       "                4477.7661\n",
       "                1028.8850\n",
       "                2343.2439\n",
       "                4796.1685\n",
       "                1291.5381\n",
       "                1712.0115\n",
       "                1852.6588\n",
       "                1779.5909\n",
       "                2417.7253\n",
       "                1067.0640\n",
       "                1689.5540\n",
       "                5442.4014\n",
       "                2735.4434\n",
       "                1599.8976\n",
       "                1191.7167\n",
       "                1762.7385\n",
       "                1625.6744\n",
       "                2497.0981\n",
       "                5563.2026\n",
       "                1645.9413\n",
       "                1665.5032\n",
       "                7253.6255\n",
       "                9438.0918\n",
       "                2536.8269\n",
       "                2167.0054\n",
       "                1606.5521\n",
       "                6822.0884\n",
       "                4042.7307\n",
       "                2505.7839\n",
       "                1752.3088\n",
       "                2004.1738\n",
       "                1394.2811\n",
       "                 819.7167\n",
       "                3046.3308\n",
       "                2340.5300\n",
       "                1497.3326\n",
       "                 936.3369\n",
       "                1784.4675\n",
       "                3072.4670\n",
       "                1424.0114\n",
       "                3624.5916\n",
       "                2307.1704\n",
       "                1413.0104\n",
       "               11060.1729\n",
       "                1633.4374\n",
       "                2393.4482\n",
       "                1227.2327\n",
       "                1952.2881\n",
       "                1221.8995\n",
       "                1655.2229\n",
       "                2057.9031\n",
       "                5930.6377\n",
       "                2234.3845\n",
       "                1730.3931\n",
       "                1616.3014\n",
       "                6799.8906\n",
       "                6355.8496\n",
       "               20082.5098\n",
       "                3458.3679\n",
       "                 964.5872\n",
       "                3280.6313\n",
       "                2882.8708\n",
       "                5112.8682\n",
       "                1311.1577\n",
       "                2074.3206\n",
       "                1550.1223\n",
       "                2205.5894\n",
       "              [torch.cuda.FloatTensor of size 256 (GPU 0)]),\n",
       "             ('conv5.conv.weight', \n",
       "              ( 0 , 0 , 0 ,.,.) = \n",
       "                2.5538e-01  6.1139e-01  7.4788e-01\n",
       "               -4.0278e-02  3.2514e-01  2.2514e-01\n",
       "               -7.1662e-02  2.3956e-01 -2.0177e-01\n",
       "              \n",
       "              ( 0 , 0 , 1 ,.,.) = \n",
       "                8.6782e-02  4.6274e-01  4.1855e-01\n",
       "               -6.4316e-02  1.1724e-01 -2.0739e-01\n",
       "               -8.0147e-02  5.7310e-02 -5.8918e-01\n",
       "              \n",
       "              ( 0 , 0 , 2 ,.,.) = \n",
       "                1.6774e-01  3.0803e-01  2.9983e-01\n",
       "               -1.1680e-01 -7.5215e-02 -3.7323e-01\n",
       "               -6.7241e-02 -1.0541e-01 -7.0667e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 0 , 1 , 0 ,.,.) = \n",
       "               -1.0401e-01 -6.4313e-01 -3.2955e-01\n",
       "                5.6105e-02 -3.7768e-01 -4.0416e-02\n",
       "                1.8295e-01 -2.1854e-01  1.9391e-01\n",
       "              \n",
       "              ( 0 , 1 , 1 ,.,.) = \n",
       "                1.1328e-01 -3.9774e-01 -2.6893e-01\n",
       "                2.4779e-01 -3.6089e-01 -1.4677e-01\n",
       "                2.0773e-01 -8.6986e-02  6.1016e-02\n",
       "              \n",
       "              ( 0 , 1 , 2 ,.,.) = \n",
       "               -6.0033e-02 -5.7249e-01 -5.8708e-01\n",
       "                1.4784e-01 -3.9629e-01 -3.5620e-01\n",
       "                1.8932e-01 -1.1951e-01 -2.1333e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 0 , 2 , 0 ,.,.) = \n",
       "                6.3488e-01  6.7995e-01  3.3790e-01\n",
       "                1.4094e-01 -5.3602e-02 -2.4254e-01\n",
       "               -2.2729e-01 -3.4652e-01 -3.8606e-01\n",
       "              \n",
       "              ( 0 , 2 , 1 ,.,.) = \n",
       "                8.7397e-01  9.0722e-01  5.6180e-01\n",
       "                4.7628e-01  4.3777e-01  9.1151e-02\n",
       "                7.0730e-02  1.0578e-01 -1.3314e-01\n",
       "              \n",
       "              ( 0 , 2 , 2 ,.,.) = \n",
       "                8.0710e-01  1.0490e+00  7.6021e-01\n",
       "                6.0387e-01  6.7965e-01  3.1063e-01\n",
       "                2.2514e-01  4.2232e-01 -4.5969e-02\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              ( 0 ,253, 0 ,.,.) = \n",
       "               -4.0784e-01 -7.0507e-01  1.1158e-01\n",
       "               -5.6047e-01 -7.0840e-01  1.2349e-02\n",
       "               -6.6903e-01 -5.4627e-01 -4.3484e-02\n",
       "              \n",
       "              ( 0 ,253, 1 ,.,.) = \n",
       "               -1.7027e-01 -4.1628e-01  3.4900e-01\n",
       "               -3.1657e-01 -4.7952e-01  2.7012e-01\n",
       "               -3.1674e-01 -1.6923e-01  2.8526e-01\n",
       "              \n",
       "              ( 0 ,253, 2 ,.,.) = \n",
       "                2.3129e-02 -2.6832e-01  3.4234e-01\n",
       "               -1.7659e-01 -2.6439e-01  2.9700e-01\n",
       "               -2.4045e-01 -6.2513e-02  3.4320e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 0 ,254, 0 ,.,.) = \n",
       "                2.6979e-01  1.4977e-01 -3.5054e-01\n",
       "                5.9294e-01  5.9931e-01  2.2030e-01\n",
       "                7.0011e-01  3.7493e-01  2.2545e-01\n",
       "              \n",
       "              ( 0 ,254, 1 ,.,.) = \n",
       "                3.1536e-01  2.2150e-01 -2.0604e-01\n",
       "                6.1500e-01  6.3285e-01  3.5057e-01\n",
       "                7.5195e-01  5.3244e-01  4.4044e-01\n",
       "              \n",
       "              ( 0 ,254, 2 ,.,.) = \n",
       "               -1.0448e-01 -1.5285e-01 -5.9203e-01\n",
       "                3.5531e-01  4.1333e-01  1.4392e-01\n",
       "                5.8777e-01  1.5199e-01  2.5085e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 0 ,255, 0 ,.,.) = \n",
       "               -3.2699e-01 -5.1517e-01  1.4363e-01\n",
       "               -1.4188e-02 -4.7973e-02  2.8992e-01\n",
       "                3.5665e-01  2.9324e-01  2.6790e-01\n",
       "              \n",
       "              ( 0 ,255, 1 ,.,.) = \n",
       "               -2.8806e-01 -5.7776e-01 -1.1331e-02\n",
       "                4.3684e-02 -5.5426e-02  2.2604e-01\n",
       "                3.0593e-01  2.4673e-01  2.9939e-01\n",
       "              \n",
       "              ( 0 ,255, 2 ,.,.) = \n",
       "               -4.3263e-01 -6.8326e-01 -1.5680e-01\n",
       "               -1.7755e-01 -2.5187e-01  1.2237e-01\n",
       "                1.1563e-01  2.8152e-02  2.2283e-01\n",
       "                    â‹®   â‹®  \n",
       "              \n",
       "              ( 1 , 0 , 0 ,.,.) = \n",
       "                5.5568e-01  6.5858e-01  3.0691e-01\n",
       "                3.5150e-01  3.1082e-01 -2.4454e-01\n",
       "                3.2587e-01  1.9893e-01 -3.2140e-01\n",
       "              \n",
       "              ( 1 , 0 , 1 ,.,.) = \n",
       "                7.9350e-01  5.8580e-01 -7.2356e-03\n",
       "                7.0556e-01  4.1472e-01 -3.9935e-01\n",
       "                5.6612e-01  2.6949e-01 -4.4187e-01\n",
       "              \n",
       "              ( 1 , 0 , 2 ,.,.) = \n",
       "                7.2590e-01  4.3526e-01 -2.6411e-01\n",
       "                7.3752e-01  3.7693e-01 -5.2338e-01\n",
       "                5.2533e-01  3.4729e-01 -3.8782e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 1 , 1 , 0 ,.,.) = \n",
       "               -2.0625e-01 -4.4407e-01 -4.5349e-01\n",
       "               -1.2171e-01 -2.6635e-01 -2.1098e-01\n",
       "                4.2387e-01 -1.0102e-01  9.2197e-02\n",
       "              \n",
       "              ( 1 , 1 , 1 ,.,.) = \n",
       "                8.1322e-02  2.1536e-03  6.6188e-02\n",
       "                8.6854e-02  2.6412e-02  3.3575e-01\n",
       "                6.5877e-01  2.2898e-01  5.0013e-01\n",
       "              \n",
       "              ( 1 , 1 , 2 ,.,.) = \n",
       "               -4.0112e-01 -6.6625e-01 -6.6830e-01\n",
       "               -6.5540e-01 -7.3943e-01 -5.4186e-01\n",
       "               -1.5174e-01 -6.1111e-01 -3.0057e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 1 , 2 , 0 ,.,.) = \n",
       "                3.3349e-01  2.4835e-01 -2.6604e-02\n",
       "                8.2125e-02  3.6252e-01  1.2621e-01\n",
       "               -2.8788e-01  1.5773e-01 -7.2015e-02\n",
       "              \n",
       "              ( 1 , 2 , 1 ,.,.) = \n",
       "                3.0396e-01  4.6561e-01 -4.5343e-04\n",
       "                1.8889e-01  5.2273e-01  1.5190e-01\n",
       "                7.4196e-03  3.9102e-01  7.9631e-03\n",
       "              \n",
       "              ( 1 , 2 , 2 ,.,.) = \n",
       "                4.3950e-01  4.4802e-01 -1.3978e-01\n",
       "                4.5073e-01  6.2248e-01 -9.0224e-02\n",
       "                3.2891e-01  5.3362e-01 -2.3520e-02\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              ( 1 ,253, 0 ,.,.) = \n",
       "               -1.5423e-01 -2.2583e-01 -4.0171e-01\n",
       "                9.2469e-02  8.5845e-02 -1.4792e-01\n",
       "               -6.5394e-02  2.5711e-01  2.3557e-01\n",
       "              \n",
       "              ( 1 ,253, 1 ,.,.) = \n",
       "               -1.7586e-01 -1.7036e-01 -4.6394e-01\n",
       "               -1.0955e-01  5.7712e-03 -3.4219e-01\n",
       "               -2.2563e-01  5.2895e-02 -3.0536e-02\n",
       "              \n",
       "              ( 1 ,253, 2 ,.,.) = \n",
       "               -1.3593e-01 -5.1177e-01 -6.9034e-01\n",
       "               -1.0768e-01 -2.0521e-01 -4.5260e-01\n",
       "               -1.2022e-01  2.3475e-02 -1.3329e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 1 ,254, 0 ,.,.) = \n",
       "               -8.5427e-01  1.5731e-03  2.7959e-01\n",
       "               -9.5833e-01 -7.1749e-02  3.7956e-01\n",
       "               -1.0060e+00 -1.4057e-02  7.2994e-01\n",
       "              \n",
       "              ( 1 ,254, 1 ,.,.) = \n",
       "               -7.1414e-01  3.8478e-01  3.2649e-01\n",
       "               -6.5786e-01  3.5276e-01  5.9276e-01\n",
       "               -7.8360e-01  6.2162e-02  9.1429e-01\n",
       "              \n",
       "              ( 1 ,254, 2 ,.,.) = \n",
       "               -9.5750e-01  3.6437e-02 -1.1321e-01\n",
       "               -9.3323e-01  2.5673e-02  9.0979e-02\n",
       "               -1.0944e+00 -2.9182e-01  3.8464e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 1 ,255, 0 ,.,.) = \n",
       "                8.4011e-01  6.2792e-01 -7.3235e-03\n",
       "                1.0375e+00  5.8970e-01 -2.2441e-01\n",
       "                7.6969e-01  1.9375e-02 -1.0563e+00\n",
       "              \n",
       "              ( 1 ,255, 1 ,.,.) = \n",
       "                8.0144e-01  5.8239e-01  1.0008e-01\n",
       "                8.8052e-01  4.9332e-01 -2.7814e-01\n",
       "                6.9714e-01 -5.6679e-02 -1.2060e+00\n",
       "              \n",
       "              ( 1 ,255, 2 ,.,.) = \n",
       "                4.9702e-01  1.5968e-01 -4.1016e-01\n",
       "                5.5684e-01  9.9345e-02 -6.7445e-01\n",
       "                2.2194e-01 -4.7845e-01 -1.4657e+00\n",
       "                    â‹®   â‹®  \n",
       "              \n",
       "              ( 2 , 0 , 0 ,.,.) = \n",
       "                4.5142e-01  3.6052e-02  2.4161e-01\n",
       "                4.5605e-01  2.9302e-01  2.9801e-01\n",
       "                4.4469e-01  4.0314e-01  4.2064e-01\n",
       "              \n",
       "              ( 2 , 0 , 1 ,.,.) = \n",
       "                5.9208e-01  3.1173e-01  6.7429e-01\n",
       "                6.4516e-01  4.6045e-01  5.9927e-01\n",
       "                8.6763e-01  8.1934e-01  8.2838e-01\n",
       "              \n",
       "              ( 2 , 0 , 2 ,.,.) = \n",
       "                2.8041e-01 -6.9103e-02  4.6964e-01\n",
       "                4.3341e-01  1.4288e-01  5.0808e-01\n",
       "                8.3811e-01  7.3363e-01  9.6737e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 2 , 1 , 0 ,.,.) = \n",
       "               -7.7509e-01 -3.5699e-01 -1.7955e-01\n",
       "               -9.2142e-01 -1.3610e-01  5.3862e-02\n",
       "               -8.1054e-01 -1.8630e-01 -2.7367e-02\n",
       "              \n",
       "              ( 2 , 1 , 1 ,.,.) = \n",
       "               -7.2698e-02  1.5132e-01  4.6677e-02\n",
       "               -1.1035e-01  4.3240e-01  3.9370e-01\n",
       "               -2.6600e-01  1.3279e-01  1.5419e-01\n",
       "              \n",
       "              ( 2 , 1 , 2 ,.,.) = \n",
       "                6.8328e-01  6.5773e-01  1.9748e-01\n",
       "                5.6527e-01  8.3716e-01  4.2420e-01\n",
       "                2.8617e-01  3.1249e-01  1.5020e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 2 , 2 , 0 ,.,.) = \n",
       "                4.5444e-01  3.9951e-01  1.2249e-01\n",
       "                6.2432e-01  2.8851e-01  3.7345e-01\n",
       "                1.0153e+00  1.1010e+00  1.0293e+00\n",
       "              \n",
       "              ( 2 , 2 , 1 ,.,.) = \n",
       "                3.4172e-02  1.3176e-01 -6.1376e-03\n",
       "                8.5691e-02  1.1089e-01  2.6446e-01\n",
       "                4.9496e-01  8.1721e-01  8.7253e-01\n",
       "              \n",
       "              ( 2 , 2 , 2 ,.,.) = \n",
       "               -4.4781e-01 -2.9448e-01 -3.1650e-01\n",
       "               -3.3754e-01 -4.1935e-01 -2.0880e-01\n",
       "               -1.4322e-01  6.7986e-02  1.4463e-01\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              ( 2 ,253, 0 ,.,.) = \n",
       "               -5.1782e-01 -1.3511e-01  3.5244e-01\n",
       "               -4.9076e-02  4.3739e-02  4.6696e-01\n",
       "               -1.6931e-01  1.3401e-01  5.1521e-01\n",
       "              \n",
       "              ( 2 ,253, 1 ,.,.) = \n",
       "               -5.7839e-01 -1.4947e-01  5.5631e-01\n",
       "               -2.1665e-01 -1.0393e-01  4.6622e-01\n",
       "               -3.0178e-01 -3.3503e-02  4.2745e-01\n",
       "              \n",
       "              ( 2 ,253, 2 ,.,.) = \n",
       "               -5.7607e-01 -1.8390e-01  5.2729e-01\n",
       "               -2.9806e-01 -2.8400e-01  4.4318e-01\n",
       "               -1.6916e-01 -2.5335e-01  3.5385e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 2 ,254, 0 ,.,.) = \n",
       "               -8.1293e-01 -5.5185e-01 -1.3863e-02\n",
       "               -4.6899e-01 -7.1570e-01  2.2855e-01\n",
       "                4.2275e-02 -7.8781e-01 -2.8234e-02\n",
       "              \n",
       "              ( 2 ,254, 1 ,.,.) = \n",
       "               -3.6351e-01 -1.9518e-01  2.3430e-01\n",
       "               -1.9959e-01 -6.7869e-01  3.6893e-01\n",
       "                1.6207e-01 -1.0027e+00 -9.7550e-03\n",
       "              \n",
       "              ( 2 ,254, 2 ,.,.) = \n",
       "                5.3469e-01  4.3148e-01  4.9588e-01\n",
       "                5.8451e-01  4.2428e-02  5.0351e-01\n",
       "                8.3848e-01 -5.2204e-01  1.2542e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 2 ,255, 0 ,.,.) = \n",
       "               -2.2335e-02 -1.0811e-01 -2.0868e-01\n",
       "                2.3273e-01  4.8972e-02 -1.5828e-01\n",
       "               -2.5066e-01 -3.2195e-01 -4.6565e-01\n",
       "              \n",
       "              ( 2 ,255, 1 ,.,.) = \n",
       "               -2.0829e-01 -1.2926e-01 -3.0801e-01\n",
       "                6.9582e-02 -3.9303e-02 -2.6308e-01\n",
       "               -4.6921e-01 -6.2375e-01 -6.7568e-01\n",
       "              \n",
       "              ( 2 ,255, 2 ,.,.) = \n",
       "               -3.0870e-02  2.9651e-02 -2.3506e-01\n",
       "                2.8316e-02 -1.9222e-02 -2.6620e-01\n",
       "               -5.8147e-01 -7.6388e-01 -7.1099e-01\n",
       "              ...         \n",
       "                    â‹®   â‹®  \n",
       "              \n",
       "              (253, 0 , 0 ,.,.) = \n",
       "               -4.9239e-01 -2.3514e-01 -1.2961e-01\n",
       "               -2.0905e-01  5.7661e-02 -1.1922e-01\n",
       "                8.5120e-02  2.4718e-01 -1.4092e-01\n",
       "              \n",
       "              (253, 0 , 1 ,.,.) = \n",
       "               -4.2758e-01  1.6390e-01  5.1130e-01\n",
       "               -1.6552e-01  2.6888e-01  3.2492e-01\n",
       "                2.2736e-03  2.4398e-01  2.2976e-01\n",
       "              \n",
       "              (253, 0 , 2 ,.,.) = \n",
       "               -4.8453e-01  2.0883e-02  2.8383e-01\n",
       "               -3.0030e-01  1.4529e-01  1.3819e-01\n",
       "                1.9925e-02  1.6919e-01  2.6140e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (253, 1 , 0 ,.,.) = \n",
       "               -4.4601e-01  8.9170e-02 -6.4539e-01\n",
       "               -1.3651e-02  2.5933e-01 -1.7261e-02\n",
       "                9.8364e-02  3.7918e-01  3.1491e-01\n",
       "              \n",
       "              (253, 1 , 1 ,.,.) = \n",
       "               -1.7075e-01  9.4902e-02 -7.3417e-01\n",
       "                1.2642e-01  1.7063e-01 -2.1054e-01\n",
       "                2.8101e-01  3.2689e-01 -5.8940e-02\n",
       "              \n",
       "              (253, 1 , 2 ,.,.) = \n",
       "                1.3576e-01  2.9962e-01 -4.3562e-01\n",
       "                2.9150e-01  3.8202e-01  9.1531e-02\n",
       "                1.9485e-01  2.2140e-01  1.0986e-02\n",
       "                        â‹®  \n",
       "              \n",
       "              (253, 2 , 0 ,.,.) = \n",
       "                7.0052e-01  6.8050e-01  9.4685e-01\n",
       "                2.4504e-01  4.1921e-01  1.2636e-01\n",
       "                2.3141e-01  5.1751e-01 -3.7700e-02\n",
       "              \n",
       "              (253, 2 , 1 ,.,.) = \n",
       "                4.5313e-01  2.1983e-01  3.3409e-01\n",
       "                8.8489e-02  1.8415e-01 -3.6589e-01\n",
       "                1.9843e-01  3.4409e-01 -5.6261e-01\n",
       "              \n",
       "              (253, 2 , 2 ,.,.) = \n",
       "                3.5270e-01 -1.5810e-01 -3.3266e-01\n",
       "                3.0642e-01  8.6861e-02 -7.6497e-01\n",
       "                3.5685e-01  3.0160e-01 -9.1225e-01\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              (253,253, 0 ,.,.) = \n",
       "               -1.2277e+00 -1.5731e+00 -1.4907e+00\n",
       "               -1.1905e+00 -1.5608e+00 -1.5648e+00\n",
       "               -3.8222e-01 -5.8547e-01 -6.1654e-01\n",
       "              \n",
       "              (253,253, 1 ,.,.) = \n",
       "               -8.4279e-01 -1.3014e+00 -1.6339e+00\n",
       "               -8.9834e-01 -1.2882e+00 -1.6467e+00\n",
       "               -2.5016e-01 -5.9211e-01 -8.3678e-01\n",
       "              \n",
       "              (253,253, 2 ,.,.) = \n",
       "               -6.7693e-01 -1.1454e+00 -1.7721e+00\n",
       "               -7.0992e-01 -1.1217e+00 -1.7758e+00\n",
       "               -1.4912e-01 -5.5504e-01 -1.0030e+00\n",
       "                        â‹®  \n",
       "              \n",
       "              (253,254, 0 ,.,.) = \n",
       "                3.6379e-01  4.1557e-01  1.1697e-01\n",
       "               -5.9368e-02 -1.6787e-01 -3.2484e-01\n",
       "                4.0111e-01  7.5626e-01  6.1956e-01\n",
       "              \n",
       "              (253,254, 1 ,.,.) = \n",
       "                4.2459e-01  1.8778e-01 -2.9593e-01\n",
       "                7.9705e-02 -4.6817e-01 -8.7267e-01\n",
       "                3.9775e-01  5.8855e-01  1.1898e-01\n",
       "              \n",
       "              (253,254, 2 ,.,.) = \n",
       "                3.3847e-01 -2.8963e-02 -6.0989e-01\n",
       "                2.8718e-02 -2.2552e-01 -7.5966e-01\n",
       "                6.1546e-02  3.7379e-01 -1.2578e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (253,255, 0 ,.,.) = \n",
       "                2.9741e-01  1.9209e-01  2.1537e-01\n",
       "                2.5912e-01  5.5488e-02 -4.0228e-02\n",
       "               -2.2105e-01 -3.3510e-01 -3.7777e-01\n",
       "              \n",
       "              (253,255, 1 ,.,.) = \n",
       "                6.7892e-02 -4.2892e-02  2.6305e-04\n",
       "                1.5537e-01 -1.7108e-01 -3.0984e-01\n",
       "               -4.0356e-01 -7.0938e-01 -7.5140e-01\n",
       "              \n",
       "              (253,255, 2 ,.,.) = \n",
       "                3.4344e-01 -1.9873e-01 -4.0182e-01\n",
       "                2.8370e-01 -4.5849e-01 -8.6709e-01\n",
       "               -4.2207e-01 -9.9131e-01 -1.2074e+00\n",
       "                    â‹®   â‹®  \n",
       "              \n",
       "              (254, 0 , 0 ,.,.) = \n",
       "                1.2157e-02  3.8772e-01  5.0237e-01\n",
       "                3.3148e-01  1.9361e-01  9.8420e-02\n",
       "                5.2908e-01  2.1431e-01 -5.8259e-02\n",
       "              \n",
       "              (254, 0 , 1 ,.,.) = \n",
       "                6.3461e-02  4.5186e-01  3.9281e-01\n",
       "                2.7562e-01  2.7052e-01  9.6221e-02\n",
       "                5.3535e-01  2.4622e-01 -5.9916e-02\n",
       "              \n",
       "              (254, 0 , 2 ,.,.) = \n",
       "               -3.5993e-02  2.6265e-01  2.3624e-01\n",
       "                2.6686e-01  3.1751e-01  2.6598e-02\n",
       "                5.6543e-01  3.2684e-01  1.4303e-02\n",
       "                        â‹®  \n",
       "              \n",
       "              (254, 1 , 0 ,.,.) = \n",
       "               -2.3125e-01 -2.7036e-01  2.0343e-01\n",
       "               -1.6115e-01 -2.4773e-01  1.0277e-01\n",
       "                4.4308e-01  2.9933e-01  4.5573e-01\n",
       "              \n",
       "              (254, 1 , 1 ,.,.) = \n",
       "               -2.7562e-01 -1.8582e-01  3.8789e-01\n",
       "               -2.3718e-01 -2.2424e-01  3.5210e-01\n",
       "                3.6881e-01  2.7692e-01  4.9867e-01\n",
       "              \n",
       "              (254, 1 , 2 ,.,.) = \n",
       "               -3.9649e-01 -4.6566e-01  5.3153e-02\n",
       "               -4.6812e-01 -7.3991e-01 -1.4118e-01\n",
       "               -6.8217e-02 -3.4639e-01 -2.4165e-02\n",
       "                        â‹®  \n",
       "              \n",
       "              (254, 2 , 0 ,.,.) = \n",
       "               -3.4955e-01 -6.7414e-01 -7.4703e-01\n",
       "               -2.6220e-01 -5.1464e-01 -4.4827e-01\n",
       "               -8.2485e-01 -6.6179e-01 -2.5687e-01\n",
       "              \n",
       "              (254, 2 , 1 ,.,.) = \n",
       "               -4.3414e-01 -8.8319e-01 -7.0667e-01\n",
       "               -3.1102e-01 -6.5920e-01 -4.9612e-01\n",
       "               -8.4693e-01 -9.1106e-01 -2.4993e-01\n",
       "              \n",
       "              (254, 2 , 2 ,.,.) = \n",
       "               -6.8878e-01 -1.0878e+00 -5.5798e-01\n",
       "               -4.6871e-01 -8.6473e-01 -3.4883e-01\n",
       "               -1.0362e+00 -1.0961e+00 -2.6919e-01\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              (254,253, 0 ,.,.) = \n",
       "                4.5203e-01  3.3423e-01  6.1743e-01\n",
       "                3.8575e-02  2.1363e-01  5.4673e-01\n",
       "               -2.2828e-01  4.7624e-02  1.3933e-01\n",
       "              \n",
       "              (254,253, 1 ,.,.) = \n",
       "               -1.4962e-01 -3.4161e-01 -1.1811e-01\n",
       "               -4.6911e-01 -4.1174e-01 -1.1871e-01\n",
       "               -7.4081e-01 -5.3355e-01 -4.7851e-01\n",
       "              \n",
       "              (254,253, 2 ,.,.) = \n",
       "               -1.0361e-01 -2.9654e-01 -7.9887e-02\n",
       "               -5.6236e-01 -4.1416e-01 -1.5498e-01\n",
       "               -8.9030e-01 -6.6114e-01 -4.9182e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (254,254, 0 ,.,.) = \n",
       "               -6.3348e-01 -3.5995e-01 -3.1826e-02\n",
       "               -4.4577e-01 -5.6866e-02  3.1433e-02\n",
       "               -1.0803e-01 -3.0564e-01 -4.9942e-01\n",
       "              \n",
       "              (254,254, 1 ,.,.) = \n",
       "               -6.6625e-01 -2.9407e-02  1.9255e-01\n",
       "               -4.9000e-01  1.7762e-01  1.0105e-01\n",
       "               -2.4350e-01 -2.5093e-01 -5.4183e-01\n",
       "              \n",
       "              (254,254, 2 ,.,.) = \n",
       "               -7.3255e-01  6.9327e-02  5.1175e-01\n",
       "               -6.2012e-01 -2.1623e-02  1.2580e-01\n",
       "               -3.8962e-01 -4.5539e-01 -7.5352e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (254,255, 0 ,.,.) = \n",
       "                9.3606e-02 -5.0943e-02 -6.6117e-01\n",
       "               -3.4634e-01 -4.2426e-01 -8.8470e-01\n",
       "               -8.1168e-01 -8.8511e-01 -1.0862e+00\n",
       "              \n",
       "              (254,255, 1 ,.,.) = \n",
       "                2.1032e-01 -3.0973e-02 -6.3694e-01\n",
       "               -2.0252e-01 -3.0044e-01 -8.4477e-01\n",
       "               -6.6427e-01 -7.2349e-01 -9.5216e-01\n",
       "              \n",
       "              (254,255, 2 ,.,.) = \n",
       "                3.3331e-01  2.3968e-01 -4.0054e-01\n",
       "                7.4517e-02 -6.9207e-03 -6.2511e-01\n",
       "               -2.6057e-01 -3.4420e-01 -7.9135e-01\n",
       "                    â‹®   â‹®  \n",
       "              \n",
       "              (255, 0 , 0 ,.,.) = \n",
       "               -8.7659e-01 -6.9809e-01 -3.2349e-01\n",
       "               -1.2784e+00 -7.9462e-01 -3.7517e-01\n",
       "               -9.3271e-01 -2.6226e-01 -2.0534e-02\n",
       "              \n",
       "              (255, 0 , 1 ,.,.) = \n",
       "               -9.0627e-01 -4.6363e-01 -2.0273e-01\n",
       "               -1.4188e+00 -8.5570e-01 -4.8906e-01\n",
       "               -1.1897e+00 -5.4528e-01 -3.0186e-01\n",
       "              \n",
       "              (255, 0 , 2 ,.,.) = \n",
       "               -1.3719e+00 -9.4066e-01 -5.3594e-01\n",
       "               -1.5507e+00 -1.0841e+00 -8.3132e-01\n",
       "               -1.1613e+00 -6.4493e-01 -5.5870e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (255, 1 , 0 ,.,.) = \n",
       "               -3.4749e-01 -3.5420e-01 -3.1072e-01\n",
       "               -1.8976e-01 -2.5694e-01 -2.4661e-01\n",
       "               -4.1751e-01 -3.6652e-01 -2.6417e-01\n",
       "              \n",
       "              (255, 1 , 1 ,.,.) = \n",
       "                1.4805e-01  3.0856e-01  2.4231e-01\n",
       "                2.0058e-01  2.5300e-01  3.2134e-01\n",
       "               -1.4158e-01  9.3399e-02  3.2845e-01\n",
       "              \n",
       "              (255, 1 , 2 ,.,.) = \n",
       "                1.3050e-01  2.5481e-01  1.2677e-01\n",
       "                1.1403e-01  1.2864e-01  4.7986e-02\n",
       "               -3.9041e-01 -2.3331e-01 -1.1168e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (255, 2 , 0 ,.,.) = \n",
       "               -1.2548e-01  4.8580e-02  2.8909e-01\n",
       "               -2.0745e-01 -2.4367e-01 -2.7290e-02\n",
       "               -1.0562e+00 -8.0719e-01 -1.7684e-01\n",
       "              \n",
       "              (255, 2 , 1 ,.,.) = \n",
       "                2.0653e-01 -9.7551e-02  3.5750e-02\n",
       "                9.5673e-02 -2.3489e-01 -2.1095e-01\n",
       "               -9.1443e-01 -7.5867e-01 -2.2469e-01\n",
       "              \n",
       "              (255, 2 , 2 ,.,.) = \n",
       "               -2.3945e-02 -4.6873e-01 -3.5369e-01\n",
       "               -4.7553e-02 -6.9546e-01 -7.8330e-01\n",
       "               -9.5692e-01 -1.1368e+00 -7.8826e-01\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              (255,253, 0 ,.,.) = \n",
       "               -2.8254e-01 -2.6536e-01  5.7150e-03\n",
       "               -3.0352e-01 -5.6966e-01 -3.4298e-01\n",
       "               -2.2362e-01  6.3109e-02  2.1255e-01\n",
       "              \n",
       "              (255,253, 1 ,.,.) = \n",
       "               -5.3394e-01 -5.1881e-01 -1.6222e-02\n",
       "               -4.9890e-01 -6.5271e-01 -2.0414e-01\n",
       "               -1.3955e-01  1.6099e-01  4.1063e-01\n",
       "              \n",
       "              (255,253, 2 ,.,.) = \n",
       "               -1.9109e-01 -2.0837e-01  3.6618e-01\n",
       "               -7.4258e-02 -2.8793e-01  1.9348e-01\n",
       "                2.1638e-01  4.2086e-01  8.4127e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (255,254, 0 ,.,.) = \n",
       "               -3.2440e-01  4.2986e-01  5.8737e-01\n",
       "               -4.6258e-01  4.3559e-01  2.6021e-01\n",
       "               -5.5182e-01 -2.4383e-01  1.3319e-01\n",
       "              \n",
       "              (255,254, 1 ,.,.) = \n",
       "               -1.8857e-01  5.7895e-01  2.6145e-01\n",
       "               -4.2250e-01  4.3890e-01  2.8621e-03\n",
       "               -7.5520e-01 -4.4369e-01 -3.1028e-01\n",
       "              \n",
       "              (255,254, 2 ,.,.) = \n",
       "               -1.1239e-01  5.8034e-01  1.2446e-01\n",
       "               -4.3315e-01  6.9445e-01  7.9927e-02\n",
       "               -8.3529e-01 -3.6756e-01 -4.5318e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (255,255, 0 ,.,.) = \n",
       "               -4.2307e-02  3.1024e-01 -1.2255e-01\n",
       "                3.7406e-01  6.0642e-01 -3.6885e-01\n",
       "                4.8066e-01  5.1198e-01 -5.4431e-01\n",
       "              \n",
       "              (255,255, 1 ,.,.) = \n",
       "                1.4360e-01  3.9975e-01 -2.1702e-02\n",
       "                4.5813e-01  6.6334e-01 -2.4653e-01\n",
       "                5.6170e-01  4.8723e-01 -5.6726e-01\n",
       "              \n",
       "              (255,255, 2 ,.,.) = \n",
       "                2.5607e-01  2.6726e-01 -1.9995e-01\n",
       "                6.5025e-01  6.9250e-01 -2.4348e-01\n",
       "                6.8099e-01  4.7428e-01 -5.7617e-01\n",
       "              [torch.cuda.FloatTensor of size 256x256x3x3x3 (GPU 0)]),\n",
       "             ('conv5.batchnorm.weight', \n",
       "               0.9301\n",
       "               1.1800\n",
       "               1.8415\n",
       "               1.6703\n",
       "               0.8274\n",
       "               1.0040\n",
       "               0.8151\n",
       "               0.6447\n",
       "               0.7289\n",
       "               1.0953\n",
       "               0.4374\n",
       "               1.4084\n",
       "               0.8233\n",
       "               1.0790\n",
       "               0.8265\n",
       "               1.6025\n",
       "               1.2133\n",
       "               0.6971\n",
       "               0.4766\n",
       "               0.7916\n",
       "               0.3546\n",
       "               1.1529\n",
       "               1.3215\n",
       "               1.3021\n",
       "               0.6599\n",
       "               1.0705\n",
       "               1.0318\n",
       "               0.7547\n",
       "               1.2278\n",
       "               0.8865\n",
       "               0.7760\n",
       "               1.0045\n",
       "               1.6211\n",
       "               1.2453\n",
       "               1.0246\n",
       "               0.7558\n",
       "               1.0742\n",
       "               0.4514\n",
       "               1.1995\n",
       "               1.1271\n",
       "               1.2266\n",
       "               0.7563\n",
       "               0.7882\n",
       "               0.7824\n",
       "               0.9219\n",
       "               1.0570\n",
       "               1.0748\n",
       "               0.4291\n",
       "               1.2778\n",
       "               0.8492\n",
       "               1.2315\n",
       "               1.1140\n",
       "               0.3753\n",
       "               0.6226\n",
       "               0.7542\n",
       "               1.1169\n",
       "               1.5998\n",
       "               1.5056\n",
       "               1.4072\n",
       "               1.0221\n",
       "               1.2057\n",
       "               1.0425\n",
       "               0.7461\n",
       "               0.9074\n",
       "               1.0524\n",
       "               0.8377\n",
       "               1.2921\n",
       "               0.8626\n",
       "               0.6262\n",
       "               0.8742\n",
       "               0.7557\n",
       "               1.2140\n",
       "               0.8530\n",
       "               0.9288\n",
       "               0.8212\n",
       "               0.6899\n",
       "               1.5637\n",
       "               1.3977\n",
       "               0.5771\n",
       "               1.0185\n",
       "               0.7237\n",
       "               0.7526\n",
       "               1.0072\n",
       "               0.5402\n",
       "               1.3419\n",
       "               1.1645\n",
       "               0.7382\n",
       "               1.4382\n",
       "               0.9399\n",
       "               0.8827\n",
       "               0.7566\n",
       "               1.1818\n",
       "               1.5091\n",
       "               0.7032\n",
       "               1.2821\n",
       "               0.7690\n",
       "               0.7584\n",
       "               0.8760\n",
       "               1.0463\n",
       "               0.7401\n",
       "               1.3728\n",
       "               0.9862\n",
       "               0.5867\n",
       "               0.7075\n",
       "               0.8768\n",
       "               0.6995\n",
       "               1.0203\n",
       "               0.8636\n",
       "               0.8471\n",
       "               0.7901\n",
       "               0.7372\n",
       "               1.0807\n",
       "               0.3736\n",
       "               1.2454\n",
       "               1.2259\n",
       "               1.3086\n",
       "               0.9793\n",
       "               0.7220\n",
       "               0.9179\n",
       "               1.0533\n",
       "               1.0965\n",
       "               0.6448\n",
       "               0.9389\n",
       "               1.0853\n",
       "               0.8869\n",
       "               1.0118\n",
       "               1.0673\n",
       "               0.8560\n",
       "               1.3238\n",
       "               1.4932\n",
       "               0.7538\n",
       "               1.0862\n",
       "               1.2796\n",
       "               1.3195\n",
       "               0.7455\n",
       "               0.8468\n",
       "               0.9321\n",
       "               1.1097\n",
       "               0.6106\n",
       "               0.8523\n",
       "               0.7018\n",
       "               0.5828\n",
       "               0.6679\n",
       "               1.0411\n",
       "               0.8751\n",
       "               1.5487\n",
       "               1.2526\n",
       "               0.7080\n",
       "               0.6428\n",
       "               0.0751\n",
       "               0.7074\n",
       "               0.6535\n",
       "               0.9719\n",
       "               0.8368\n",
       "               0.9539\n",
       "               1.1316\n",
       "               0.9002\n",
       "               1.0643\n",
       "               0.4134\n",
       "               0.5461\n",
       "               1.5449\n",
       "               0.7169\n",
       "               1.0412\n",
       "               0.9962\n",
       "               0.9332\n",
       "               0.6508\n",
       "               1.3312\n",
       "               0.7252\n",
       "               1.0150\n",
       "               0.7966\n",
       "               0.8596\n",
       "               0.9372\n",
       "               0.7099\n",
       "               0.8933\n",
       "               1.5739\n",
       "               1.1079\n",
       "               1.0118\n",
       "               0.7937\n",
       "               0.7166\n",
       "               1.1381\n",
       "               0.8597\n",
       "               0.4546\n",
       "               0.4120\n",
       "               1.1729\n",
       "               0.7115\n",
       "               0.7488\n",
       "               0.3631\n",
       "               1.2259\n",
       "               1.3520\n",
       "               0.6223\n",
       "               0.9367\n",
       "               0.7239\n",
       "               0.9822\n",
       "               1.1466\n",
       "               0.8061\n",
       "               0.8094\n",
       "               0.9409\n",
       "               0.9936\n",
       "               0.7890\n",
       "               0.7134\n",
       "               1.2018\n",
       "               0.8395\n",
       "               0.6946\n",
       "               0.9330\n",
       "               1.2076\n",
       "               0.8050\n",
       "               1.4107\n",
       "               1.1894\n",
       "               1.2800\n",
       "               0.3375\n",
       "               1.5606\n",
       "               1.2016\n",
       "               1.1842\n",
       "               0.8018\n",
       "               0.9087\n",
       "               0.7886\n",
       "               0.9719\n",
       "               0.4798\n",
       "               0.3726\n",
       "               0.8601\n",
       "               0.9040\n",
       "               0.8668\n",
       "               1.2283\n",
       "               1.2291\n",
       "               0.8161\n",
       "               1.0394\n",
       "               0.9630\n",
       "               0.7064\n",
       "               0.8070\n",
       "               1.5656\n",
       "               0.1783\n",
       "               0.6763\n",
       "               1.3717\n",
       "               0.7407\n",
       "               1.2988\n",
       "               0.5850\n",
       "               0.7984\n",
       "               1.1113\n",
       "               1.0675\n",
       "               1.0892\n",
       "               1.0029\n",
       "               0.7816\n",
       "               0.4690\n",
       "               1.3441\n",
       "               1.6888\n",
       "               0.5094\n",
       "               1.0360\n",
       "               1.3811\n",
       "               0.8310\n",
       "               0.5969\n",
       "               0.7043\n",
       "               1.2693\n",
       "               1.1464\n",
       "               1.2866\n",
       "               0.7195\n",
       "               1.2379\n",
       "              [torch.cuda.FloatTensor of size 256 (GPU 0)]),\n",
       "             ('conv5.batchnorm.bias', \n",
       "              -0.8383\n",
       "              -0.6392\n",
       "               0.2303\n",
       "              -1.4200\n",
       "              -0.6139\n",
       "              -0.3503\n",
       "              -0.5072\n",
       "              -0.4680\n",
       "              -0.7516\n",
       "              -0.7052\n",
       "              -0.4123\n",
       "              -0.3954\n",
       "              -0.5588\n",
       "               0.0298\n",
       "              -0.6930\n",
       "              -1.0891\n",
       "              -0.1329\n",
       "              -0.7604\n",
       "              -0.4062\n",
       "              -0.4206\n",
       "              -0.8588\n",
       "              -0.5050\n",
       "              -0.2121\n",
       "              -0.5974\n",
       "              -0.8471\n",
       "               0.1013\n",
       "              -0.4789\n",
       "              -0.8312\n",
       "              -0.7070\n",
       "              -0.2832\n",
       "              -0.7096\n",
       "              -0.3157\n",
       "              -1.1860\n",
       "              -0.2086\n",
       "              -0.3035\n",
       "              -0.5310\n",
       "              -0.3034\n",
       "              -0.2304\n",
       "              -0.5557\n",
       "              -0.8629\n",
       "              -0.8208\n",
       "              -0.7899\n",
       "              -0.6822\n",
       "              -0.6943\n",
       "              -0.7488\n",
       "              -0.9780\n",
       "              -0.6136\n",
       "              -0.1391\n",
       "              -0.3890\n",
       "              -0.6650\n",
       "              -0.7743\n",
       "              -0.4235\n",
       "              -0.8517\n",
       "              -0.2832\n",
       "              -0.6349\n",
       "              -0.5439\n",
       "              -1.2899\n",
       "              -0.5341\n",
       "              -0.0248\n",
       "              -0.6555\n",
       "              -0.5281\n",
       "              -0.9384\n",
       "              -0.8055\n",
       "              -0.4708\n",
       "              -0.7866\n",
       "               0.0563\n",
       "              -0.3974\n",
       "              -0.9124\n",
       "              -0.4353\n",
       "              -0.9093\n",
       "              -0.7467\n",
       "              -0.7744\n",
       "              -0.6238\n",
       "              -0.3593\n",
       "              -0.4343\n",
       "              -0.5613\n",
       "              -0.8925\n",
       "              -1.0826\n",
       "              -0.7627\n",
       "              -0.3255\n",
       "              -0.8060\n",
       "              -0.5426\n",
       "              -0.7584\n",
       "               0.0865\n",
       "              -0.2785\n",
       "              -0.4571\n",
       "              -0.8092\n",
       "              -1.5647\n",
       "              -0.5339\n",
       "              -0.3729\n",
       "              -0.5370\n",
       "              -0.4793\n",
       "              -0.2350\n",
       "              -0.8955\n",
       "              -0.7061\n",
       "              -0.6152\n",
       "              -0.6179\n",
       "              -0.0803\n",
       "              -0.5763\n",
       "              -0.2100\n",
       "              -0.3563\n",
       "              -0.6285\n",
       "              -0.6192\n",
       "              -0.6825\n",
       "              -0.6324\n",
       "              -0.7366\n",
       "              -0.4810\n",
       "               0.0057\n",
       "              -0.6166\n",
       "              -0.6198\n",
       "              -0.3895\n",
       "              -0.2967\n",
       "              -0.0651\n",
       "               0.0399\n",
       "               0.0386\n",
       "              -0.7651\n",
       "              -0.3933\n",
       "              -0.7990\n",
       "              -0.7141\n",
       "              -0.4002\n",
       "              -0.6939\n",
       "              -0.7377\n",
       "              -0.1775\n",
       "              -0.1032\n",
       "              -0.6786\n",
       "              -0.7236\n",
       "              -0.2254\n",
       "              -0.8545\n",
       "              -0.5667\n",
       "              -0.1532\n",
       "              -0.4914\n",
       "              -0.3487\n",
       "              -0.9896\n",
       "              -0.3425\n",
       "              -0.5400\n",
       "              -0.7360\n",
       "              -0.8920\n",
       "              -0.6916\n",
       "              -0.8441\n",
       "              -0.5701\n",
       "              -0.8434\n",
       "              -0.1432\n",
       "              -0.8820\n",
       "              -0.1365\n",
       "              -0.5695\n",
       "              -1.3020\n",
       "              -0.8590\n",
       "              -0.5168\n",
       "              -0.7929\n",
       "              -0.1843\n",
       "              -0.7981\n",
       "              -0.4170\n",
       "              -0.6576\n",
       "              -0.7151\n",
       "              -0.3269\n",
       "              -0.1123\n",
       "              -0.5503\n",
       "              -0.2368\n",
       "              -0.9495\n",
       "              -0.4689\n",
       "              -0.6372\n",
       "              -0.8588\n",
       "              -0.5817\n",
       "              -0.2441\n",
       "              -0.3073\n",
       "              -0.7962\n",
       "              -0.6601\n",
       "              -0.9073\n",
       "              -0.9089\n",
       "              -0.6569\n",
       "              -0.1548\n",
       "              -0.4956\n",
       "              -0.7929\n",
       "              -0.2587\n",
       "              -1.4259\n",
       "              -0.2351\n",
       "              -0.5853\n",
       "              -0.7557\n",
       "              -0.4875\n",
       "              -1.0398\n",
       "              -0.6939\n",
       "               0.0743\n",
       "              -0.0368\n",
       "              -0.4028\n",
       "              -0.7018\n",
       "              -0.6823\n",
       "              -0.2900\n",
       "              -0.1704\n",
       "              -0.2413\n",
       "              -0.2386\n",
       "              -0.5745\n",
       "              -0.4971\n",
       "              -0.6131\n",
       "               0.0399\n",
       "              -0.4296\n",
       "              -0.5474\n",
       "              -0.4356\n",
       "              -0.1007\n",
       "              -0.4114\n",
       "              -0.5492\n",
       "              -0.6057\n",
       "              -0.4432\n",
       "              -0.5101\n",
       "              -0.2844\n",
       "              -0.3095\n",
       "              -0.7710\n",
       "              -0.7887\n",
       "              -0.5927\n",
       "              -0.1961\n",
       "              -0.7074\n",
       "              -0.6622\n",
       "              -0.7576\n",
       "              -0.5695\n",
       "              -0.5035\n",
       "              -0.6060\n",
       "              -0.1485\n",
       "              -0.4328\n",
       "              -0.3458\n",
       "              -0.8080\n",
       "              -0.6897\n",
       "              -0.9392\n",
       "              -0.7201\n",
       "              -0.9315\n",
       "              -0.9570\n",
       "              -0.7427\n",
       "              -0.5937\n",
       "              -0.8804\n",
       "              -0.4888\n",
       "              -0.6341\n",
       "              -0.7124\n",
       "              -0.1673\n",
       "              -0.5169\n",
       "              -0.6444\n",
       "              -0.7698\n",
       "              -0.4005\n",
       "              -0.7268\n",
       "              -0.7566\n",
       "              -0.6574\n",
       "              -0.4271\n",
       "              -0.2834\n",
       "              -0.1090\n",
       "              -0.4332\n",
       "               0.1434\n",
       "              -0.7873\n",
       "              -1.3589\n",
       "              -0.2782\n",
       "              -0.5010\n",
       "              -0.3509\n",
       "              -0.2783\n",
       "              -0.3726\n",
       "              -0.8388\n",
       "              -1.0764\n",
       "              -0.7235\n",
       "              -0.7026\n",
       "              -0.3651\n",
       "              -0.4435\n",
       "              [torch.cuda.FloatTensor of size 256 (GPU 0)]),\n",
       "             ('conv5.batchnorm.running_mean', \n",
       "               -38.5591\n",
       "               -56.2146\n",
       "               -40.6085\n",
       "               -66.5002\n",
       "                30.1663\n",
       "              -108.2041\n",
       "                95.2768\n",
       "              -137.8175\n",
       "                 6.1961\n",
       "               -69.1272\n",
       "              -136.4081\n",
       "               -51.4450\n",
       "               -55.0276\n",
       "               -83.1925\n",
       "               -15.4793\n",
       "               -26.5555\n",
       "               -65.1539\n",
       "                38.6379\n",
       "              -130.9624\n",
       "               -67.5976\n",
       "               -39.9337\n",
       "               -73.9349\n",
       "               -55.0655\n",
       "               -59.6736\n",
       "               -47.4416\n",
       "               -24.7283\n",
       "                38.6205\n",
       "                29.1390\n",
       "               -17.4198\n",
       "               -90.8461\n",
       "               -61.1200\n",
       "               -33.4725\n",
       "               -64.0035\n",
       "               -21.8171\n",
       "               -61.1067\n",
       "               -80.9410\n",
       "               -21.6357\n",
       "               -99.5457\n",
       "               -40.7978\n",
       "               -65.9644\n",
       "               -67.8316\n",
       "                -8.8206\n",
       "               -34.3205\n",
       "              -132.5276\n",
       "               -63.5283\n",
       "               -66.0287\n",
       "               -34.7634\n",
       "              -146.2921\n",
       "               -61.9114\n",
       "              -101.8028\n",
       "               -49.4944\n",
       "               -59.2811\n",
       "               -39.4403\n",
       "              -134.8913\n",
       "               -77.0809\n",
       "               -41.1713\n",
       "               -47.9935\n",
       "               -33.1235\n",
       "               -55.6044\n",
       "               -18.9954\n",
       "               -45.7574\n",
       "               -44.8452\n",
       "                 2.5231\n",
       "               -48.6213\n",
       "               -99.7315\n",
       "               -25.1093\n",
       "               -77.9605\n",
       "                31.5884\n",
       "                -0.8020\n",
       "               -49.5545\n",
       "              -101.7088\n",
       "               -64.3611\n",
       "               -90.2435\n",
       "                -8.6318\n",
       "               -94.9791\n",
       "               -76.5448\n",
       "               -52.7634\n",
       "               -62.5037\n",
       "                 8.2958\n",
       "               -27.4667\n",
       "               -57.4585\n",
       "               -30.3670\n",
       "               -26.3180\n",
       "               -59.6237\n",
       "               -59.4124\n",
       "               -70.7743\n",
       "                -5.7339\n",
       "               -64.1612\n",
       "               -71.7842\n",
       "               -56.9273\n",
       "               -50.9602\n",
       "               -34.1775\n",
       "               -94.4509\n",
       "               -28.7128\n",
       "               -77.7127\n",
       "               -48.6667\n",
       "               -67.6887\n",
       "               -49.7805\n",
       "               -40.9663\n",
       "               -42.0874\n",
       "               -37.6361\n",
       "                -1.8906\n",
       "               -19.4297\n",
       "               -46.0543\n",
       "               -56.3858\n",
       "               -48.0900\n",
       "               -69.4093\n",
       "               -70.6538\n",
       "               -91.0410\n",
       "              -111.4150\n",
       "               -59.9784\n",
       "               -46.7129\n",
       "               -38.8859\n",
       "              -109.7080\n",
       "               -50.2361\n",
       "               -82.4080\n",
       "               -49.4962\n",
       "                 9.9196\n",
       "               -87.6673\n",
       "              -133.5412\n",
       "               -73.7722\n",
       "                -8.4375\n",
       "               -62.0377\n",
       "               -37.5937\n",
       "               -65.7422\n",
       "                -4.7110\n",
       "               -35.7046\n",
       "               -81.7747\n",
       "               -55.6561\n",
       "               -11.6018\n",
       "               -83.0039\n",
       "               -38.1450\n",
       "               -68.1217\n",
       "               -60.4061\n",
       "               -70.6902\n",
       "              -103.3513\n",
       "               -41.6972\n",
       "               -85.8044\n",
       "               -22.9747\n",
       "               -78.3435\n",
       "               -22.0066\n",
       "              -105.9373\n",
       "               -67.4782\n",
       "               -53.6449\n",
       "                -9.9105\n",
       "               -47.5667\n",
       "               -23.1906\n",
       "               -77.2501\n",
       "                25.8347\n",
       "              -145.0670\n",
       "               -76.1722\n",
       "               -19.4368\n",
       "                14.5545\n",
       "              -102.4308\n",
       "               -29.8733\n",
       "               -44.7576\n",
       "                 2.1998\n",
       "               -42.3576\n",
       "               -30.2461\n",
       "               -38.9228\n",
       "               -38.4783\n",
       "                 5.5182\n",
       "                34.1619\n",
       "               -40.3834\n",
       "               -66.3730\n",
       "                -8.0150\n",
       "               -92.3698\n",
       "               -32.2328\n",
       "               -13.5167\n",
       "               -90.3079\n",
       "               -16.1877\n",
       "                -5.2060\n",
       "               -45.6261\n",
       "                 9.6149\n",
       "               -36.6172\n",
       "               -40.4891\n",
       "               -35.6832\n",
       "               -36.8691\n",
       "              -112.7088\n",
       "                22.9446\n",
       "               -89.6244\n",
       "              -200.4651\n",
       "               -94.7633\n",
       "               -10.1649\n",
       "                19.2250\n",
       "                41.2153\n",
       "              -115.4818\n",
       "               -54.3077\n",
       "               -59.1215\n",
       "              -124.7751\n",
       "                -9.1251\n",
       "               -90.0805\n",
       "               -38.3571\n",
       "               -47.9357\n",
       "                28.4172\n",
       "              -111.1267\n",
       "              -121.7865\n",
       "              -117.4780\n",
       "               -10.9981\n",
       "               -70.7596\n",
       "               -54.0497\n",
       "               -84.7692\n",
       "               -38.6149\n",
       "               -45.0224\n",
       "               -57.3985\n",
       "               -88.3873\n",
       "               -20.7293\n",
       "               -51.4450\n",
       "               -46.7640\n",
       "               -43.2342\n",
       "               -53.8795\n",
       "               -75.5075\n",
       "               -13.2956\n",
       "              -121.5349\n",
       "               -49.1857\n",
       "               -57.7111\n",
       "                -0.2557\n",
       "              -132.8282\n",
       "               -38.0585\n",
       "                -4.0173\n",
       "               -57.0196\n",
       "                47.9099\n",
       "               -80.8251\n",
       "               -83.2747\n",
       "                -0.9298\n",
       "               -62.5026\n",
       "                 4.1745\n",
       "               -87.8491\n",
       "               -13.9878\n",
       "               -52.0716\n",
       "              -163.7231\n",
       "               -73.1836\n",
       "                -7.3152\n",
       "               -43.6020\n",
       "               -39.2528\n",
       "                -7.2670\n",
       "               -12.5947\n",
       "               -57.4477\n",
       "               -91.9422\n",
       "               -96.6381\n",
       "               -72.7366\n",
       "               -75.1682\n",
       "               -88.1025\n",
       "               -80.4029\n",
       "               -30.5994\n",
       "              -106.7459\n",
       "               -44.9920\n",
       "               -60.4197\n",
       "              -102.6558\n",
       "              -153.0665\n",
       "                -0.8946\n",
       "               -46.6212\n",
       "               -47.1546\n",
       "               -58.3421\n",
       "               -52.8918\n",
       "               -95.3125\n",
       "              [torch.cuda.FloatTensor of size 256 (GPU 0)]),\n",
       "             ('conv5.batchnorm.running_var', \n",
       "                2284.6055\n",
       "                2228.6848\n",
       "                3814.5278\n",
       "                1413.7272\n",
       "                3955.9036\n",
       "                2333.0063\n",
       "                5070.7065\n",
       "                6953.1924\n",
       "                3303.4478\n",
       "                3002.3208\n",
       "                6328.6118\n",
       "                1867.0909\n",
       "                2755.9329\n",
       "                2721.4502\n",
       "                3452.2708\n",
       "                1272.3914\n",
       "                2968.9763\n",
       "                2605.2100\n",
       "                7312.6572\n",
       "                4305.5122\n",
       "                2399.0249\n",
       "                3025.1128\n",
       "                2997.4509\n",
       "                1658.4482\n",
       "                2037.3262\n",
       "                2557.9097\n",
       "                4241.4092\n",
       "                2761.8850\n",
       "                2316.6609\n",
       "                3639.8943\n",
       "                4120.8042\n",
       "                3278.6870\n",
       "                1183.9734\n",
       "                2640.8237\n",
       "                1653.4260\n",
       "                4031.7681\n",
       "                1760.0446\n",
       "                4357.3984\n",
       "                1623.9944\n",
       "                1868.9316\n",
       "                2183.5015\n",
       "                3075.2803\n",
       "                2058.4287\n",
       "                3776.8413\n",
       "                2980.0884\n",
       "                1922.4486\n",
       "                3031.7839\n",
       "                7362.8828\n",
       "                2318.0938\n",
       "                3396.2705\n",
       "                2130.4893\n",
       "                2531.1135\n",
       "                1295.9182\n",
       "                6469.1968\n",
       "                3131.8967\n",
       "                3871.7407\n",
       "                1045.2941\n",
       "                2077.0928\n",
       "                4172.2188\n",
       "                2301.4829\n",
       "                1622.3721\n",
       "                2322.2095\n",
       "                2947.7234\n",
       "                2550.8806\n",
       "                2330.7554\n",
       "                2486.2639\n",
       "                1991.2275\n",
       "                2864.5872\n",
       "                4782.1729\n",
       "                2176.2275\n",
       "                2565.7026\n",
       "                1662.5691\n",
       "                3556.7278\n",
       "                3438.1577\n",
       "                2434.4905\n",
       "                2375.9692\n",
       "                1938.1390\n",
       "                1354.5426\n",
       "                3467.0493\n",
       "                2942.5139\n",
       "                3009.5457\n",
       "                2848.4944\n",
       "                4276.5029\n",
       "                3791.6514\n",
       "                2472.1431\n",
       "                2414.9897\n",
       "                2404.4495\n",
       "                 985.3277\n",
       "                2969.1694\n",
       "                3927.6218\n",
       "                2451.4382\n",
       "                2471.0781\n",
       "                3146.3608\n",
       "                4806.2227\n",
       "                1856.3353\n",
       "                3071.8918\n",
       "                3116.1409\n",
       "                2980.1338\n",
       "                2688.3225\n",
       "                3248.7271\n",
       "                2542.0532\n",
       "                2671.2778\n",
       "                3372.7861\n",
       "                3268.5723\n",
       "                2800.7744\n",
       "                3128.2344\n",
       "                2162.1331\n",
       "                3612.7935\n",
       "                1867.5282\n",
       "                2068.1753\n",
       "                4227.7607\n",
       "                2144.3555\n",
       "                9093.7080\n",
       "                4593.2222\n",
       "                3381.0884\n",
       "                2781.0559\n",
       "                1870.6602\n",
       "                3091.5825\n",
       "                2183.7830\n",
       "                3590.6580\n",
       "                2233.0447\n",
       "                3701.7478\n",
       "                3452.2083\n",
       "                2737.4695\n",
       "                2579.8184\n",
       "                2898.0601\n",
       "                4289.4048\n",
       "                2264.0527\n",
       "                1471.2257\n",
       "                4769.1333\n",
       "                2972.4507\n",
       "                2720.3501\n",
       "                1404.8379\n",
       "                1884.2784\n",
       "                3093.8608\n",
       "                3206.6030\n",
       "                1971.8391\n",
       "                1711.0487\n",
       "                5393.4849\n",
       "                4835.5996\n",
       "                2981.0259\n",
       "                2434.5916\n",
       "                2771.9685\n",
       "                1888.3594\n",
       "                3005.0452\n",
       "                1263.0665\n",
       "                1883.4805\n",
       "                3644.1609\n",
       "                3091.3181\n",
       "                7248.9272\n",
       "                7186.5942\n",
       "                5807.9443\n",
       "                2286.4824\n",
       "                2109.4004\n",
       "                2906.1384\n",
       "                2683.4944\n",
       "                2941.2637\n",
       "                1996.3510\n",
       "                1262.1875\n",
       "                2384.6707\n",
       "                1874.8376\n",
       "                2248.8884\n",
       "                3685.4221\n",
       "                2108.6538\n",
       "                2709.6951\n",
       "                4277.5698\n",
       "                2014.9017\n",
       "                2551.6169\n",
       "                1255.5773\n",
       "                2532.0469\n",
       "                2572.6030\n",
       "                2668.3879\n",
       "                4076.4539\n",
       "                2432.2473\n",
       "                 977.5982\n",
       "                1809.6963\n",
       "                4415.9233\n",
       "                2298.4998\n",
       "                3348.6628\n",
       "                2064.7932\n",
       "                2635.5469\n",
       "               11185.2871\n",
       "                6836.3589\n",
       "                2965.6433\n",
       "                3308.9507\n",
       "                4885.5972\n",
       "                4958.2109\n",
       "                2934.9243\n",
       "                2028.2495\n",
       "               10532.7148\n",
       "                2080.0627\n",
       "                2928.9250\n",
       "                2896.4998\n",
       "                2704.3325\n",
       "                3131.3328\n",
       "                4223.7607\n",
       "                2448.8323\n",
       "                3631.5850\n",
       "                4255.9453\n",
       "                2441.7024\n",
       "                2030.7366\n",
       "                3069.7190\n",
       "                4649.4224\n",
       "                3480.4612\n",
       "                2666.6799\n",
       "                7731.7837\n",
       "                2259.4004\n",
       "                1977.5212\n",
       "                4571.5366\n",
       "                1923.6448\n",
       "                2295.1777\n",
       "                1765.4957\n",
       "                3471.7517\n",
       "                4436.2827\n",
       "                3323.7417\n",
       "                3559.8218\n",
       "                1951.8202\n",
       "                5408.5806\n",
       "                1308.3252\n",
       "                2721.7317\n",
       "                1679.6545\n",
       "                3048.6567\n",
       "                2136.8416\n",
       "                1327.6100\n",
       "                2392.6531\n",
       "                3094.7966\n",
       "                2468.1970\n",
       "                3282.0842\n",
       "                3381.7385\n",
       "                1751.8013\n",
       "               10559.9326\n",
       "                2282.6074\n",
       "                2187.3416\n",
       "                3956.6572\n",
       "                2520.9431\n",
       "                4324.8755\n",
       "                3598.2715\n",
       "                2071.2307\n",
       "                2369.0134\n",
       "                1882.6270\n",
       "                2481.7656\n",
       "                2837.4365\n",
       "                4134.0488\n",
       "                1830.9548\n",
       "                1056.2380\n",
       "                3602.9827\n",
       "                2818.9170\n",
       "                2574.3806\n",
       "                3423.4753\n",
       "                8747.1611\n",
       "                2555.1606\n",
       "                1369.0381\n",
       "                2190.8867\n",
       "                1964.6511\n",
       "                3440.7566\n",
       "                2635.9895\n",
       "              [torch.cuda.FloatTensor of size 256 (GPU 0)]),\n",
       "             ('conv6.conv.weight', \n",
       "              ( 0 , 0 , 0 ,.,.) = \n",
       "                1.5592e-01  1.0339e+00  1.0405e+00\n",
       "                2.3471e-01  7.1362e-01  1.0365e+00\n",
       "                5.4125e-01  5.4800e-01  5.5169e-01\n",
       "              \n",
       "              ( 0 , 0 , 1 ,.,.) = \n",
       "               -4.9214e-01  1.8489e-01  2.8107e-01\n",
       "               -3.1280e-01  2.2113e-01  1.9727e-01\n",
       "                1.1061e-01  8.1512e-03  1.9528e-01\n",
       "              \n",
       "              ( 0 , 0 , 2 ,.,.) = \n",
       "               -3.0619e-01  6.6159e-01  6.4394e-01\n",
       "               -3.8310e-01  8.4417e-01  7.1732e-01\n",
       "               -6.5032e-02  3.6833e-01  1.9131e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 0 , 1 , 0 ,.,.) = \n",
       "               -3.4599e-02  3.1105e-01  4.9644e-01\n",
       "               -3.4755e-01 -3.3840e-01  2.1924e-01\n",
       "               -8.6204e-01 -3.2907e-01  1.0068e+00\n",
       "              \n",
       "              ( 0 , 1 , 1 ,.,.) = \n",
       "                7.8267e-02 -3.9702e-02 -6.2710e-02\n",
       "               -1.7004e-01 -6.3714e-01 -3.4266e-01\n",
       "               -7.3955e-01 -5.9958e-01  4.8634e-01\n",
       "              \n",
       "              ( 0 , 1 , 2 ,.,.) = \n",
       "                4.8702e-01  3.9103e-01 -7.6237e-02\n",
       "                3.1594e-01 -1.8591e-01 -2.6676e-01\n",
       "               -2.2023e-01 -1.6734e-01  4.6142e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 0 , 2 , 0 ,.,.) = \n",
       "                1.8982e-01 -3.3014e-02 -2.8251e-01\n",
       "                2.4060e-01 -5.3713e-01 -6.1149e-01\n",
       "                1.1475e-01 -9.0496e-01 -9.9274e-01\n",
       "              \n",
       "              ( 0 , 2 , 1 ,.,.) = \n",
       "                2.0082e-01  1.6666e-01  2.0405e-01\n",
       "                2.0427e-01 -2.0664e-01 -1.5800e-01\n",
       "               -8.1715e-02 -3.9188e-01 -2.6417e-01\n",
       "              \n",
       "              ( 0 , 2 , 2 ,.,.) = \n",
       "                1.0718e-01  1.2916e-01  2.8347e-01\n",
       "                1.1150e-01 -1.7677e-01  2.3801e-02\n",
       "               -2.1454e-01 -3.7078e-01 -4.0779e-02\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              ( 0 ,253, 0 ,.,.) = \n",
       "                3.6990e-01 -7.5838e-02 -5.0794e-01\n",
       "                5.1942e-01 -8.2857e-02 -2.2121e-02\n",
       "                1.2501e+00  7.0426e-01  4.9020e-01\n",
       "              \n",
       "              ( 0 ,253, 1 ,.,.) = \n",
       "                2.5301e-01 -6.0304e-01 -1.1656e+00\n",
       "                5.2730e-01 -6.5636e-01 -7.2666e-01\n",
       "                1.2556e+00  3.7916e-01 -4.6917e-02\n",
       "              \n",
       "              ( 0 ,253, 2 ,.,.) = \n",
       "                6.3301e-01 -5.4475e-01 -1.2933e+00\n",
       "                7.1068e-01 -6.0090e-01 -9.3009e-01\n",
       "                1.1542e+00  4.1248e-01  4.1697e-02\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 0 ,254, 0 ,.,.) = \n",
       "                1.2781e-01  3.5433e-01  5.3275e-01\n",
       "                3.6780e-01  2.5964e-01  2.4728e-01\n",
       "                2.7303e-01  2.2771e-02  7.6153e-03\n",
       "              \n",
       "              ( 0 ,254, 1 ,.,.) = \n",
       "                2.2566e-01  3.6705e-01  4.0542e-01\n",
       "                4.6414e-01  3.1795e-01  2.5841e-01\n",
       "                5.0221e-01  1.6131e-01  9.3056e-02\n",
       "              \n",
       "              ( 0 ,254, 2 ,.,.) = \n",
       "                2.9794e-01  3.0645e-01  4.4321e-02\n",
       "                5.8699e-01  2.8125e-01 -6.0821e-02\n",
       "                5.7280e-01  7.5494e-02  7.9531e-03\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 0 ,255, 0 ,.,.) = \n",
       "               -2.7972e-01 -1.2101e-01 -6.6058e-02\n",
       "               -2.2649e-01 -4.7826e-02 -4.6307e-02\n",
       "               -2.2862e-01 -1.6237e-01  1.6214e-01\n",
       "              \n",
       "              ( 0 ,255, 1 ,.,.) = \n",
       "               -2.4358e-01 -4.5952e-01 -4.1629e-01\n",
       "               -2.5758e-01 -5.7526e-01 -4.4533e-01\n",
       "               -2.1073e-01 -5.4722e-01  7.8037e-02\n",
       "              \n",
       "              ( 0 ,255, 2 ,.,.) = \n",
       "               -1.0072e+00 -8.1077e-01  3.5142e-02\n",
       "               -5.9780e-01 -8.1683e-01 -3.5458e-01\n",
       "               -4.2308e-01 -6.0207e-01  1.1927e-01\n",
       "                    â‹®   â‹®  \n",
       "              \n",
       "              ( 1 , 0 , 0 ,.,.) = \n",
       "               -7.2226e-01 -3.7933e-01 -5.7390e-01\n",
       "               -4.1902e-01  7.4325e-02 -3.1111e-01\n",
       "               -4.0960e-01  3.7862e-01  9.1874e-02\n",
       "              \n",
       "              ( 1 , 0 , 1 ,.,.) = \n",
       "               -9.4591e-02  9.1777e-02  3.0942e-01\n",
       "               -5.0961e-02  2.5224e-01  6.5114e-01\n",
       "               -3.1499e-01  3.1186e-01  6.5141e-01\n",
       "              \n",
       "              ( 1 , 0 , 2 ,.,.) = \n",
       "               -2.4548e-01  1.1937e-01  6.1499e-01\n",
       "                3.5459e-02  3.1677e-01  5.5811e-01\n",
       "               -5.6181e-02  2.4129e-01  2.3406e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 1 , 1 , 0 ,.,.) = \n",
       "               -2.3599e-01  5.0759e-01  2.6150e-01\n",
       "                1.7314e-01  3.8382e-01  1.9118e-01\n",
       "               -2.6156e-02 -3.0607e-01  2.8367e-01\n",
       "              \n",
       "              ( 1 , 1 , 1 ,.,.) = \n",
       "               -1.0304e+00 -1.2578e-01 -1.3414e-01\n",
       "               -8.1318e-01 -2.3541e-01 -2.0807e-01\n",
       "               -5.7229e-01 -3.9163e-01  1.2377e-01\n",
       "              \n",
       "              ( 1 , 1 , 2 ,.,.) = \n",
       "               -8.3646e-01 -4.7193e-01 -2.2502e-01\n",
       "               -8.8798e-01 -6.7608e-01 -2.1468e-01\n",
       "               -6.7120e-01 -8.0360e-01 -3.1471e-02\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 1 , 2 , 0 ,.,.) = \n",
       "               -2.3791e-01 -3.6240e-02 -1.5343e-02\n",
       "               -2.7019e-01 -1.0491e-02 -8.9892e-02\n",
       "                8.9591e-02  2.2762e-01 -1.1767e-02\n",
       "              \n",
       "              ( 1 , 2 , 1 ,.,.) = \n",
       "                1.9601e-01  1.1194e-01 -4.1502e-02\n",
       "                3.2879e-01  3.6680e-01  1.4117e-01\n",
       "                5.5091e-01  4.9946e-01  2.2166e-01\n",
       "              \n",
       "              ( 1 , 2 , 2 ,.,.) = \n",
       "                6.3118e-01  3.9951e-01  6.9284e-02\n",
       "                7.8267e-01  6.3806e-01  2.7613e-01\n",
       "                8.9787e-01  7.7767e-01  4.1211e-01\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              ( 1 ,253, 0 ,.,.) = \n",
       "                1.2795e-01  1.2389e-01  1.9249e-01\n",
       "               -7.4147e-03 -2.0699e-01 -4.1780e-01\n",
       "               -3.0466e-01 -5.0070e-01 -6.7060e-01\n",
       "              \n",
       "              ( 1 ,253, 1 ,.,.) = \n",
       "               -4.0858e-01 -1.4672e-01  5.2203e-02\n",
       "               -2.8928e-01 -3.6100e-01 -4.7860e-01\n",
       "               -7.1468e-01 -6.3794e-01 -7.6664e-01\n",
       "              \n",
       "              ( 1 ,253, 2 ,.,.) = \n",
       "               -6.4441e-01 -1.5377e-01 -1.9543e-01\n",
       "               -3.6599e-01  7.7815e-02 -2.0675e-01\n",
       "               -5.8815e-01  1.4833e-02 -2.9685e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 1 ,254, 0 ,.,.) = \n",
       "               -1.6243e-01 -2.8758e-02 -1.7684e-01\n",
       "                3.5085e-01  1.2207e-01 -5.8353e-02\n",
       "                3.2045e-01  9.5504e-02 -6.5843e-03\n",
       "              \n",
       "              ( 1 ,254, 1 ,.,.) = \n",
       "               -2.6971e-01 -2.5619e-01 -1.4356e-01\n",
       "                7.0896e-02 -2.7002e-01 -6.4414e-02\n",
       "                1.1838e-01 -1.7600e-01 -1.5196e-01\n",
       "              \n",
       "              ( 1 ,254, 2 ,.,.) = \n",
       "                2.6650e-01  1.5115e-01  7.9614e-02\n",
       "                4.6410e-01 -2.6903e-02 -8.4179e-02\n",
       "                4.3531e-01  6.0839e-02 -1.4374e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 1 ,255, 0 ,.,.) = \n",
       "               -1.9347e-01 -3.2033e-02 -2.1882e-01\n",
       "                1.7226e-02  1.4384e-01 -2.0075e-01\n",
       "               -2.1118e-02  4.1556e-01  9.9807e-02\n",
       "              \n",
       "              ( 1 ,255, 1 ,.,.) = \n",
       "               -9.5688e-01 -2.9974e-01 -1.2050e-01\n",
       "               -7.3174e-01  1.1263e-01  1.3658e-01\n",
       "               -7.2367e-01  4.7776e-01  4.9490e-01\n",
       "              \n",
       "              ( 1 ,255, 2 ,.,.) = \n",
       "               -4.8546e-01 -4.0289e-01 -4.4747e-01\n",
       "               -1.2052e-01  4.6255e-02 -9.7051e-02\n",
       "               -3.3271e-01  2.5232e-01  1.4212e-01\n",
       "                    â‹®   â‹®  \n",
       "              \n",
       "              ( 2 , 0 , 0 ,.,.) = \n",
       "               -6.8337e-02  4.3120e-02  4.8108e-02\n",
       "               -4.8546e-02 -2.6236e-02  3.3554e-02\n",
       "                4.0474e-02 -2.2009e-02  1.3883e-02\n",
       "              \n",
       "              ( 2 , 0 , 1 ,.,.) = \n",
       "               -3.8122e-02  6.3142e-02  8.2515e-02\n",
       "               -2.6737e-02 -9.6595e-03  9.6609e-02\n",
       "                6.2450e-02  7.8206e-03  1.0490e-01\n",
       "              \n",
       "              ( 2 , 0 , 2 ,.,.) = \n",
       "               -1.1419e-01  7.4782e-02  2.6312e-02\n",
       "               -2.8692e-02 -5.1612e-02  1.5937e-02\n",
       "                1.5267e-02 -6.3676e-02  4.6862e-02\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 2 , 1 , 0 ,.,.) = \n",
       "                4.7053e-02  3.9941e-02 -4.0596e-02\n",
       "                7.1868e-02 -4.4609e-02 -9.4407e-03\n",
       "                1.8425e-01  6.3387e-02  8.4830e-02\n",
       "              \n",
       "              ( 2 , 1 , 1 ,.,.) = \n",
       "                1.5400e-02 -6.4818e-03 -4.5539e-02\n",
       "                4.7202e-02 -8.2220e-02  7.3420e-03\n",
       "                1.4438e-01  2.8084e-02  8.0821e-02\n",
       "              \n",
       "              ( 2 , 1 , 2 ,.,.) = \n",
       "                3.8005e-02 -3.6167e-02  1.7935e-02\n",
       "                7.3435e-02 -3.4553e-02  7.4677e-02\n",
       "                1.9194e-01 -2.5342e-03  1.0765e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 2 , 2 , 0 ,.,.) = \n",
       "               -1.0498e-01  6.8440e-02  4.0906e-02\n",
       "               -7.2095e-02 -3.9930e-02  2.4319e-02\n",
       "                8.0594e-02  6.8487e-02  7.3019e-02\n",
       "              \n",
       "              ( 2 , 2 , 1 ,.,.) = \n",
       "               -6.1226e-02  1.2154e-01  2.5334e-02\n",
       "                6.6312e-02  2.8638e-02  4.4368e-02\n",
       "                1.2211e-01  1.5773e-01  8.6475e-02\n",
       "              \n",
       "              ( 2 , 2 , 2 ,.,.) = \n",
       "               -1.3067e-01  1.0697e-02  9.9430e-03\n",
       "                7.3984e-03 -4.7406e-02 -1.2566e-02\n",
       "                1.0292e-01  1.1224e-01  9.9013e-02\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              ( 2 ,253, 0 ,.,.) = \n",
       "               -1.0529e-01 -1.0311e-01 -1.3656e-01\n",
       "               -2.4486e-01 -8.4100e-02 -1.2731e-01\n",
       "               -1.8269e-01 -1.1376e-01 -1.4178e-01\n",
       "              \n",
       "              ( 2 ,253, 1 ,.,.) = \n",
       "               -1.6326e-01 -1.6379e-01 -1.5473e-01\n",
       "               -2.1469e-01 -8.7541e-02 -1.1687e-01\n",
       "               -1.8021e-01 -1.1803e-01 -1.2065e-01\n",
       "              \n",
       "              ( 2 ,253, 2 ,.,.) = \n",
       "               -1.4814e-01 -2.1058e-01 -1.5207e-01\n",
       "               -2.3623e-01 -1.0901e-01 -1.6523e-01\n",
       "               -1.7038e-01 -1.5201e-01 -1.8394e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 2 ,254, 0 ,.,.) = \n",
       "                6.5335e-02  2.8225e-02  1.5638e-02\n",
       "                8.3657e-02  7.1865e-02  6.1096e-02\n",
       "                4.3730e-02  1.0786e-01  1.4586e-02\n",
       "              \n",
       "              ( 2 ,254, 1 ,.,.) = \n",
       "                7.9961e-02  2.4520e-02  1.2825e-02\n",
       "               -1.1799e-02  5.4561e-02  3.7985e-02\n",
       "                5.0098e-02  1.2855e-01  3.8070e-02\n",
       "              \n",
       "              ( 2 ,254, 2 ,.,.) = \n",
       "                4.8266e-02  1.1882e-02  7.0681e-03\n",
       "                1.8134e-03  1.0461e-01  3.6413e-02\n",
       "                1.3448e-02  1.0185e-01  6.7585e-02\n",
       "                        â‹®  \n",
       "              \n",
       "              ( 2 ,255, 0 ,.,.) = \n",
       "               -1.0587e-01  8.4556e-02  1.2587e-01\n",
       "                1.8357e-02 -2.5441e-02  1.3595e-01\n",
       "                1.5772e-01  2.0646e-02  6.5975e-02\n",
       "              \n",
       "              ( 2 ,255, 1 ,.,.) = \n",
       "               -1.2647e-01  7.3007e-02  1.8482e-01\n",
       "                3.7243e-02 -4.4951e-02  8.8327e-02\n",
       "                1.6981e-01  4.2086e-02  7.5940e-02\n",
       "              \n",
       "              ( 2 ,255, 2 ,.,.) = \n",
       "               -9.5488e-02  3.7993e-02  1.8817e-01\n",
       "                6.1155e-02 -3.9680e-02  8.7155e-02\n",
       "                1.9197e-01  2.1343e-02  5.9346e-02\n",
       "              ...         \n",
       "                    â‹®   â‹®  \n",
       "              \n",
       "              (253, 0 , 0 ,.,.) = \n",
       "                1.4977e-01  4.0050e-01  7.4792e-01\n",
       "                7.0133e-02 -3.3454e-01  3.2255e-02\n",
       "                9.7327e-02 -3.4374e-01 -7.4968e-01\n",
       "              \n",
       "              (253, 0 , 1 ,.,.) = \n",
       "                2.1595e-01  2.7618e-01  8.1332e-01\n",
       "               -2.8298e-01 -2.9095e-01  2.3429e-01\n",
       "               -2.7616e-01 -3.4330e-01 -4.6214e-01\n",
       "              \n",
       "              (253, 0 , 2 ,.,.) = \n",
       "                7.8218e-03  2.7653e-02  4.3083e-01\n",
       "               -4.4312e-03 -1.6887e-01  9.8407e-02\n",
       "                1.8490e-01 -1.3499e-01 -5.4319e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (253, 1 , 0 ,.,.) = \n",
       "                1.0467e-02 -4.5900e-02 -3.2299e-01\n",
       "                7.6778e-02  1.0369e-01 -4.8387e-03\n",
       "                5.3277e-01  1.1344e-01  1.6870e-01\n",
       "              \n",
       "              (253, 1 , 1 ,.,.) = \n",
       "               -2.2382e-01  2.0353e-01  2.7406e-01\n",
       "                4.1389e-02  2.8155e-01  4.6701e-01\n",
       "                5.6812e-01  2.7572e-01  5.5549e-01\n",
       "              \n",
       "              (253, 1 , 2 ,.,.) = \n",
       "               -5.0198e-01 -3.5073e-01 -2.7559e-01\n",
       "               -2.4822e-01 -3.0734e-01 -7.1324e-02\n",
       "                3.7203e-01  7.2438e-03  1.5332e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (253, 2 , 0 ,.,.) = \n",
       "               -5.2721e-02  4.3404e-01  6.8323e-01\n",
       "               -2.2584e-01  1.4087e-01  2.0302e-01\n",
       "               -2.3586e-02  1.4861e-01  1.5549e-01\n",
       "              \n",
       "              (253, 2 , 1 ,.,.) = \n",
       "               -3.3364e-01  2.5147e-01  7.5701e-01\n",
       "               -1.1702e-01  1.8498e-01  2.8739e-01\n",
       "                2.3108e-01  2.3234e-01  6.1477e-02\n",
       "              \n",
       "              (253, 2 , 2 ,.,.) = \n",
       "               -6.7814e-01 -2.5229e-01  2.6222e-01\n",
       "               -2.9648e-01 -1.9982e-01 -2.2896e-01\n",
       "                1.6666e-01 -1.5909e-03 -3.5042e-01\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              (253,253, 0 ,.,.) = \n",
       "               -1.7888e-01 -1.5976e-01 -1.7772e-02\n",
       "               -1.8535e-01 -5.1042e-01 -2.3309e-01\n",
       "                1.1361e-01 -9.6563e-01 -4.6458e-01\n",
       "              \n",
       "              (253,253, 1 ,.,.) = \n",
       "               -3.6342e-01 -3.9309e-01 -1.0544e-02\n",
       "               -1.8417e-01 -7.4922e-01  2.6795e-03\n",
       "                1.0286e-01 -9.4071e-01 -2.7016e-01\n",
       "              \n",
       "              (253,253, 2 ,.,.) = \n",
       "               -6.6999e-01 -8.0035e-01 -3.2465e-01\n",
       "               -2.8294e-01 -1.1074e+00 -1.6118e-01\n",
       "               -4.4021e-03 -1.1770e+00 -4.0028e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (253,254, 0 ,.,.) = \n",
       "                1.1282e-02  1.2561e-01 -5.0596e-01\n",
       "               -6.1273e-02 -5.8269e-02 -2.7417e-01\n",
       "               -1.9082e-01 -1.1142e-01 -1.7234e-01\n",
       "              \n",
       "              (253,254, 1 ,.,.) = \n",
       "               -6.7769e-02 -1.9425e-01 -6.9957e-01\n",
       "               -2.4531e-01 -2.4160e-01 -3.5203e-01\n",
       "               -3.9980e-01 -3.1075e-01 -2.2181e-01\n",
       "              \n",
       "              (253,254, 2 ,.,.) = \n",
       "               -9.8096e-02 -1.2245e-01 -5.1228e-01\n",
       "               -2.6755e-01 -2.7731e-01 -2.8688e-01\n",
       "               -4.1620e-01 -2.0934e-01 -9.4871e-02\n",
       "                        â‹®  \n",
       "              \n",
       "              (253,255, 0 ,.,.) = \n",
       "               -9.4547e-01 -1.1808e+00 -7.1608e-01\n",
       "               -6.4971e-01 -1.1890e+00 -7.7759e-01\n",
       "               -5.4520e-01 -5.4941e-01 -7.7837e-01\n",
       "              \n",
       "              (253,255, 1 ,.,.) = \n",
       "                1.7128e-01  1.3895e-01  3.4982e-01\n",
       "               -7.3619e-03 -4.2468e-03  1.4272e-01\n",
       "               -2.4318e-01  1.0976e-01 -4.5103e-02\n",
       "              \n",
       "              (253,255, 2 ,.,.) = \n",
       "                1.3266e-01  2.2768e-01  5.0907e-01\n",
       "               -3.7360e-01 -2.0382e-01 -4.8305e-02\n",
       "               -4.9856e-01 -6.6195e-02 -3.4946e-01\n",
       "                    â‹®   â‹®  \n",
       "              \n",
       "              (254, 0 , 0 ,.,.) = \n",
       "                4.7729e-01 -6.1215e-02  1.3294e-01\n",
       "                6.9760e-01 -3.9431e-02  4.0597e-01\n",
       "                2.2104e-01  5.1130e-02  5.1830e-01\n",
       "              \n",
       "              (254, 0 , 1 ,.,.) = \n",
       "                8.9531e-01  5.4053e-01  2.0582e-01\n",
       "                1.0333e+00  4.8259e-01  5.1348e-01\n",
       "                8.4967e-01  7.5981e-01  8.7576e-01\n",
       "              \n",
       "              (254, 0 , 2 ,.,.) = \n",
       "                9.5026e-01  7.9442e-01  5.5409e-01\n",
       "                1.1497e+00  6.5815e-01  7.3764e-01\n",
       "                9.3846e-01  6.5886e-01  9.1189e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (254, 1 , 0 ,.,.) = \n",
       "               -3.8776e-01 -3.1857e-01  2.9149e-01\n",
       "               -2.2035e-01 -3.8440e-01  9.5890e-02\n",
       "                6.2339e-01 -1.0796e-01 -1.4629e-01\n",
       "              \n",
       "              (254, 1 , 1 ,.,.) = \n",
       "               -1.9893e-01 -4.9423e-02  8.0663e-01\n",
       "                1.8310e-01  5.3345e-02  4.8788e-01\n",
       "                7.3423e-01  1.1840e-01  5.0078e-02\n",
       "              \n",
       "              (254, 1 , 2 ,.,.) = \n",
       "                3.7543e-02 -3.6154e-01  1.6212e-01\n",
       "                2.7575e-01 -3.0599e-02  1.9931e-01\n",
       "                7.5354e-01 -5.4258e-02 -1.7819e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (254, 2 , 0 ,.,.) = \n",
       "               -1.2659e-02 -2.4885e-01 -1.9224e-01\n",
       "                8.7498e-02 -1.8106e-01  9.8925e-02\n",
       "                6.7343e-01  2.6002e-01  3.1044e-01\n",
       "              \n",
       "              (254, 2 , 1 ,.,.) = \n",
       "                8.5028e-02 -1.5615e-01 -2.2731e-01\n",
       "                3.4812e-01  3.3586e-02 -1.7581e-02\n",
       "                9.6473e-01  2.3851e-01  1.6700e-01\n",
       "              \n",
       "              (254, 2 , 2 ,.,.) = \n",
       "                5.2592e-02 -2.6390e-01 -3.9067e-01\n",
       "                2.1710e-01 -4.4372e-02 -3.2814e-01\n",
       "                7.5479e-01  3.4615e-01  6.2670e-02\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              (254,253, 0 ,.,.) = \n",
       "               -3.8011e-01 -4.3626e-01 -4.8746e-01\n",
       "               -2.6085e-01 -1.9501e-01 -2.9187e-01\n",
       "               -7.7136e-01 -7.5754e-01 -9.7699e-01\n",
       "              \n",
       "              (254,253, 1 ,.,.) = \n",
       "                1.4337e-02  2.2276e-01  3.4349e-01\n",
       "                3.7382e-01  5.0625e-01  3.9032e-01\n",
       "               -1.8736e-01 -8.7106e-02 -3.9148e-01\n",
       "              \n",
       "              (254,253, 2 ,.,.) = \n",
       "               -8.2194e-01 -4.7619e-01 -6.3712e-01\n",
       "               -6.7083e-01 -2.2956e-01 -5.8979e-01\n",
       "               -7.5816e-01 -8.0401e-01 -1.2115e+00\n",
       "                        â‹®  \n",
       "              \n",
       "              (254,254, 0 ,.,.) = \n",
       "               -2.8494e-01  2.0867e-01 -6.4493e-02\n",
       "               -9.9066e-02  3.4742e-01  3.5546e-03\n",
       "                9.2103e-02  2.3747e-01  1.6159e-01\n",
       "              \n",
       "              (254,254, 1 ,.,.) = \n",
       "               -4.9811e-02  1.6249e-01 -1.6467e-01\n",
       "                2.9938e-02  2.6950e-01 -4.9743e-01\n",
       "                2.1060e-02  1.9201e-01 -3.4987e-01\n",
       "              \n",
       "              (254,254, 2 ,.,.) = \n",
       "               -2.8434e-01 -3.7631e-02 -2.8072e-01\n",
       "               -2.8903e-01 -1.6328e-01 -6.7090e-01\n",
       "               -3.9985e-01 -4.1054e-01 -7.2641e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (254,255, 0 ,.,.) = \n",
       "                1.9760e-01  4.1281e-01  1.0289e+00\n",
       "               -5.0671e-03  4.5709e-01  9.4053e-01\n",
       "               -1.3832e-01 -1.2823e-01  5.6066e-01\n",
       "              \n",
       "              (254,255, 1 ,.,.) = \n",
       "                8.5712e-01  8.6260e-01  9.8415e-01\n",
       "                6.3912e-01  7.8194e-01  9.6948e-01\n",
       "                2.7176e-01  5.4876e-02  6.8733e-01\n",
       "              \n",
       "              (254,255, 2 ,.,.) = \n",
       "                8.6682e-01  7.0999e-01  7.6474e-01\n",
       "                5.3742e-01  5.3458e-01  8.2331e-01\n",
       "                4.0043e-01  2.4157e-01  8.1426e-01\n",
       "                    â‹®   â‹®  \n",
       "              \n",
       "              (255, 0 , 0 ,.,.) = \n",
       "               -1.4678e-01 -2.2373e-01 -4.3651e-01\n",
       "               -1.0860e-01  2.1343e-01 -5.4832e-01\n",
       "               -2.7147e-01 -1.7349e-02 -6.5524e-01\n",
       "              \n",
       "              (255, 0 , 1 ,.,.) = \n",
       "               -6.4760e-01 -9.1836e-01 -9.1749e-01\n",
       "               -8.4315e-01 -6.1182e-01 -1.1497e+00\n",
       "               -9.0466e-01 -7.2343e-01 -1.1796e+00\n",
       "              \n",
       "              (255, 0 , 2 ,.,.) = \n",
       "               -7.4632e-01 -6.5977e-01 -7.9562e-01\n",
       "               -1.1082e+00 -5.9452e-01 -9.2957e-01\n",
       "               -1.0913e+00 -3.4117e-01 -6.2657e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (255, 1 , 0 ,.,.) = \n",
       "               -4.1934e-01 -3.3992e-01 -4.4414e-01\n",
       "               -5.8615e-01 -5.6149e-01 -5.8422e-01\n",
       "               -4.9068e-01 -8.1905e-01 -7.7940e-01\n",
       "              \n",
       "              (255, 1 , 1 ,.,.) = \n",
       "               -1.0959e+00 -3.6897e-01 -2.1703e-01\n",
       "               -1.1037e+00 -6.0245e-01 -3.7372e-01\n",
       "               -8.8324e-01 -7.2283e-01 -5.1347e-01\n",
       "              \n",
       "              (255, 1 , 2 ,.,.) = \n",
       "               -9.5952e-01  1.7710e-02  4.4980e-01\n",
       "               -9.9610e-01 -1.8858e-01  1.1350e-01\n",
       "               -1.1371e+00 -6.6109e-01 -2.2089e-01\n",
       "                        â‹®  \n",
       "              \n",
       "              (255, 2 , 0 ,.,.) = \n",
       "               -4.9105e-01 -1.0184e-01 -3.4279e-01\n",
       "               -3.2415e-04 -7.8673e-02 -3.8516e-01\n",
       "                3.0942e-01  3.4019e-01 -7.6034e-03\n",
       "              \n",
       "              (255, 2 , 1 ,.,.) = \n",
       "               -4.0424e-01  1.8467e-01 -1.7203e-01\n",
       "                4.2976e-02  1.7068e-01 -1.8205e-01\n",
       "                3.8765e-01  5.0391e-01  1.1613e-01\n",
       "              \n",
       "              (255, 2 , 2 ,.,.) = \n",
       "               -7.5665e-01 -1.2434e-01 -3.6027e-01\n",
       "               -3.4099e-01 -3.5931e-03 -4.0853e-01\n",
       "               -8.7845e-02  1.7971e-01 -3.9627e-02\n",
       "                  ...     \n",
       "                        â‹®  \n",
       "              \n",
       "              (255,253, 0 ,.,.) = \n",
       "                1.2737e-01  8.6917e-01  3.0247e-01\n",
       "               -3.3636e-01  6.6015e-01 -6.5766e-02\n",
       "               -5.2404e-01  5.2973e-01 -1.6668e-02\n",
       "              \n",
       "              (255,253, 1 ,.,.) = \n",
       "                7.6632e-03  6.6718e-01  5.7096e-02\n",
       "               -2.3074e-01  6.3997e-01 -9.8984e-02\n",
       "               -2.5184e-01  5.2723e-01 -1.6661e-01\n",
       "              \n",
       "              (255,253, 2 ,.,.) = \n",
       "               -4.0436e-02  4.7220e-01  2.8751e-01\n",
       "               -7.6241e-02  6.5235e-01  1.9428e-01\n",
       "               -4.0271e-02  6.2006e-01  2.9460e-02\n",
       "                        â‹®  \n",
       "              \n",
       "              (255,254, 0 ,.,.) = \n",
       "                7.0066e-01  2.9418e-01  2.3036e-01\n",
       "                3.2688e-01  1.7593e-01  2.7691e-01\n",
       "                4.1706e-01  1.8954e-01  4.4137e-01\n",
       "              \n",
       "              (255,254, 1 ,.,.) = \n",
       "                8.8889e-01  4.7581e-01  3.9716e-01\n",
       "                6.7835e-01  4.6480e-01  4.7626e-01\n",
       "                6.9515e-01  5.8091e-01  8.1313e-01\n",
       "              \n",
       "              (255,254, 2 ,.,.) = \n",
       "                1.1645e+00  8.4236e-01  6.7447e-01\n",
       "                1.0769e+00  9.5049e-01  9.6226e-01\n",
       "                1.0561e+00  1.0973e+00  1.3239e+00\n",
       "                        â‹®  \n",
       "              \n",
       "              (255,255, 0 ,.,.) = \n",
       "               -2.3920e-01 -7.7395e-01 -4.6054e-01\n",
       "               -2.6973e-01 -7.0822e-01 -3.1288e-01\n",
       "               -4.3195e-01 -5.2749e-01 -7.2260e-01\n",
       "              \n",
       "              (255,255, 1 ,.,.) = \n",
       "               -2.3386e-01 -5.8912e-01 -3.0552e-01\n",
       "               -4.4582e-01 -4.5393e-01 -7.6944e-02\n",
       "               -7.5919e-01 -4.2348e-01 -9.0179e-02\n",
       "              \n",
       "              (255,255, 2 ,.,.) = \n",
       "                3.3853e-01 -3.2445e-01 -2.1695e-01\n",
       "                2.3873e-01 -2.8451e-01  1.6471e-01\n",
       "               -1.5988e-01 -3.1917e-01  2.7158e-02\n",
       "              [torch.cuda.FloatTensor of size 256x256x3x3x3 (GPU 0)]),\n",
       "             ('conv6.batchnorm.weight', \n",
       "               0.3911\n",
       "               0.4173\n",
       "               0.3350\n",
       "               0.3783\n",
       "               0.2410\n",
       "               0.2614\n",
       "               0.3282\n",
       "               0.3095\n",
       "               0.1260\n",
       "               0.4559\n",
       "               0.3799\n",
       "               0.4497\n",
       "               0.4341\n",
       "               0.4778\n",
       "               0.3983\n",
       "               0.2475\n",
       "               0.3334\n",
       "               0.2756\n",
       "               0.2818\n",
       "               0.4286\n",
       "               0.4865\n",
       "               0.2018\n",
       "               0.3998\n",
       "               0.4721\n",
       "               0.4680\n",
       "               0.2372\n",
       "               0.3051\n",
       "               0.3164\n",
       "               0.3618\n",
       "               0.4874\n",
       "               0.3978\n",
       "               0.4694\n",
       "               0.3627\n",
       "               0.2161\n",
       "               0.3435\n",
       "               0.2679\n",
       "               0.2572\n",
       "               0.3655\n",
       "               0.4203\n",
       "               0.4095\n",
       "               0.4514\n",
       "               0.3922\n",
       "               0.3164\n",
       "               0.4131\n",
       "               0.4376\n",
       "               0.2184\n",
       "               0.4713\n",
       "               0.2913\n",
       "               0.2824\n",
       "               0.3914\n",
       "               0.3091\n",
       "               0.3293\n",
       "               0.3834\n",
       "               0.3942\n",
       "               0.3578\n",
       "               0.3890\n",
       "               0.2954\n",
       "               0.3868\n",
       "               0.2143\n",
       "               0.3028\n",
       "               0.4399\n",
       "               0.4401\n",
       "               0.2953\n",
       "               0.3811\n",
       "               0.4751\n",
       "               0.3520\n",
       "               0.2809\n",
       "               0.1898\n",
       "               0.3600\n",
       "               0.4929\n",
       "               0.2620\n",
       "               0.4704\n",
       "               0.4305\n",
       "               0.4658\n",
       "               0.3226\n",
       "               0.4501\n",
       "               0.2343\n",
       "               0.3718\n",
       "               0.4718\n",
       "               0.1770\n",
       "               0.1574\n",
       "               0.3272\n",
       "               0.3554\n",
       "               0.3997\n",
       "               0.3153\n",
       "               0.3533\n",
       "               0.3213\n",
       "               0.3163\n",
       "               0.3234\n",
       "               0.2045\n",
       "               0.4107\n",
       "               0.4663\n",
       "               0.3221\n",
       "               0.1749\n",
       "               0.3621\n",
       "               0.2274\n",
       "               0.3814\n",
       "               0.5080\n",
       "               0.4225\n",
       "               0.2396\n",
       "               0.3899\n",
       "               0.4210\n",
       "               0.3256\n",
       "               0.2892\n",
       "               0.2871\n",
       "               0.1974\n",
       "               0.4379\n",
       "               0.2193\n",
       "               0.3562\n",
       "               0.4996\n",
       "               0.3535\n",
       "               0.3711\n",
       "               0.3615\n",
       "               0.3138\n",
       "               0.3851\n",
       "               0.3537\n",
       "               0.2873\n",
       "               0.4172\n",
       "               0.4137\n",
       "               0.3173\n",
       "               0.2428\n",
       "               0.4551\n",
       "               0.3836\n",
       "               0.4569\n",
       "               0.1962\n",
       "               0.4377\n",
       "               0.2870\n",
       "               0.3436\n",
       "               0.4679\n",
       "               0.3294\n",
       "               0.2966\n",
       "               0.1636\n",
       "               0.4347\n",
       "               0.3482\n",
       "               0.2886\n",
       "               0.3378\n",
       "               0.3949\n",
       "               0.3745\n",
       "               0.4464\n",
       "               0.3971\n",
       "               0.4783\n",
       "               0.4012\n",
       "               0.3806\n",
       "               0.4198\n",
       "               0.3566\n",
       "               0.2721\n",
       "               0.3653\n",
       "               0.4449\n",
       "               0.4540\n",
       "               0.5238\n",
       "               0.4429\n",
       "               0.4411\n",
       "               0.1444\n",
       "               0.3280\n",
       "               0.4452\n",
       "               0.4221\n",
       "               0.2612\n",
       "               0.4557\n",
       "               0.4801\n",
       "               0.2734\n",
       "               0.3713\n",
       "               0.3464\n",
       "               0.2585\n",
       "               0.1497\n",
       "               0.3945\n",
       "               0.3402\n",
       "               0.4336\n",
       "               0.2479\n",
       "               0.2754\n",
       "               0.3525\n",
       "               0.3461\n",
       "               0.3851\n",
       "               0.2464\n",
       "               0.3452\n",
       "               0.3496\n",
       "               0.2991\n",
       "               0.2624\n",
       "               0.3473\n",
       "               0.4957\n",
       "               0.4824\n",
       "               0.2810\n",
       "               0.2719\n",
       "               0.4824\n",
       "               0.1974\n",
       "               0.3085\n",
       "               0.4961\n",
       "               0.2304\n",
       "               0.1578\n",
       "               0.3881\n",
       "               0.3595\n",
       "               0.3368\n",
       "               0.5781\n",
       "               0.1735\n",
       "               0.4554\n",
       "               0.1117\n",
       "               0.3465\n",
       "               0.2250\n",
       "               0.4902\n",
       "               0.2729\n",
       "               0.4192\n",
       "               0.3627\n",
       "               0.3261\n",
       "               0.5478\n",
       "               0.4265\n",
       "               0.2298\n",
       "               0.3910\n",
       "               0.4016\n",
       "               0.3778\n",
       "               0.3751\n",
       "               0.3379\n",
       "               0.3836\n",
       "               0.4426\n",
       "               0.2768\n",
       "               0.3914\n",
       "               0.3548\n",
       "               0.4844\n",
       "               0.2217\n",
       "               0.2491\n",
       "               0.4057\n",
       "               0.2423\n",
       "               0.4741\n",
       "               0.4205\n",
       "               0.4860\n",
       "               0.3928\n",
       "               0.4412\n",
       "               0.2585\n",
       "               0.4057\n",
       "               0.3961\n",
       "               0.4025\n",
       "               0.2837\n",
       "               0.2293\n",
       "               0.2518\n",
       "               0.4072\n",
       "               0.3731\n",
       "               0.3926\n",
       "               0.4345\n",
       "               0.3690\n",
       "               0.3637\n",
       "               0.3675\n",
       "               0.3395\n",
       "               0.4595\n",
       "               0.3645\n",
       "               0.3684\n",
       "               0.4437\n",
       "               0.1400\n",
       "               0.3036\n",
       "               0.4205\n",
       "               0.3738\n",
       "               0.2408\n",
       "               0.3798\n",
       "               0.3548\n",
       "               0.3324\n",
       "               0.6809\n",
       "               0.4144\n",
       "               0.3863\n",
       "               0.3829\n",
       "              [torch.cuda.FloatTensor of size 256 (GPU 0)]),\n",
       "             ('conv6.batchnorm.bias', \n",
       "              -0.5166\n",
       "              -0.0798\n",
       "              -0.7661\n",
       "              -0.4976\n",
       "              -0.9258\n",
       "              -0.6503\n",
       "              -0.3894\n",
       "              -0.5422\n",
       "              -0.6718\n",
       "              -0.5557\n",
       "              -0.4479\n",
       "              -0.3445\n",
       "              -0.7166\n",
       "              -0.3899\n",
       "              -0.9418\n",
       "              -0.1833\n",
       "              -0.6756\n",
       "              -0.6050\n",
       "              -0.2900\n",
       "              -0.4764\n",
       "              -0.8768\n",
       "              -0.6597\n",
       "              -0.7917\n",
       "              -0.6923\n",
       "              -0.5408\n",
       "              -0.6393\n",
       "              -0.3903\n",
       "              -0.7477\n",
       "              -0.4605\n",
       "              -0.5975\n",
       "              -0.3847\n",
       "              -0.7003\n",
       "              -0.2291\n",
       "              -0.6921\n",
       "              -0.8543\n",
       "              -0.7623\n",
       "              -0.6675\n",
       "              -0.7200\n",
       "              -0.5708\n",
       "              -0.4446\n",
       "              -0.5216\n",
       "              -0.4781\n",
       "              -0.8176\n",
       "              -0.4356\n",
       "              -0.5370\n",
       "              -0.5130\n",
       "              -0.8338\n",
       "              -0.7490\n",
       "              -0.6170\n",
       "              -0.3339\n",
       "              -0.3573\n",
       "              -0.3143\n",
       "              -0.5593\n",
       "              -0.3587\n",
       "              -0.3526\n",
       "              -1.0003\n",
       "              -0.9029\n",
       "              -0.7048\n",
       "              -0.8409\n",
       "              -0.2104\n",
       "              -0.7523\n",
       "              -0.5441\n",
       "              -0.2995\n",
       "              -0.5132\n",
       "              -0.7577\n",
       "              -0.0919\n",
       "              -0.4333\n",
       "              -0.7435\n",
       "              -0.9106\n",
       "              -0.7501\n",
       "              -0.8681\n",
       "              -0.6286\n",
       "              -0.4995\n",
       "              -0.5239\n",
       "              -0.5161\n",
       "              -0.7824\n",
       "              -0.2179\n",
       "              -0.1966\n",
       "              -0.7861\n",
       "              -0.8239\n",
       "              -0.7267\n",
       "              -0.2878\n",
       "              -0.3244\n",
       "              -0.5540\n",
       "              -0.5093\n",
       "              -0.6543\n",
       "              -0.8402\n",
       "              -0.6977\n",
       "              -0.2344\n",
       "              -0.5643\n",
       "              -0.1831\n",
       "              -0.4963\n",
       "              -0.7456\n",
       "              -0.5507\n",
       "              -0.7659\n",
       "              -0.6778\n",
       "              -0.3725\n",
       "              -0.6821\n",
       "              -0.4938\n",
       "              -0.5928\n",
       "              -0.4551\n",
       "              -0.8480\n",
       "              -0.2918\n",
       "              -0.3740\n",
       "              -0.8644\n",
       "              -0.5839\n",
       "              -0.5559\n",
       "              -0.6324\n",
       "              -0.6255\n",
       "              -0.3041\n",
       "              -0.8444\n",
       "              -0.5025\n",
       "              -0.3094\n",
       "              -0.3898\n",
       "              -0.5091\n",
       "              -0.5836\n",
       "              -0.8097\n",
       "              -0.5313\n",
       "              -0.7752\n",
       "              -0.7471\n",
       "              -0.1849\n",
       "              -0.8511\n",
       "              -0.5763\n",
       "              -0.7954\n",
       "              -0.5347\n",
       "              -0.6257\n",
       "              -0.6958\n",
       "              -0.3589\n",
       "              -0.4529\n",
       "              -0.1193\n",
       "              -0.7337\n",
       "              -0.8076\n",
       "              -0.5940\n",
       "              -0.5685\n",
       "              -0.8517\n",
       "              -0.4352\n",
       "              -0.7405\n",
       "              -0.4339\n",
       "              -0.5356\n",
       "              -0.8045\n",
       "              -0.7512\n",
       "              -0.2838\n",
       "              -0.5174\n",
       "              -0.5872\n",
       "              -0.4174\n",
       "              -0.3175\n",
       "              -0.7288\n",
       "              -0.8583\n",
       "              -0.4030\n",
       "              -0.5453\n",
       "              -0.6218\n",
       "              -0.4948\n",
       "              -0.8075\n",
       "              -0.4690\n",
       "              -0.5548\n",
       "              -0.5451\n",
       "              -0.0928\n",
       "              -0.5338\n",
       "              -0.5652\n",
       "              -0.8576\n",
       "              -0.3496\n",
       "              -0.4345\n",
       "              -0.8256\n",
       "              -0.6373\n",
       "              -0.4470\n",
       "              -0.4405\n",
       "              -0.3186\n",
       "              -0.8268\n",
       "              -0.5422\n",
       "              -0.8732\n",
       "              -0.7279\n",
       "              -0.4657\n",
       "              -0.5734\n",
       "              -0.3575\n",
       "              -0.5899\n",
       "              -0.4043\n",
       "              -0.8018\n",
       "              -0.5230\n",
       "              -0.6030\n",
       "              -0.4512\n",
       "              -0.4484\n",
       "              -0.6488\n",
       "              -0.7022\n",
       "              -0.5571\n",
       "              -0.8244\n",
       "              -0.9541\n",
       "              -0.6610\n",
       "              -0.7553\n",
       "              -0.4767\n",
       "              -0.2998\n",
       "              -0.4945\n",
       "              -0.5138\n",
       "              -1.0067\n",
       "              -0.5114\n",
       "              -0.8027\n",
       "              -0.4326\n",
       "              -0.7589\n",
       "              -0.8930\n",
       "              -0.7763\n",
       "              -0.6076\n",
       "              -0.7433\n",
       "               0.1138\n",
       "              -0.6736\n",
       "              -0.6052\n",
       "              -0.7062\n",
       "              -0.8905\n",
       "              -0.6972\n",
       "              -0.4960\n",
       "              -0.3932\n",
       "              -0.7300\n",
       "              -0.7835\n",
       "              -0.6907\n",
       "              -0.2028\n",
       "              -0.8204\n",
       "              -0.5718\n",
       "              -0.9811\n",
       "              -0.5829\n",
       "              -0.6321\n",
       "              -0.6966\n",
       "              -0.7126\n",
       "              -0.6222\n",
       "              -0.5328\n",
       "              -0.6820\n",
       "              -0.8494\n",
       "              -0.6709\n",
       "              -0.7223\n",
       "              -0.4851\n",
       "              -0.4163\n",
       "              -0.8363\n",
       "              -0.7402\n",
       "              -0.6409\n",
       "              -0.6207\n",
       "              -0.3386\n",
       "              -0.3326\n",
       "              -0.8112\n",
       "              -0.7671\n",
       "              -0.4228\n",
       "              -0.4816\n",
       "              -0.9169\n",
       "              -0.7205\n",
       "              -0.6408\n",
       "              -0.5662\n",
       "              -0.4522\n",
       "              -0.4497\n",
       "              -0.8126\n",
       "              -0.3514\n",
       "              -0.5703\n",
       "              -0.5849\n",
       "              -0.5731\n",
       "              -0.4287\n",
       "              -0.3503\n",
       "              -0.4122\n",
       "              -0.5772\n",
       "              -0.6278\n",
       "              -0.6934\n",
       "              -0.5319\n",
       "              [torch.cuda.FloatTensor of size 256 (GPU 0)]),\n",
       "             ('conv6.batchnorm.running_mean', \n",
       "               -92.9979\n",
       "                -6.5016\n",
       "               -37.2919\n",
       "               -61.4153\n",
       "                43.8445\n",
       "                -5.7063\n",
       "               -28.0426\n",
       "               -55.8202\n",
       "               -16.5645\n",
       "               -86.5853\n",
       "               -19.2165\n",
       "               -70.3564\n",
       "               -51.0844\n",
       "               -80.8603\n",
       "               -29.7483\n",
       "               -45.7361\n",
       "               -38.7042\n",
       "               -20.8314\n",
       "               -59.1970\n",
       "               -49.3878\n",
       "               -55.8091\n",
       "               -37.6840\n",
       "               -16.8170\n",
       "               -61.2817\n",
       "               -66.7115\n",
       "               -24.0966\n",
       "               -36.6041\n",
       "               -35.7063\n",
       "               -67.7601\n",
       "               -49.7992\n",
       "               -46.9656\n",
       "               -44.4408\n",
       "               -63.7160\n",
       "               -11.7375\n",
       "                20.6646\n",
       "               -45.7119\n",
       "               -32.1330\n",
       "               -82.3780\n",
       "               -47.3866\n",
       "               -15.6298\n",
       "               -48.9147\n",
       "               -57.5631\n",
       "               -82.3000\n",
       "               -44.6019\n",
       "               -53.8685\n",
       "               -30.2825\n",
       "               -52.3476\n",
       "               -28.2261\n",
       "               -35.5338\n",
       "               -60.6826\n",
       "               -69.5676\n",
       "               -78.1376\n",
       "               -53.4374\n",
       "               -29.3179\n",
       "               -45.2705\n",
       "               -49.1661\n",
       "                21.3533\n",
       "               -11.8184\n",
       "                -5.2612\n",
       "               -77.6546\n",
       "               -54.4461\n",
       "              -121.5559\n",
       "               -59.2508\n",
       "               -28.4199\n",
       "               -77.8195\n",
       "                15.8936\n",
       "                -0.5491\n",
       "               -31.8222\n",
       "               -24.0036\n",
       "               -60.4884\n",
       "               -34.2359\n",
       "               -54.3853\n",
       "               -57.4396\n",
       "               -58.3918\n",
       "               -39.1658\n",
       "               -49.6406\n",
       "               -22.3593\n",
       "               -57.7056\n",
       "               -63.1912\n",
       "               -22.2550\n",
       "               -35.3240\n",
       "               -17.8219\n",
       "               -62.6989\n",
       "               -53.4202\n",
       "               -42.0498\n",
       "               -76.1740\n",
       "               -39.2514\n",
       "               -35.3782\n",
       "               -53.1569\n",
       "               -17.9315\n",
       "               -98.6098\n",
       "               -52.5816\n",
       "               -24.8561\n",
       "               -28.2635\n",
       "               -36.0130\n",
       "               -40.4272\n",
       "               -86.0321\n",
       "               -66.6338\n",
       "               -43.5739\n",
       "               -22.6371\n",
       "               -28.4108\n",
       "               -24.7061\n",
       "               -81.0747\n",
       "               -15.9083\n",
       "                14.4902\n",
       "                -6.2790\n",
       "               -67.7105\n",
       "               -20.4683\n",
       "               -52.6835\n",
       "               -65.2842\n",
       "               -15.5126\n",
       "               -63.5941\n",
       "               -54.5812\n",
       "               -49.8368\n",
       "               -61.9612\n",
       "               -23.3477\n",
       "               -57.5994\n",
       "               -49.8996\n",
       "               -36.9915\n",
       "               -22.9623\n",
       "               -20.0171\n",
       "               -35.9946\n",
       "               -45.0925\n",
       "               -39.1821\n",
       "               -62.2308\n",
       "               -26.6223\n",
       "               -29.3204\n",
       "               -44.5299\n",
       "               -37.8500\n",
       "               -32.9461\n",
       "               -27.3488\n",
       "               -31.5290\n",
       "               -72.5178\n",
       "               -16.0948\n",
       "               -41.5084\n",
       "               -60.2973\n",
       "               -56.0468\n",
       "               -79.2035\n",
       "               -76.2716\n",
       "               -47.5662\n",
       "               -84.6138\n",
       "               -57.2450\n",
       "               -62.2296\n",
       "               -47.0750\n",
       "               -56.4055\n",
       "               -55.6778\n",
       "                 5.7186\n",
       "               -27.4222\n",
       "               -91.5641\n",
       "               -72.2869\n",
       "               -41.4203\n",
       "               -50.5025\n",
       "               -42.2809\n",
       "               -65.0556\n",
       "               -57.2096\n",
       "               -58.5595\n",
       "               -47.5702\n",
       "               -90.9235\n",
       "               -47.0000\n",
       "               -50.6369\n",
       "               -52.9093\n",
       "              -100.6887\n",
       "               -47.4896\n",
       "               -34.1497\n",
       "               -88.1695\n",
       "               -48.8909\n",
       "               -62.1972\n",
       "               -16.2666\n",
       "               -21.1866\n",
       "                -7.3999\n",
       "               -24.0996\n",
       "               -25.9828\n",
       "               -18.0599\n",
       "               -42.6247\n",
       "                -5.1473\n",
       "               -46.1520\n",
       "               -42.0125\n",
       "               -45.3667\n",
       "               -49.6200\n",
       "               -60.1502\n",
       "               -85.1301\n",
       "               -21.7406\n",
       "               -68.6818\n",
       "               -12.2412\n",
       "               -26.8985\n",
       "               -66.7125\n",
       "               -24.5654\n",
       "                 0.5946\n",
       "               -57.1190\n",
       "              -100.9830\n",
       "               -30.1479\n",
       "               -47.6084\n",
       "               -19.0728\n",
       "               -50.0453\n",
       "               -16.6744\n",
       "               -68.0755\n",
       "               -47.0180\n",
       "               -74.3714\n",
       "               -63.7269\n",
       "               -28.9221\n",
       "               -23.2662\n",
       "                22.1807\n",
       "               -48.6693\n",
       "               -72.7861\n",
       "               -18.4843\n",
       "               105.5956\n",
       "               -45.1843\n",
       "               -62.4677\n",
       "               -35.3520\n",
       "               -55.9373\n",
       "               -55.9662\n",
       "               -48.7285\n",
       "               -44.0998\n",
       "                 5.0239\n",
       "               -40.4654\n",
       "               -34.9237\n",
       "               -51.0459\n",
       "               -13.9951\n",
       "               -32.1767\n",
       "               -33.4510\n",
       "               -60.8513\n",
       "                 7.0813\n",
       "               -92.2877\n",
       "                 8.2712\n",
       "               -50.2994\n",
       "                -9.0607\n",
       "               -64.1929\n",
       "               -61.9979\n",
       "                30.5318\n",
       "                 8.2156\n",
       "               -14.8984\n",
       "               -24.4792\n",
       "               -39.8042\n",
       "               -51.8711\n",
       "               -40.1259\n",
       "               -71.0716\n",
       "               -37.2898\n",
       "                24.4241\n",
       "                40.5542\n",
       "               -28.7759\n",
       "               -55.8536\n",
       "               -63.8505\n",
       "               -55.3704\n",
       "               -68.8728\n",
       "               -14.8712\n",
       "              -107.2331\n",
       "               -73.9410\n",
       "              -124.7054\n",
       "               -22.4143\n",
       "               -36.4816\n",
       "               -66.4938\n",
       "               -58.9452\n",
       "               -70.3046\n",
       "               -82.8997\n",
       "               -56.2627\n",
       "               -67.2975\n",
       "              [torch.cuda.FloatTensor of size 256 (GPU 0)]),\n",
       "             ('conv6.batchnorm.running_var', \n",
       "                2920.4326\n",
       "                5586.1616\n",
       "                1889.3949\n",
       "                2536.0186\n",
       "                3916.7324\n",
       "                1711.5162\n",
       "                3775.4050\n",
       "                3506.8843\n",
       "                3132.1567\n",
       "                4058.2815\n",
       "                3718.0237\n",
       "                7850.9795\n",
       "                5528.1758\n",
       "                4383.9932\n",
       "                4217.9341\n",
       "                3554.5386\n",
       "                2551.0637\n",
       "                1770.0341\n",
       "                3109.1223\n",
       "                4438.1670\n",
       "                2227.0969\n",
       "                2568.7004\n",
       "                6684.5498\n",
       "                3560.2437\n",
       "                3556.3469\n",
       "                1690.0272\n",
       "                3055.8657\n",
       "                1636.4038\n",
       "                2595.5461\n",
       "                2945.5613\n",
       "                3290.3486\n",
       "                3142.5337\n",
       "                8256.5098\n",
       "                1706.2941\n",
       "                4129.9062\n",
       "                1740.3975\n",
       "                2276.0779\n",
       "                4935.6494\n",
       "                2638.4863\n",
       "                4957.0684\n",
       "                4868.7075\n",
       "                2656.7029\n",
       "                4393.4922\n",
       "                2789.0669\n",
       "                3398.1135\n",
       "                1498.5388\n",
       "                1894.0885\n",
       "                1472.7843\n",
       "                2021.8380\n",
       "                6276.2656\n",
       "                3299.3582\n",
       "                2688.5212\n",
       "                5040.7559\n",
       "                6215.1943\n",
       "                3687.2664\n",
       "                5130.2134\n",
       "                5176.3359\n",
       "                3208.1882\n",
       "                1718.0944\n",
       "                3416.7791\n",
       "                4012.5271\n",
       "                7293.8052\n",
       "                3725.6521\n",
       "                3585.9927\n",
       "                5488.7676\n",
       "                5312.0903\n",
       "                2784.7773\n",
       "                4184.7778\n",
       "                3631.4097\n",
       "                2142.2295\n",
       "                3765.4155\n",
       "                2676.0710\n",
       "                2751.4143\n",
       "                4039.3621\n",
       "                3776.1646\n",
       "                2759.6062\n",
       "                2880.8806\n",
       "                5832.9214\n",
       "                3396.7166\n",
       "                4150.2637\n",
       "                4137.6362\n",
       "                5142.0674\n",
       "                4950.0723\n",
       "                3695.6406\n",
       "                3274.3755\n",
       "                2443.7642\n",
       "                2510.1633\n",
       "                3871.7180\n",
       "                4625.5234\n",
       "                1788.6870\n",
       "                9784.2891\n",
       "                2634.7405\n",
       "                1714.8040\n",
       "                1153.3202\n",
       "                2063.6965\n",
       "                4028.3994\n",
       "                4158.6372\n",
       "                2324.3313\n",
       "                3851.7827\n",
       "                1687.4559\n",
       "                7411.6265\n",
       "                3367.6389\n",
       "                4986.7109\n",
       "                2456.1868\n",
       "                5208.1743\n",
       "                3093.0095\n",
       "                2874.4771\n",
       "                2562.0876\n",
       "                5602.1094\n",
       "               13301.9473\n",
       "                2122.4749\n",
       "                4487.0420\n",
       "                5302.9897\n",
       "                2967.2395\n",
       "                3193.7354\n",
       "                3325.8337\n",
       "                3944.8794\n",
       "                4581.2104\n",
       "                1353.3783\n",
       "                1592.6825\n",
       "                4206.9971\n",
       "                4412.4937\n",
       "                3420.1396\n",
       "                3077.7307\n",
       "                5663.3394\n",
       "                3693.7251\n",
       "                1911.0089\n",
       "                4665.0928\n",
       "                2752.5190\n",
       "                5893.2852\n",
       "                1506.4030\n",
       "                3074.6655\n",
       "                4460.1021\n",
       "                4183.9863\n",
       "                1711.4281\n",
       "                2267.7412\n",
       "                2864.9915\n",
       "                4328.6245\n",
       "                4660.0288\n",
       "                2779.1050\n",
       "                2820.0779\n",
       "                5325.7334\n",
       "                3153.0100\n",
       "                2940.9587\n",
       "                3067.2610\n",
       "                4238.4043\n",
       "                2436.2598\n",
       "                2008.2805\n",
       "                7630.5430\n",
       "                5410.3013\n",
       "                3353.3999\n",
       "                4106.8955\n",
       "                 971.1701\n",
       "                2520.4241\n",
       "                2681.9792\n",
       "                3325.6082\n",
       "                8380.4521\n",
       "                5629.2275\n",
       "                3106.9849\n",
       "                4002.1433\n",
       "                4552.4331\n",
       "                3171.0688\n",
       "                4090.9050\n",
       "                1188.6086\n",
       "                5223.3169\n",
       "                2922.7107\n",
       "                9239.4619\n",
       "                1978.3655\n",
       "                1361.0134\n",
       "                4201.2861\n",
       "                1571.3248\n",
       "                3434.3386\n",
       "                3401.6348\n",
       "                2843.6975\n",
       "                3563.6421\n",
       "                3718.8760\n",
       "                3906.9067\n",
       "                3060.6060\n",
       "                4793.1875\n",
       "                4061.4607\n",
       "                3397.5095\n",
       "                1468.4968\n",
       "                2935.3770\n",
       "                1559.8951\n",
       "                3444.8257\n",
       "                1944.9751\n",
       "                1256.7694\n",
       "                1882.7203\n",
       "                3126.6414\n",
       "                5893.2061\n",
       "                2704.4097\n",
       "                4360.3408\n",
       "               11053.6992\n",
       "                2670.2983\n",
       "                1919.7286\n",
       "                3034.2285\n",
       "                3558.0159\n",
       "                1601.6077\n",
       "                3416.9480\n",
       "                1997.0809\n",
       "                2793.5725\n",
       "                7579.1733\n",
       "                3257.5254\n",
       "                4920.0166\n",
       "                1823.2999\n",
       "                6269.0815\n",
       "                2182.5291\n",
       "                3388.6331\n",
       "                2501.3142\n",
       "                3525.5603\n",
       "                3654.2341\n",
       "                2149.9780\n",
       "                3695.1729\n",
       "                5423.1050\n",
       "                2060.1221\n",
       "                1905.3402\n",
       "                3213.3044\n",
       "                1312.5365\n",
       "                5058.9995\n",
       "                3601.1304\n",
       "                2331.5110\n",
       "                6636.5742\n",
       "                3458.4014\n",
       "                4922.9775\n",
       "                1759.8510\n",
       "                1724.0490\n",
       "                3905.3777\n",
       "                3762.2590\n",
       "                2616.2004\n",
       "                3650.7258\n",
       "                1754.9001\n",
       "                1828.4575\n",
       "                4600.4634\n",
       "                3414.7007\n",
       "                5057.9268\n",
       "                5893.7031\n",
       "                2820.9377\n",
       "                3428.1931\n",
       "                5567.1621\n",
       "                2165.9180\n",
       "                4012.9038\n",
       "                2883.0596\n",
       "                3777.2576\n",
       "                6206.6133\n",
       "                2970.9883\n",
       "                6316.8662\n",
       "                2354.2070\n",
       "                6278.9185\n",
       "                 900.4299\n",
       "                3141.4102\n",
       "                6006.7114\n",
       "                3720.0315\n",
       "                3962.6948\n",
       "                3932.1416\n",
       "                4013.1492\n",
       "                3498.0876\n",
       "              [torch.cuda.FloatTensor of size 256 (GPU 0)]),\n",
       "             ('lstm.weight_ih_l0', \n",
       "              -1.5623e-01 -1.2999e-01 -2.2747e-02  ...   1.7891e-01 -6.9893e-02 -6.5677e-02\n",
       "              -3.8115e-01 -1.7688e-02  7.3010e-02  ...  -9.7179e-02 -4.6671e-01  7.4974e-01\n",
       "               6.3329e-01 -6.7145e-01 -2.7676e-02  ...   4.9537e-04 -1.2582e+00 -4.1120e-01\n",
       "                              ...                   â‹±                   ...                \n",
       "              -1.2673e-01 -3.3196e-01 -7.4766e-02  ...   6.0752e-01  1.8267e-02  1.2071e-01\n",
       "              -7.4315e-04 -8.3050e-02  4.4807e-02  ...  -4.1356e-01 -2.5187e-01  1.0146e+00\n",
       "              -9.3269e-01 -3.0648e-02 -1.5056e-01  ...  -3.0314e-01 -1.8545e-01 -8.0915e-01\n",
       "              [torch.cuda.FloatTensor of size 1024x256 (GPU 0)]),\n",
       "             ('lstm.weight_hh_l0', \n",
       "               6.4254e-01  6.3259e-01  3.1612e-01  ...  -1.5014e-02 -7.9884e-02  6.3124e-01\n",
       "               3.3876e-01 -1.7501e-01  2.7199e-01  ...   5.9043e-01  5.9933e-01  2.5514e-01\n",
       "              -8.7615e-01 -1.0166e-01  2.3632e-01  ...   9.0991e-01 -2.2957e-01  1.0078e+00\n",
       "                              ...                   â‹±                   ...                \n",
       "               1.5112e-01 -6.9835e-02  3.6653e-01  ...   2.9276e-01  5.8545e-01  4.1554e-01\n",
       "              -1.3711e-01 -7.7855e-01  2.6553e-01  ...   3.9758e-01  4.3500e-01 -3.2421e-01\n",
       "              -4.9314e-02  1.2393e+00 -1.7484e-01  ...   2.9353e-01  2.4455e-01  1.6860e-02\n",
       "              [torch.cuda.FloatTensor of size 1024x256 (GPU 0)]),\n",
       "             ('lstm.bias_ih_l0', \n",
       "              -0.3139\n",
       "              -0.2415\n",
       "              -0.2599\n",
       "                 â‹®   \n",
       "              -0.2951\n",
       "              -0.5156\n",
       "              -0.0183\n",
       "              [torch.cuda.FloatTensor of size 1024 (GPU 0)]),\n",
       "             ('lstm.bias_hh_l0', \n",
       "              -0.2328\n",
       "              -0.3096\n",
       "              -0.2711\n",
       "                 â‹®   \n",
       "              -0.2597\n",
       "              -0.4936\n",
       "               0.0224\n",
       "              [torch.cuda.FloatTensor of size 1024 (GPU 0)]),\n",
       "             ('lstm.weight_ih_l0_reverse', \n",
       "              -1.1435e-02 -1.8044e-01  8.8484e-02  ...   1.3016e-01 -8.2664e-02 -4.3832e-01\n",
       "               1.3707e-01 -1.4092e-01  9.5264e-02  ...   1.5073e-01 -6.1298e-01 -1.0207e-01\n",
       "              -9.2598e-01  1.1429e-01  3.1608e-02  ...   3.2614e-01 -4.3265e-01 -5.2492e-01\n",
       "                              ...                   â‹±                   ...                \n",
       "              -3.9905e-01 -2.0946e-01  7.6128e-02  ...   3.0100e-01 -1.0328e+00  2.5624e-01\n",
       "              -7.7056e-01 -4.0036e-01 -5.7794e-02  ...   1.4342e-01  3.8816e-01 -1.3136e+00\n",
       "               5.5064e-01 -6.4763e-02 -1.3701e-01  ...  -2.3319e-01 -1.1643e-01  7.4079e-01\n",
       "              [torch.cuda.FloatTensor of size 1024x256 (GPU 0)]),\n",
       "             ('lstm.weight_hh_l0_reverse', \n",
       "               2.4614e-01  7.4713e-01  5.6302e-01  ...  -5.5707e-02 -2.7546e-01 -7.4405e-01\n",
       "               9.7967e-01  1.9290e-01  1.3714e+00  ...  -3.8860e-02  7.6311e-01  4.7291e-01\n",
       "              -3.2182e-01 -2.3074e-01 -6.3929e-01  ...  -1.0223e-01 -1.9292e-01 -3.4468e-01\n",
       "                              ...                   â‹±                   ...                \n",
       "               8.3049e-01 -2.1649e-01  6.2792e-01  ...   6.1412e-01 -4.7108e-01 -4.0113e-01\n",
       "               3.9329e-01  2.2707e-01  2.0674e-01  ...  -1.6158e-03 -1.4332e-01 -1.5509e-01\n",
       "              -5.3529e-02  8.4030e-01  6.9589e-01  ...  -2.2039e-01  6.7670e-01 -2.7390e-02\n",
       "              [torch.cuda.FloatTensor of size 1024x256 (GPU 0)]),\n",
       "             ('lstm.bias_ih_l0_reverse', \n",
       "              -0.2059\n",
       "              -0.0836\n",
       "              -0.4810\n",
       "                 â‹®   \n",
       "              -0.2036\n",
       "              -0.3798\n",
       "              -0.0484\n",
       "              [torch.cuda.FloatTensor of size 1024 (GPU 0)]),\n",
       "             ('lstm.bias_hh_l0_reverse', \n",
       "              -0.2495\n",
       "              -0.1826\n",
       "              -0.4744\n",
       "                 â‹®   \n",
       "              -0.1547\n",
       "              -0.3431\n",
       "              -0.0519\n",
       "              [torch.cuda.FloatTensor of size 1024 (GPU 0)]),\n",
       "             ('lstm.weight_ih_l1', \n",
       "               2.2425e-02 -9.0364e-02 -7.9091e-02  ...  -1.1357e-01 -8.3101e-01  7.8929e-02\n",
       "               8.3693e-01 -6.6182e-01 -2.6034e-02  ...   7.9020e-02 -3.9224e-01  6.8285e-01\n",
       "              -3.3310e-01 -6.3020e-01  5.9074e-02  ...  -5.0968e-02 -4.6534e-02  7.1899e-01\n",
       "                              ...                   â‹±                   ...                \n",
       "              -3.2771e-01  5.7585e-01  1.4691e-02  ...   3.4125e-01 -2.0976e-01  4.1051e-02\n",
       "               2.4715e-01  1.6311e-01 -2.1420e-01  ...  -1.8224e-01 -1.0345e-01  1.3952e-01\n",
       "              -9.7459e-02 -7.6734e-02  1.4437e-01  ...  -5.0874e-02  2.4561e-01 -1.6295e-01\n",
       "              [torch.cuda.FloatTensor of size 1024x512 (GPU 0)]),\n",
       "             ('lstm.weight_hh_l1', \n",
       "              -2.3397e-01 -9.7681e-02  5.2102e-02  ...   3.6018e-02  3.1880e-03 -4.8926e-01\n",
       "               5.1702e-01  4.6890e-01 -5.0193e-01  ...  -6.9273e-01 -8.5369e-01 -5.4253e-01\n",
       "              -1.6068e-01  1.7745e-02 -4.6811e-01  ...  -1.6911e-01 -3.8124e-01 -1.1837e+00\n",
       "                              ...                   â‹±                   ...                \n",
       "              -3.4562e-01  2.3683e-01 -3.7449e-01  ...  -6.2766e-01 -3.9269e-01  2.9967e-01\n",
       "               2.4106e-01  2.9804e-01 -1.9833e-01  ...  -1.5221e-01 -3.1884e-02 -2.5779e-01\n",
       "              -3.3679e-01 -2.5241e-01  2.7060e-01  ...  -4.0876e-01 -5.8612e-01  1.2867e-01\n",
       "              [torch.cuda.FloatTensor of size 1024x256 (GPU 0)]),\n",
       "             ('lstm.bias_ih_l1', \n",
       "              -0.5305\n",
       "              -0.5547\n",
       "              -0.6168\n",
       "                 â‹®   \n",
       "              -0.3472\n",
       "              -0.4878\n",
       "              -0.4351\n",
       "              [torch.cuda.FloatTensor of size 1024 (GPU 0)]),\n",
       "             ('lstm.bias_hh_l1', \n",
       "              -0.5095\n",
       "              -0.5202\n",
       "              -0.5885\n",
       "                 â‹®   \n",
       "              -0.3128\n",
       "              -0.4640\n",
       "              -0.3695\n",
       "              [torch.cuda.FloatTensor of size 1024 (GPU 0)]),\n",
       "             ('lstm.weight_ih_l1_reverse', \n",
       "               3.8535e-02 -3.8918e-01  7.1900e-02  ...   9.5279e-01 -4.2580e-01 -5.0849e-01\n",
       "               8.0806e-01  4.1808e-01 -1.3011e-01  ...  -4.7647e-01 -1.6031e-01 -3.9788e-01\n",
       "               2.0296e-01  9.2887e-02 -6.3940e-02  ...   3.7152e-02  1.6577e-01  7.1729e-02\n",
       "                              ...                   â‹±                   ...                \n",
       "              -2.4321e-01 -6.5418e-01  6.2313e-01  ...   5.2181e-02 -1.3065e-01 -7.3738e-01\n",
       "               1.2021e-01 -4.6588e-01 -7.6246e-02  ...  -2.7465e-01 -3.3878e-01 -4.0742e-01\n",
       "              -3.7550e-02  4.8899e-03  1.1253e-01  ...  -2.7148e-01 -8.2234e-02  2.1243e-01\n",
       "              [torch.cuda.FloatTensor of size 1024x512 (GPU 0)]),\n",
       "             ('lstm.weight_hh_l1_reverse', \n",
       "              -1.6337e-01 -9.6199e-01  4.0403e-01  ...   2.6148e-01  2.3491e-01  4.6527e-01\n",
       "              -2.2765e-01 -1.7369e-01  1.2500e+00  ...   6.8440e-01 -1.4024e-01 -1.2770e-01\n",
       "               4.7175e-02 -2.5427e-01  4.5822e-01  ...  -2.9946e-01  2.7609e-01 -3.7166e-01\n",
       "                              ...                   â‹±                   ...                \n",
       "               5.1566e-01  3.2414e-01  3.2601e-02  ...   9.7718e-01 -6.4407e-01 -2.4190e-01\n",
       "              -1.2661e-01  1.4021e-01  6.0474e-01  ...  -5.5548e-01  2.3621e-01 -7.1833e-02\n",
       "              -2.1332e-01  1.0069e-01 -2.6338e-02  ...  -2.2457e-01  3.7101e-01  7.5949e-01\n",
       "              [torch.cuda.FloatTensor of size 1024x256 (GPU 0)]),\n",
       "             ('lstm.bias_ih_l1_reverse', \n",
       "              -0.2804\n",
       "              -0.3233\n",
       "              -0.4859\n",
       "                 â‹®   \n",
       "              -0.4393\n",
       "              -0.4515\n",
       "              -0.4315\n",
       "              [torch.cuda.FloatTensor of size 1024 (GPU 0)]),\n",
       "             ('lstm.bias_hh_l1_reverse', \n",
       "              -0.2240\n",
       "              -0.3235\n",
       "              -0.4950\n",
       "                 â‹®   \n",
       "              -0.4849\n",
       "              -0.4686\n",
       "              -0.4754\n",
       "              [torch.cuda.FloatTensor of size 1024 (GPU 0)]),\n",
       "             ('fc0.linear.weight', \n",
       "              -1.2444e-01  2.6263e-01 -5.0042e-01  ...   8.2348e-02 -4.2776e-01  3.1197e-01\n",
       "              -1.3519e-02  3.3216e-02 -2.9402e-02  ...  -2.4083e-02  1.3840e-03  6.8412e-02\n",
       "              -1.0084e-02 -2.1950e-03  5.6152e-01  ...  -5.9022e-01 -1.8388e-01 -6.9634e-01\n",
       "                              ...                   â‹±                   ...                \n",
       "               4.4992e-02 -3.4169e-02 -3.9565e-02  ...  -2.2984e-02  1.5677e-02  2.5794e-02\n",
       "               4.1491e-01 -1.6250e-01  8.3773e-02  ...  -2.5240e-01  1.1802e-01  1.1895e-01\n",
       "              -7.6817e-04  3.7890e-01 -2.1146e-01  ...   2.4930e-01 -7.1875e-02 -3.6938e-02\n",
       "              [torch.cuda.FloatTensor of size 1024x512 (GPU 0)]),\n",
       "             ('fc0.linear.bias', \n",
       "               0.0266\n",
       "              -0.1732\n",
       "              -0.6888\n",
       "                 â‹®   \n",
       "              -0.0997\n",
       "               0.0162\n",
       "              -0.0054\n",
       "              [torch.cuda.FloatTensor of size 1024 (GPU 0)])])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
