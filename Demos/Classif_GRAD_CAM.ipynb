{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import importlib\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gzip\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import HTML\n",
    "from skvideo.io import FFmpegReader, ffprobe, vwrite\n",
    "from torch.autograd import Variable\n",
    "from ptcap.trainers import DataParallelWrapper\n",
    "from ptcap.grad_cam_videos import GradCam\n",
    "from ptcap.data.annotation_parser import V2Parser\n",
    "\n",
    "sys.path.insert(0, \"../\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_templates = sorted(set(validation_parser.annotations[\"template\"]))\n",
    "# print(\"Number of different classes: \", len(all_templates))\n",
    "# class_dict = {k: idx for idx, k in enumerate(all_templates)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "int2label={\n",
    " 0: 'Approaching [something] with your camera',\n",
    " 1: 'Attaching [something] to [something]',\n",
    " 2: 'Bending [something] so that it deforms',\n",
    " 3: 'Bending [something] until it breaks',\n",
    " 4: 'Burying [something] in [something]',\n",
    " 5: 'Closing [something]',\n",
    " 6: 'Covering [something] with [something]',\n",
    " 7: 'Digging [something] out of [something]',\n",
    " 8: 'Dropping [something] behind [something]',\n",
    " 9: 'Dropping [something] in front of [something]',\n",
    " 10: 'Dropping [something] into [something]',\n",
    " 11: 'Dropping [something] next to [something]',\n",
    " 12: 'Dropping [something] onto [something]',\n",
    " 13: 'Failing to put [something] into [something] because [something] does not fit',\n",
    " 14: 'Folding [something]',\n",
    " 15: 'Hitting [something] with [something]',\n",
    " 16: 'Holding [something]',\n",
    " 17: 'Holding [something] behind [something]',\n",
    " 18: 'Holding [something] in front of [something]',\n",
    " 19: 'Holding [something] next to [something]',\n",
    " 20: 'Holding [something] over [something]',\n",
    " 21: 'Laying [something] on the table on its side, not upright',\n",
    " 22: 'Letting [something] roll along a flat surface',\n",
    " 23: 'Letting [something] roll down a slanted surface',\n",
    " 24: 'Letting [something] roll up a slanted surface, so it rolls back down',\n",
    " 25: 'Lifting [something] up completely without letting it drop down',\n",
    " 26: 'Lifting [something] up completely, then letting it drop down',\n",
    " 27: 'Lifting [something] with [something] on it',\n",
    " 28: 'Lifting a surface with [something] on it but not enough for it to slide down',\n",
    " 29: 'Lifting a surface with [something] on it until it starts sliding down',\n",
    " 30: 'Lifting up one end of [something] without letting it drop down',\n",
    " 31: 'Lifting up one end of [something], then letting it drop down',\n",
    " 32: 'Moving [part] of [something]',\n",
    " 33: 'Moving [something] across a surface until it falls down',\n",
    " 34: 'Moving [something] across a surface without it falling down',\n",
    " 35: 'Moving [something] and [something] away from each other',\n",
    " 36: 'Moving [something] and [something] closer to each other',\n",
    " 37: 'Moving [something] and [something] so they collide with each other',\n",
    " 38: 'Moving [something] and [something] so they pass each other',\n",
    " 39: 'Moving [something] away from [something]',\n",
    " 40: 'Moving [something] away from the camera',\n",
    " 41: 'Moving [something] closer to [something]',\n",
    " 42: 'Moving [something] down',\n",
    " 43: 'Moving [something] towards the camera',\n",
    " 44: 'Moving [something] up',\n",
    " 45: 'Moving away from [something] with your camera',\n",
    " 46: 'Opening [something]',\n",
    " 47: 'Picking [something] up',\n",
    " 48: 'Piling [something] up',\n",
    " 49: 'Plugging [something] into [something]',\n",
    " 50: 'Plugging [something] into [something] but pulling it right out as you remove your hand',\n",
    " 51: 'Poking [something] so it slightly moves',\n",
    " 52: \"Poking [something] so lightly that it doesn't or almost doesn't move\",\n",
    " 53: 'Poking [something] so that it falls over',\n",
    " 54: 'Poking [something] so that it spins around',\n",
    " 55: 'Poking a hole into [some substance]',\n",
    " 56: 'Poking a hole into [something soft]',\n",
    " 57: 'Poking a stack of [something] so the stack collapses',\n",
    " 58: 'Poking a stack of [something] without the stack collapsing',\n",
    " 59: 'Pouring [something] into [something]',\n",
    " 60: 'Pouring [something] into [something] until it overflows',\n",
    " 61: 'Pouring [something] onto [something]',\n",
    " 62: 'Pouring [something] out of [something]',\n",
    " 63: 'Pretending or failing to wipe [something] off of [something]',\n",
    " 64: 'Pretending or trying and failing to twist [something]',\n",
    " 65: 'Pretending to be tearing [something that is not tearable]',\n",
    " 66: 'Pretending to close [something] without actually closing it',\n",
    " 67: 'Pretending to open [something] without actually opening it',\n",
    " 68: 'Pretending to pick [something] up',\n",
    " 69: 'Pretending to poke [something]',\n",
    " 70: 'Pretending to pour [something] out of [something], but [something] is empty',\n",
    " 71: 'Pretending to put [something] behind [something]',\n",
    " 72: 'Pretending to put [something] into [something]',\n",
    " 73: 'Pretending to put [something] next to [something]',\n",
    " 74: 'Pretending to put [something] on a surface',\n",
    " 75: 'Pretending to put [something] onto [something]',\n",
    " 76: 'Pretending to put [something] underneath [something]',\n",
    " 77: 'Pretending to scoop [something] up with [something]',\n",
    " 78: 'Pretending to spread air onto [something]',\n",
    " 79: 'Pretending to sprinkle air onto [something]',\n",
    " 80: 'Pretending to squeeze [something]',\n",
    " 81: 'Pretending to take [something] from [somewhere]',\n",
    " 82: 'Pretending to take [something] out of [something]',\n",
    " 83: 'Pretending to throw [something]',\n",
    " 84: 'Pretending to turn [something] upside down',\n",
    " 85: 'Pulling [something] from behind of [something]',\n",
    " 86: 'Pulling [something] from left to right',\n",
    " 87: 'Pulling [something] from right to left',\n",
    " 88: 'Pulling [something] onto [something]',\n",
    " 89: 'Pulling [something] out of [something]',\n",
    " 90: 'Pulling two ends of [something] but nothing happens',\n",
    " 91: 'Pulling two ends of [something] so that it gets stretched',\n",
    " 92: 'Pulling two ends of [something] so that it separates into two pieces',\n",
    " 93: 'Pushing [something] from left to right',\n",
    " 94: 'Pushing [something] from right to left',\n",
    " 95: 'Pushing [something] off of [something]',\n",
    " 96: 'Pushing [something] onto [something]',\n",
    " 97: 'Pushing [something] so it spins',\n",
    " 98: \"Pushing [something] so that it almost falls off but doesn't\",\n",
    " 99: 'Pushing [something] so that it falls off the table',\n",
    " 100: 'Pushing [something] so that it slightly moves',\n",
    " 101: 'Pushing [something] with [something]',\n",
    " 102: 'Putting [number of] [something] onto [something]',\n",
    " 103: 'Putting [something similar to other things that are already on the table]',\n",
    " 104: 'Putting [something that cannot actually stand upright] upright on the table, so it falls on its side',\n",
    " 105: 'Putting [something] and [something] on the table',\n",
    " 106: 'Putting [something] behind [something]',\n",
    " 107: 'Putting [something] in front of [something]',\n",
    " 108: 'Putting [something] into [something]',\n",
    " 109: 'Putting [something] next to [something]',\n",
    " 110: 'Putting [something] on a flat surface without letting it roll',\n",
    " 111: 'Putting [something] on a surface',\n",
    " 112: 'Putting [something] on the edge of [something] so it is not supported and falls down',\n",
    " 113: 'Putting [something] onto [something else that cannot support it] so it falls down',\n",
    " 114: 'Putting [something] onto [something]',\n",
    " 115: \"Putting [something] onto a slanted surface but it doesn't glide down\",\n",
    " 116: \"Putting [something] that can't roll onto a slanted surface, so it slides down\",\n",
    " 117: \"Putting [something] that can't roll onto a slanted surface, so it stays where it is\",\n",
    " 118: 'Putting [something] underneath [something]',\n",
    " 119: 'Putting [something] upright on the table',\n",
    " 120: 'Putting [something], [something] and [something] on the table',\n",
    " 121: 'Removing [something], revealing [something] behind',\n",
    " 122: 'Rolling [something] on a flat surface',\n",
    " 123: 'Scooping [something] up with [something]',\n",
    " 124: 'Showing [something] behind [something]',\n",
    " 125: 'Showing [something] next to [something]',\n",
    " 126: 'Showing [something] on top of [something]',\n",
    " 127: 'Showing [something] to the camera',\n",
    " 128: 'Showing a photo of [something] to the camera',\n",
    " 129: 'Showing that [something] is empty',\n",
    " 130: 'Showing that [something] is inside [something]',\n",
    " 131: 'Spilling [something] behind [something]',\n",
    " 132: 'Spilling [something] next to [something]',\n",
    " 133: 'Spilling [something] onto [something]',\n",
    " 134: 'Spinning [something] so it continues spinning',\n",
    " 135: 'Spinning [something] that quickly stops spinning',\n",
    " 136: 'Spreading [something] onto [something]',\n",
    " 137: 'Sprinkling [something] onto [something]',\n",
    " 138: 'Squeezing [something]',\n",
    " 139: 'Stacking [number of] [something]',\n",
    " 140: 'Stuffing [something] into [something]',\n",
    " 141: 'Taking [one of many similar things on the table]',\n",
    " 142: 'Taking [something] from [somewhere]',\n",
    " 143: 'Taking [something] out of [something]',\n",
    " 144: 'Tearing [something] into two pieces',\n",
    " 145: 'Tearing [something] just a little bit',\n",
    " 146: 'Throwing [something]',\n",
    " 147: 'Throwing [something] against [something]',\n",
    " 148: 'Throwing [something] in the air and catching it',\n",
    " 149: 'Throwing [something] in the air and letting it fall',\n",
    " 150: 'Throwing [something] onto a surface',\n",
    " 151: \"Tilting [something] with [something] on it slightly so it doesn't fall down\",\n",
    " 152: 'Tilting [something] with [something] on it until it falls off',\n",
    " 153: 'Tipping [something] over',\n",
    " 154: 'Tipping [something] with [something in it] over, so [something in it] falls out',\n",
    " 155: 'Touching (without moving) [part] of [something]',\n",
    " 156: \"Trying but failing to attach [something] to [something] because it doesn't stick\",\n",
    " 157: 'Trying to bend [something unbendable] so nothing happens',\n",
    " 158: 'Trying to pour [something] into [something], but missing so it spills next to it',\n",
    " 159: 'Turning [something] upside down',\n",
    " 160: 'Turning the camera downwards while filming [something]',\n",
    " 161: 'Turning the camera left while filming [something]',\n",
    " 162: 'Turning the camera right while filming [something]',\n",
    " 163: 'Turning the camera upwards while filming [something]',\n",
    " 164: 'Twisting (wringing) [something] wet until water comes out',\n",
    " 165: 'Twisting [something]',\n",
    " 166: 'Uncovering [something]',\n",
    " 167: 'Unfolding [something]',\n",
    " 168: 'Wiping [something] off of [something]',\n",
    " 169: '[Something] being deflected from [something]',\n",
    " 170: '[Something] colliding with [something] and both are being deflected',\n",
    " 171: '[Something] colliding with [something] and both come to a halt',\n",
    " 172: '[Something] falling like a feather or paper',\n",
    " 173: '[Something] falling like a rock'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptcap.model.captioners import EncoderDecoder\n",
    "from ptcap.model.encoders import C3dLSTMEncoder\n",
    "from ptcap.model.two_stream_encoders import TwoStreamEncoder\n",
    "from ptcap.model.external_encoders import FCEncoder, JesterEncoder, BIJesterEncoder\n",
    "from ptcap.model.decoders import LSTMDecoder, CoupledLSTMDecoder\n",
    "\n",
    "net = EncoderDecoder(\n",
    "        encoder=TwoStreamEncoder,\n",
    "        decoder=CoupledLSTMDecoder,\n",
    "        encoder_kwargs={\"encoder_output_size\": 1024,\"c2d_out_ch\": 32,\n",
    "                   \"c3d_out_ch\": 32, \"rnn_output_size\":1024},#, \"pretrained_path\": \"/home/farzaneh/PycharmProjects/pretrained_nets/fully_conv_net_on_smtsmt_20170627/model.checkpoint\"},\n",
    "        decoder_kwargs={\"embedding_size\": 256, \"hidden_size\": 1024, \"num_lstm_layers\": 2, \n",
    "        \"vocab_size\": 2728, \"num_step\" :17, \"fc_size\":1024}, \n",
    "        gpus=[0]).cuda()\n",
    "net = DataParallelWrapper(net, device_ids=[0]).cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/home/farzaneh/PycharmProjects/pytorch-captioning/results/clapnet_balanced_tokens/'\n",
    "path = '/home/farzaneh/PycharmProjects/pytorch-captioning/results/ECCV/v2_gulp160_two_stream_c2_32_c3_32_labels_cutoff5_cassif1_cap0/'\n",
    "\n",
    "checkpoint = torch.load(path + '/model.best')\n",
    "\n",
    "\n",
    "net.load_state_dict(checkpoint[\"model\"])\n",
    "#checkpoint[\"model\"].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_path = \"/data/20bn-something-something-v2/v2-validation.json\"\n",
    "videos_folder = \"/data-ssd/v2-gulp-160/\"\n",
    "caption_type = \"label\"\n",
    "\n",
    "validation_parser = V2Parser(validation_path,\n",
    "                                            videos_folder,\n",
    "                               caption_type=caption_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_parser.annotations[\"template\"]\n",
    "all_templates = sorted(set(validation_parser.annotations[\"template\"]))\n",
    "print(\"Number of different classes: \", len(all_templates))\n",
    "class_dict = {k: idx for idx, k in enumerate(all_templates)}\n",
    "inv_class_dict = {idx:k for k, idx in class_dict.items()}\n",
    "#class_dict = [class_dict[p] for p in all_templates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_generator(annotation_path, root_path):\n",
    "    with open(annotation_path, \"rt\") as f:\n",
    "        annotations = json.load(f)\n",
    "    files = validation_parser.get_video_paths()\n",
    "    captions = validation_parser.get_captions()\n",
    "    classif_labels = validation_parser.get_labels()\n",
    "    return ((os.path.join(root_path, f), cap, classif_l) for f, cap, classif_l in zip(files, captions, classif_labels))\n",
    "path_gen = path_generator('/data/20bn-something-something-v2/v2-train.json', \n",
    "                          '/data/20bn-something-something-v2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rtorchn.data.fileio import MpegReader\n",
    "\n",
    "reader = MpegReader(12, (128, 128), keep_aspect_ratio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rtorchn.data.preprocessing import default_evaluation_preprocesser\n",
    "\n",
    "preprocessor = default_evaluation_preprocesser([48, 96, 96], 64.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptcap.data.tokenizer import Tokenizer\n",
    "\n",
    "USER_MAXLEN=17\n",
    "tokenizer = Tokenizer(user_maxlen=USER_MAXLEN)\n",
    "tokenizer.load_dictionaries(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_model2(net, video):\n",
    "\n",
    "    gradients = []\n",
    "    layer_feats = []\n",
    "    x = video\n",
    "    ###########################################################################################\n",
    "\n",
    "#     for name, module in net.module.encoder.c3d_extractor._modules.items():\n",
    "#         print(name)\n",
    "#         x = module(x)\n",
    "#         if \"conv4\" in name:\n",
    "#             x.register_hook(lambda grad:gradients.append(grad))\n",
    "#             print(\"U\"*10)\n",
    "#             print(gradients)\n",
    "#             print(\"grad appended\")\n",
    "#             layer_feats += [x]\n",
    "\n",
    "#     x = x.view(x.size()[0:3])  # [batch_size*num_feature*num_step](8*256*48)\n",
    "#     c3d2 = x.permute(0, 2, 1)\n",
    "#     layer_feats = layer_feats[0]\n",
    "#     print(gradients)\n",
    "#     ###########################################################################################\n",
    "    conv1_feats = net.module.encoder.c3d_extractor.conv1(video)\n",
    "    pool1_feats = net.module.encoder.c3d_extractor.pool1(conv1_feats)\n",
    "\n",
    "    conv2_feats = net.module.encoder.c3d_extractor.conv2(pool1_feats)\n",
    "    pool2_feats = net.module.encoder.c3d_extractor.pool2(conv2_feats)\n",
    "\n",
    "    conv3_feats = net.module.encoder.c3d_extractor.conv3(pool2_feats)  \n",
    "\n",
    "    pool3_feats = net.module.encoder.c3d_extractor.pool3(conv3_feats)  \n",
    "\n",
    "    conv4_feats = net.module.encoder.c3d_extractor.conv4(pool3_feats) \n",
    "\n",
    "\n",
    "    conv5_feats = net.module.encoder.c3d_extractor.conv5(conv4_feats)   \n",
    "    conv6_feats = net.module.encoder.c3d_extractor.conv6(conv5_feats)   \n",
    "    \n",
    " # REGISTER HOOK ##\n",
    "    layer_feats = conv6_feats\n",
    "    conv6_feats.register_hook(lambda grad:gradients.append(grad))\n",
    "\n",
    "    pool4_feats = net.module.encoder.c3d_extractor.pool4(conv6_feats)   \n",
    "\n",
    "\n",
    "    pool4_feats = pool4_feats.view(pool4_feats.size()[0:3])   \n",
    "\n",
    "    c3d2 = pool4_feats.permute(0, 2, 1)   \n",
    "\n",
    "#     c3d2 = net.module.encoder.c3d_extractor.extract_features(video)\n",
    "    ###########################################################################################\n",
    "    c2d2 = net.module.encoder.c2d_extractor.extract_features(video)\n",
    "\n",
    "    h2 = torch.cat([c2d2, c3d2 ], 2)\n",
    "\n",
    "    #net.module.encoder.lstm.flatten_parameters()\n",
    "    lstm_outputs2, _ = net.module.encoder.lstm(h2) \n",
    "    oo =  net.module.encoder.dropout(net.module.encoder.relu(net.module.encoder.fc(lstm_outputs2)))\n",
    "\n",
    "        #h = net.module.encoder.extract_features(video)\n",
    "    net_classif_output2 = net.module.predict_from_encoder_features(oo)\n",
    "\n",
    "    return net_classif_output2,h2, lstm_outputs2, c2d2, c3d2, layer_feats, gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(net, input_tuple ):\n",
    "    video, caption = input_tuple\n",
    "    probs, classif_probs1, h1, lstm_outputs1, c2d1, c3d1 = net((video, caption), False)\n",
    "    return classif_probs1, h1, lstm_outputs1, c2d1, c3d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAM calculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cam(net, net_output, layer_feats, target_index, vocab_size, gradients, token_counter):\n",
    "\n",
    "    one_hot = np.zeros((1, vocab_size), dtype=np.float32)\n",
    "    one_hot[0][target_index] = 1\n",
    "    one_hot = Variable(torch.from_numpy(one_hot), requires_grad=True)\n",
    "    one_hot = torch.sum(one_hot.cuda() * net_output)\n",
    "    \n",
    "    net.module.encoder.c2d_extractor.conv4.zero_grad()\n",
    "    #net.module.classif_layer.zero_grad()\n",
    "    one_hot.backward(retain_graph=True)\n",
    "    print(\"backward\"*10)\n",
    "\n",
    "    grads_val = gradients[0].cpu().data.numpy() #take the only element out of gradients list\n",
    "    feats_numpy = layer_feats.cpu().data.numpy()[0, :] #first sample of batch\n",
    "    weights = np.mean(grads_val, axis=(2, 3, 4))[0, :]   #grads_val: (1, 256, 48, 10, 10)\n",
    "    cam = np.ones(feats_numpy.shape[1:], dtype=np.float32)\n",
    "    weights = weights / weights.max()\n",
    "    for ii, ww in enumerate(weights):\n",
    "        cam += ww * feats_numpy[ii, :, :, :]\n",
    "    #     cam = np.maximum(cam, 0)\n",
    "    return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path_to_video, _, classif_label = next(path_gen)\n",
    "# path_to_video = '/data/20bn-something-something-v2/149631.webm'\n",
    "\n",
    "# classif_label = 47\n",
    "\n",
    "video_uint8 = reader.open(path_to_video)\n",
    "video = preprocessor(video_uint8)\n",
    "video = Variable(torch.from_numpy(video[None]), volatile=False).cuda()\n",
    "empty_caption = Variable(torch.zeros([1, 1]), volatile=True).long().cuda()\n",
    "\n",
    "\n",
    "vocab_size = 178\n",
    "\n",
    "\n",
    "\n",
    "all_cams = []\n",
    "\n",
    "\n",
    "target_index =  classif_label\n",
    "\n",
    "##model\n",
    "net_output, h, lstm_out, c2d, c3d  = run_model(net, (video, empty_caption))\n",
    "_,predind  = torch.max(net_output, dim=1)\n",
    "print(\"pppppp\"*10)\n",
    "\n",
    "\n",
    "net2_output, h2, lstm_out2, c2d2, c3d2, layer_feats, gradients = run_model2(net,video )\n",
    "_, goh2 = torch.max(net2_output , dim=1)\n",
    "cam = calc_cam(net, net2_output, layer_feats, target_index, vocab_size, gradients, 0)\n",
    "\n",
    "\n",
    "print(int2label[classif_label])\n",
    "print( [classif_label])\n",
    "print( [predind.data.cpu().numpy()[0]])\n",
    "print( [goh2.data.cpu().numpy()[0]])\n",
    "print(\"*\"*15)\n",
    "\n",
    "for gg in range(1,video_uint8.shape[0], 2):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    single_cam = cam[gg]\n",
    "    single_cam = cv2.resize(single_cam, (224, 224))\n",
    "    single_cam = single_cam - np.min(single_cam)\n",
    "    single_cam = single_cam / np.max(single_cam)\n",
    "    plt.imshow(single_cam)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(video_uint8[gg])\n",
    "    plt.show()\n",
    "    all_cams.append(single_cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnNormalize(object):\n",
    "    \"\"\"Unnormalize an tensor image with mean and standard deviation.\n",
    "    Given mean: (R, G, B) and std: (R, G, B),\n",
    "    will normalize each channel of the torch.*Tensor, i.e.\n",
    "    channel = (channel x std) + mean\n",
    "    Args:\n",
    "        mean (sequence): Sequence of means for R, G, B channels respecitvely.\n",
    "        std (sequence): Sequence of standard deviations for R, G, B channels\n",
    "            respecitvely.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = np.array(mean).astype('float32')\n",
    "        self.std = np.array(std).astype('float32')\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        if isinstance(tensor, torch.Tensor):\n",
    "            self.mean = torch.FloatTensor(self.mean)\n",
    "            self.std = torch.FloatTensor(self.std)\n",
    "\n",
    "            if (self.std.dim() != tensor.dim() or\n",
    "                    self.mean.dim() != tensor.dim()):\n",
    "                for i in range(tensor.dim() - self.std.dim()):\n",
    "                    self.std = self.std.unsqueeze(-1)\n",
    "                    self.mean = self.mean.unsqueeze(-1)\n",
    "\n",
    "            tensor = torch.add(torch.mul(tensor, self.std), self.mean)\n",
    "        else:\n",
    "            # Relying on Numpy broadcasting abilities\n",
    "            tensor = tensor * self.std + self.mean\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unnormalize_op = UnNormalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "input_data_unnormalised = unnormalize_op(video.data.cpu().squeeze(0))\n",
    "input_data_unnormalised = input_data_unnormalised.permute(1, 2, 3, 0).numpy()  # (16x224x224x3)\n",
    "input_data_unnormalised = np.flip(input_data_unnormalised, 3)\n",
    "\n",
    "output_images_folder_cam_combined = os.path.join(\"cam_saved_images\", \"/home/farzaneh/cam/\", \"combined\")\n",
    "\n",
    "output_images_folder_original = os.path.join(\"cam_saved_images\", \"/home/farzaneh/cam/\", \"original\")\n",
    "output_images_folder_cam = os.path.join(\"cam_saved_images\", \"/home/farzaneh/cam\", \"cam\")\n",
    "\n",
    "os.makedirs(output_images_folder_cam_combined, exist_ok=True)\n",
    "os.makedirs(output_images_folder_cam, exist_ok=True)\n",
    "os.makedirs(output_images_folder_original, exist_ok=True)\n",
    "\n",
    "clip_size = len(all_cams)\n",
    "\n",
    "RESIZE_SIZE = 96\n",
    "RESIZE_FLAG = 1\n",
    "SAVE_INDIVIDUALS = 1\n",
    "for i in range(clip_size):\n",
    "    input_data_img = input_data_unnormalised[i, :, :, :]\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * all_cams[i]), cv2.COLORMAP_JET)\n",
    "    if RESIZE_FLAG:\n",
    "        input_data_img = cv2.resize(input_data_img, (RESIZE_SIZE, RESIZE_SIZE))\n",
    "        heatmap = cv2.resize(heatmap, (RESIZE_SIZE, RESIZE_SIZE))\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    cam = heatmap + np.float32(input_data_img)\n",
    "    cam = cam / np.max(cam)\n",
    "    combined_img = np.concatenate((np.uint8(255 * input_data_img), np.uint8(255 * cam)), axis=1)\n",
    "    \n",
    "    cv2.imwrite(os.path.join(output_images_folder_cam_combined, \"img%02d.jpg\" % (i + 1)), combined_img)\n",
    "    if SAVE_INDIVIDUALS:\n",
    "        cv2.imwrite(os.path.join(output_images_folder_cam, \"img%02d.jpg\" % (i + 1)), np.uint8(255 * cam))\n",
    "        cv2.imwrite(os.path.join(output_images_folder_original, \"img%02d.jpg\" % (i + 1)), np.uint8(255 * input_data_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_combined_gif = os.path.join(output_images_folder_cam_combined, \"mygif.gif\")\n",
    "os.system(\"convert -delay 10 -loop 0 {}.jpg {}\".format(\n",
    "                                    os.path.join(output_images_folder_cam_combined, \"*\"),\n",
    "                                    path_to_combined_gif))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
