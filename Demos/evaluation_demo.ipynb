{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Evaluation Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import gzip\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import HTML\n",
    "from skvideo.io import FFmpegReader, ffprobe, vwrite\n",
    "from torch.autograd import Variable\n",
    "from ptcap.trainers import DataParallelWrapper\n",
    "from ptcap.scores import ( caption_accuracy, first_token_accuracy, token_accuracy)\n",
    "from ptcap.data.annotation_parser import JsonParser\n",
    "from collections import OrderedDict\n",
    "from collections import Counter, namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int2label = {\n",
    "     0: 'Approaching [something] with your camera',\n",
    "     1: 'Attaching [something] to [something]',\n",
    "     2: 'Bending [something] so that it deforms',\n",
    "     3: 'Bending [something] until it breaks',\n",
    "     4: 'Burying [something] in [something]',\n",
    "     5: 'Closing [something]',\n",
    "     6: 'Covering [something] with [something]',\n",
    "     7: 'Digging [something] out of [something]',\n",
    "     8: 'Dropping [something] behind [something]',\n",
    "     9: 'Dropping [something] in front of [something]',\n",
    "     10: 'Dropping [something] into [something]',\n",
    "     11: 'Dropping [something] next to [something]',\n",
    "     12: 'Dropping [something] onto [something]',\n",
    "     13: 'Failing to put [something] into [something] because [something] does not fit',\n",
    "     14: 'Folding [something]',\n",
    "     15: 'Hitting [something] with [something]',\n",
    "     16: 'Holding [something]',\n",
    "     17: 'Holding [something] behind [something]',\n",
    "     18: 'Holding [something] in front of [something]',\n",
    "     19: 'Holding [something] next to [something]',\n",
    "     20: 'Holding [something] over [something]',\n",
    "     21: 'Laying [something] on the table on its side, not upright',\n",
    "     22: 'Letting [something] roll along a flat surface',\n",
    "     23: 'Letting [something] roll down a slanted surface',\n",
    "     24: 'Letting [something] roll up a slanted surface, so it rolls back down',\n",
    "     25: 'Lifting [something] up completely without letting it drop down',\n",
    "     26: 'Lifting [something] up completely, then letting it drop down',\n",
    "     27: 'Lifting [something] with [something] on it',\n",
    "     28: 'Lifting a surface with [something] on it but not enough for it to slide down',\n",
    "     29: 'Lifting a surface with [something] on it until it starts sliding down',\n",
    "     30: 'Lifting up one end of [something] without letting it drop down',\n",
    "     31: 'Lifting up one end of [something], then letting it drop down',\n",
    "     32: 'Moving [part] of [something]',\n",
    "     33: 'Moving [something] across a surface until it falls down',\n",
    "     34: 'Moving [something] across a surface without it falling down',\n",
    "     35: 'Moving [something] and [something] away from each other',\n",
    "     36: 'Moving [something] and [something] closer to each other',\n",
    "     37: 'Moving [something] and [something] so they collide with each other',\n",
    "     38: 'Moving [something] and [something] so they pass each other',\n",
    "     39: 'Moving [something] away from [something]',\n",
    "     40: 'Moving [something] away from the camera',\n",
    "     41: 'Moving [something] closer to [something]',\n",
    "     42: 'Moving [something] down',\n",
    "     43: 'Moving [something] towards the camera',\n",
    "     44: 'Moving [something] up',\n",
    "     45: 'Moving away from [something] with your camera',\n",
    "     46: 'Opening [something]',\n",
    "     47: 'Picking [something] up',\n",
    "     48: 'Piling [something] up',\n",
    "     49: 'Plugging [something] into [something]',\n",
    "     50: 'Plugging [something] into [something] but pulling it right out as you remove your hand',\n",
    "     51: 'Poking [something] so it slightly moves',\n",
    "     52: 'Poking [something] so lightly that it doesn’t or almost doesn’t move',\n",
    "     53: 'Poking [something] so that it falls over',\n",
    "     54: 'Poking [something] so that it spins around',\n",
    "     55: 'Poking a hole into [some substance]',\n",
    "     56: 'Poking a hole into [something soft]',\n",
    "     57: 'Poking a stack of [something] so the stack collapses',\n",
    "     58: 'Poking a stack of [something] without the stack collapsing',\n",
    "     59: 'Pouring [something] into [something]',\n",
    "     60: 'Pouring [something] into [something] until it overflows',\n",
    "     61: 'Pouring [something] onto [something]',\n",
    "     62: 'Pouring [something] out of [something]',\n",
    "     63: 'Pretending or failing to wipe [something] off of [something]',\n",
    "     64: 'Pretending or trying and failing to twist [something]',\n",
    "     65: 'Pretending to be tearing [something that is not tearable]',\n",
    "     66: 'Pretending to close [something] without actually closing it',\n",
    "     67: 'Pretending to open [something] without actually opening it',\n",
    "     68: 'Pretending to pick [something] up',\n",
    "     69: 'Pretending to poke [something]',\n",
    "     70: 'Pretending to pour [something] out of [something], but [something] is empty',\n",
    "     71: 'Pretending to put [something] behind [something]',\n",
    "     72: 'Pretending to put [something] into [something]',\n",
    "     73: 'Pretending to put [something] next to [something]',\n",
    "     74: 'Pretending to put [something] on a surface',\n",
    "     75: 'Pretending to put [something] onto [something]',\n",
    "     76: 'Pretending to put [something] underneath [something]',\n",
    "     77: 'Pretending to scoop [something] up with [something]',\n",
    "     78: 'Pretending to spread “air” onto [something]',\n",
    "     79: 'Pretending to sprinkle \"air\" onto [something]',\n",
    "     80: 'Pretending to squeeze [something]',\n",
    "     81: 'Pretending to take [something] from [somewhere]',\n",
    "     82: 'Pretending to take [something] out of [something]',\n",
    "     83: 'Pretending to throw [something]',\n",
    "     84: 'Pretending to turn [something] upside down',\n",
    "     85: 'Pulling [something] from behind of [something]',\n",
    "     86: 'Pulling [something] from left to right',\n",
    "     87: 'Pulling [something] from right to left',\n",
    "     88: 'Pulling [something] onto [something]',\n",
    "     89: 'Pulling [something] out of [something]',\n",
    "     90: 'Pulling two ends of [something] but nothing happens',\n",
    "     91: 'Pulling two ends of [something] so that it gets stretched',\n",
    "     92: 'Pulling two ends of [something] so that it separates into two pieces',\n",
    "     93: 'Pushing [something] from left to right',\n",
    "     94: 'Pushing [something] from right to left',\n",
    "     95: 'Pushing [something] off of [something]',\n",
    "     96: 'Pushing [something] onto [something]',\n",
    "     97: 'Pushing [something] so it spins',\n",
    "     98: \"Pushing [something] so that it almost falls off but doesn't\",\n",
    "     99: 'Pushing [something] so that it falls off the table',\n",
    "     100: 'Pushing [something] so that it slightly moves',\n",
    "     101: 'Pushing [something] with [something]',\n",
    "     102: 'Putting [number of] [something] onto [something]',\n",
    "     103: 'Putting [something similar to other things that are already on the table]',\n",
    "     104: 'Putting [something that cannot actually stand upright] upright on the table, so it falls on its side',\n",
    "     105: 'Putting [something] and [something] on the table',\n",
    "     106: 'Putting [something] behind [something]',\n",
    "     107: 'Putting [something] in front of [something]',\n",
    "     108: 'Putting [something] into [something]',\n",
    "     109: 'Putting [something] next to [something]',\n",
    "     110: 'Putting [something] on a flat surface without letting it roll',\n",
    "     111: 'Putting [something] on a surface',\n",
    "     112: 'Putting [something] on the edge of [something] so it is not supported and falls down',\n",
    "     113: 'Putting [something] onto [something else that cannot support it] so it falls down',\n",
    "     114: 'Putting [something] onto [something]',\n",
    "     115: 'Putting [something] onto a slanted surface but it doesn’t glide down',\n",
    "     116: 'Putting [something] that can’t roll onto a slanted surface, so it slides down',\n",
    "     117: 'Putting [something] that can’t roll onto a slanted surface, so it stays where it is',\n",
    "     118: 'Putting [something] underneath [something]',\n",
    "     119: 'Putting [something] upright on the table',\n",
    "     120: 'Putting [something], [something] and [something] on the table',\n",
    "     121: 'Removing [something], revealing [something] behind',\n",
    "     122: 'Rolling [something] on a flat surface',\n",
    "     123: 'Scooping [something] up with [something]',\n",
    "     124: 'Show a shadow of [something] that is moving. ',\n",
    "     125: 'Show a shadow of [something], making sure the shadow is not moving. ',\n",
    "     126: 'Showing [something] behind [something]',\n",
    "     127: 'Showing [something] next to [something]',\n",
    "     128: 'Showing [something] on top of [something]',\n",
    "     129: 'Showing [something] to the camera',\n",
    "     130: 'Showing a photo of [something] to the camera',\n",
    "     131: 'Showing a shadow of [something] that is moving.',\n",
    "     132: 'Showing a shadow of [something], making sure the shadow is not moving.',\n",
    "     133: 'Showing that [something] is empty',\n",
    "     134: 'Showing that [something] is inside [something]',\n",
    "     135: 'Spilling [something] behind [something]',\n",
    "     136: 'Spilling [something] next to [something]',\n",
    "     137: 'Spilling [something] onto [something]',\n",
    "     138: 'Spinning [something] so it continues spinning',\n",
    "     139: 'Spinning [something] that quickly stops spinning',\n",
    "     140: 'Spreading [something] onto [something]',\n",
    "     141: 'Sprinkling [something] onto [something]',\n",
    "     142: 'Squeezing [something]',\n",
    "     143: 'Stacking [number of] [something]',\n",
    "     144: 'Stuffing [something] into [something]',\n",
    "     145: 'Taking [one of many similar things on the table]',\n",
    "     146: 'Taking [something] from [somewhere]',\n",
    "     147: 'Taking [something] out of [something]',\n",
    "     148: 'Tearing [something] into two pieces',\n",
    "     149: 'Tearing [something] just a little bit',\n",
    "     150: 'Throwing [something]',\n",
    "     151: 'Throwing [something] against [something]',\n",
    "     152: 'Throwing [something] in the air and catching it',\n",
    "     153: 'Throwing [something] in the air and letting it fall',\n",
    "     154: 'Throwing [something] onto a surface',\n",
    "     155: 'Tilting [something] with [something] on it slightly so it doesn’t fall down',\n",
    "     156: 'Tilting [something] with [something] on it until it falls off',\n",
    "     157: 'Tipping [something] over',\n",
    "     158: 'Tipping [something] with [something in it] over, so [something in it] falls out',\n",
    "     159: 'Touching (without moving) [part] of [something]',\n",
    "     160: 'Trying but failing to attach [something] to [something] because it doesn’t stick',\n",
    "     161: 'Trying to bend [something unbendable] so nothing happens',\n",
    "     162: 'Trying to pour [something] into [something], but missing so it spills next to it',\n",
    "     163: 'Turning [something] upside down',\n",
    "     164: 'Turning the camera downwards while filming [something]',\n",
    "     165: 'Turning the camera left while filming [something]',\n",
    "     166: 'Turning the camera right while filming [something]',\n",
    "     167: 'Turning the camera upwards while filming [something]',\n",
    "     168: 'Twisting (wringing) [something] wet until water comes out',\n",
    "     169: 'Twisting [something]',\n",
    "     170: 'Uncovering [something]',\n",
    "     171: 'Unfolding [something]',\n",
    "     172: 'Wiping [something] off of [something]',\n",
    "     173: '[Something] being deflected from [something]',\n",
    "     174: '[Something] colliding with [something] and both are being deflected',\n",
    "     175: '[Something] colliding with [something] and both come to a halt',\n",
    "     176: '[Something] falling like a feather or paper',\n",
    "     177: '[Something] falling like a rock'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = ['A', 'AN', 'THE', '<END>']\n",
    "\n",
    "def safe_div(x,y):\n",
    "    if y == 0:\n",
    "        return 0\n",
    "    return x / y\n",
    "def fscore(precision, recall, beta=1):\n",
    "    numerator = (1.0 + (beta ** 2)) * precision * recall\n",
    "    denominator = ((beta ** 2) * precision) + recall\n",
    "    return {\"fscore\": safe_div(numerator, denominator)}\n",
    "class LCS(object):\n",
    "    \"\"\"\n",
    "    The main functionality of this class is to compute the LCS (Lowest Common\n",
    "    Subsequence) between a caption and prediction. By default, it returns the\n",
    "    precision and recall values calculated based on the LCS between a prediction\n",
    "    and a caption.\n",
    "    \"\"\"\n",
    "    def __init__(self, functions_list, tokenizer):\n",
    "        \"\"\"\n",
    "        Initializes functions_list and tokenizer.\n",
    "        Args:\n",
    "        functions_list: A list of the functions that will be applied on the\n",
    "        precision and recall values calculated based on the LCS between a\n",
    "        prediction and a caption.\n",
    "        \"\"\"\n",
    "\n",
    "        self.functions_list = functions_list\n",
    "        self.scores_container = OrderedDict()\n",
    "        self.scores_dict = OrderedDict()\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, outputs):\n",
    "        string_predictions = [self.tokenizer.get_string(str_pred.data.numpy())\n",
    "                              for str_pred in outputs.predictions]\n",
    "        return self.score_batch(string_predictions, outputs.string_captions)\n",
    "\n",
    "    def collect_scores(self, batch_scores_dict, scores_dict):\n",
    "        for metric, metric_value in scores_dict.items():\n",
    "            if metric not in batch_scores_dict:\n",
    "                batch_scores_dict[metric] = [metric_value]\n",
    "            else:\n",
    "                batch_scores_dict[metric].append(metric_value)\n",
    "        return batch_scores_dict\n",
    "\n",
    "    @classmethod\n",
    "    def compute_lcs(cls, prediction, caption):\n",
    "        num_rows = len(prediction)\n",
    "        num_cols = len(caption)\n",
    "\n",
    "        table = [[0] * (num_cols + 1) for _ in range(num_rows + 1)]\n",
    "        for i in range(1, num_rows + 1):\n",
    "            for j in range(1, num_cols + 1):\n",
    "                if prediction[i - 1] == caption[j - 1]:\n",
    "                    table[i][j] = table[i - 1][j - 1] + 1\n",
    "                else:\n",
    "                    table[i][j] = max(table[i][j - 1], table[i - 1][j])\n",
    "        return table, table[num_rows][num_cols]\n",
    "\n",
    "    def mean_scores(self, batch_scores_dict):\n",
    "        for metric, metric_value in batch_scores_dict.items():\n",
    "            batch_scores_dict[metric] = np.mean(metric_value)\n",
    "        return batch_scores_dict\n",
    "\n",
    "    def score_batch(self, predictions, captions):\n",
    "        assert len(predictions) == len(captions)\n",
    "\n",
    "        batch_scores_dict = OrderedDict()\n",
    "        for count, (prediction, caption) in enumerate(zip(predictions,\n",
    "                                                          captions)):\n",
    "            scores_dict = self.score_sample(prediction.split(), caption.split())\n",
    "            batch_scores_dict = self.collect_scores(batch_scores_dict,\n",
    "                                                    scores_dict)\n",
    "\n",
    "        batch_scores_dict = self.mean_scores(batch_scores_dict)\n",
    "        return batch_scores_dict\n",
    "\n",
    "    def score_sample(self, prediction, caption):\n",
    "        scores_dict = OrderedDict()\n",
    "        _, lcs_score = self.compute_lcs(prediction, caption)\n",
    "        scores_dict[\"precision\"] = safe_div(lcs_score, len(prediction))\n",
    "        scores_dict[\"recall\"] = safe_div(lcs_score, len(caption))\n",
    "\n",
    "        for score_function in self.functions_list:\n",
    "            scores_dict.update(score_function(scores_dict[\"precision\"],\n",
    "                                              scores_dict[\"recall\"]))\n",
    "\n",
    "        return scores_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool to deal with mpeg videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_video(video_filenames):\n",
    "    \"\"\"\n",
    "    Tool to display videos inside the notebook.\n",
    "    \"\"\"\n",
    "    \n",
    "    if type(video_filenames) is not list:\n",
    "        video_filenames = [video_filenames]\n",
    "    \n",
    "    html_code = ''\n",
    "    for filename in video_filenames:\n",
    "        video = io.open(filename, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        html_code += '''\n",
    "        <video alt=\"test\" width=\"640\" height=\"480\" controls>\n",
    "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "        </video>\n",
    "        '''.format(encoded.decode('ascii'))\n",
    "        \n",
    "    return HTML(data= html_code)\n",
    "\n",
    "\n",
    "def open_mpeg_video(fname, framerate, size):\n",
    "    \"\"\"\n",
    "    Open an mpeg video, and return it as a numpy array.\n",
    "    \"\"\"\n",
    "    \n",
    "    metadata = ffprobe(fname)\n",
    "    duration = float(metadata['video']['@duration'])\n",
    "    # Compute corresponding nb of frames\n",
    "    nframes = int(duration * framerate)\n",
    "    oargs = {\n",
    "        \"-r\": \"%d\" % framerate,\n",
    "        \"-vframes\": \"%d\" % nframes,\n",
    "        \"-s\": \"%dx%d\" % (size[0], size[1])\n",
    "    }\n",
    "    # Open file\n",
    "    reader = FFmpegReader(fname, inputdict={}, outputdict=oargs)\n",
    "    video = []\n",
    "    # Get frames until there is no more\n",
    "    for frame in reader.nextFrame():\n",
    "        video.append(frame)\n",
    "    # Return as a numpy array\n",
    "    return np.array(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Model Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptcap.model.captioners import EncoderDecoder\n",
    "from ptcap.model.external_encoders import FCEncoder, JesterEncoder, BIJesterEncoder\n",
    "from ptcap.model.decoders import LSTMDecoder, CoupledLSTMDecoder\n",
    "  \n",
    "#net = FullyConvolutionalNet(num_classes=178)jester1024_cutoff_300_ssssssss/\n",
    "\n",
    "net = EncoderDecoder(\n",
    "        encoder=BIJesterEncoder,\n",
    "        decoder=CoupledLSTMDecoder,\n",
    "        encoder_kwargs={\"freeze\": False},#, \"pretrained_path\": \"/home/farzaneh/PycharmProjects/pretrained_nets/fully_conv_net_on_smtsmt_20170627/model.checkpoint\"},\n",
    "        decoder_kwargs={\"embedding_size\": 256, \"hidden_size\": 512, \"num_lstm_layers\": 2, \n",
    "        \"vocab_size\": 2578, \"num_step\" :17}, \n",
    "        gpus=[0]).cuda()\n",
    "net = DataParallelWrapper(net, device_ids=[0]).cuda(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/farzaneh/PycharmProjects/pytorch-captioning/results/v2_gulp160_labels_classif0.1_cap0.9'\n",
    "# path = '/home/farzaneh/PycharmProjects/pytorch-captioning/results/clapnet_captioning_only_f0.1'\n",
    "\n",
    "checkpoint = torch.load(path + '/model.best')\n",
    "\n",
    "\n",
    "net.load_state_dict(checkpoint[\"model\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ptcap.data.tokenizer import Tokenizer\n",
    "\n",
    "USER_MAXLEN=17\n",
    "tokenizer = Tokenizer(user_maxlen=USER_MAXLEN)\n",
    "tokenizer.load_dictionaries(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D) Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TMP_VIDEO_FILENAME = 'tmp.mp4'\n",
    "\n",
    "def unpreprocess(video):\n",
    "    video = video.data.numpy()[0]\n",
    "    video = 64. * video.transpose(1, 2, 3, 0)\n",
    "    return np.array(video, 'uint8')\n",
    "\n",
    "def demo(net, preprocessor, filename, top_n=5):\n",
    "    # Open mpeg file and get a numpy array\n",
    "    video_uint8 = open_mpeg_video(filename, 12, [128, 128])\n",
    "    # Preprocessing\n",
    "    video = preprocessor(video_uint8)\n",
    "    # Convert to torch variable\n",
    "    video = Variable(torch.from_numpy(video[None]), volatile=True).cuda()\n",
    "    empty_caption = Variable(torch.zeros([1, 1]), volatile=True).long().cuda()\n",
    "    \n",
    "    # Compute predictions\n",
    "    pred, class_pred = net.forward((video, empty_caption), use_teacher_forcing=False)\n",
    "    # Convert to numpy \n",
    "    pred = np.exp(pred.cpu().data.numpy())[0]\n",
    "        \n",
    "    pred_argmax = np.argmax(pred, axis=1)\n",
    "    decoded_pred = tokenizer.decode_caption(pred_argmax)\n",
    "    beautiful_caption = \" \".join(str(e+\" \") for e in decoded_pred if \"<END>\" not in e)\n",
    "    #print('__CAPTION__: {}'.format(beautiful_caption))\n",
    "    \n",
    "    \n",
    "    # Class index\n",
    "    class_index = torch.max(class_pred, dim=1)[1].cpu().data[0]\n",
    "    cls = int2label[class_index]\n",
    "    #print('ACTION: {:60s}\\n'.format(cls))\n",
    "    \n",
    "    \n",
    "    matched_action = get_template(decoded_pred, templates, tokenizer)\n",
    "    # print(actions)\n",
    "    objects = get_object_tokens(decoded_pred, matched_action[0][0])\n",
    "\n",
    "    \n",
    "    objects_list = extract_objects(objects)\n",
    "    # Print class name with proba\n",
    "    # Save input video in tmp file\n",
    "    vwrite(TMP_VIDEO_FILENAME, unpreprocess(video.cpu()))\n",
    "    return beautiful_caption, cls, objects_list, matched_action[0][0]\n",
    "\n",
    "\n",
    "def path_generator(annotation_path, root_path):\n",
    "    with gzip.open(annotation_path, \"rt\") as f:\n",
    "        annotations = json.load(f)\n",
    "    files = [elem['file'] for elem in annotations]\n",
    "    labels = [elem['label'] for elem in annotations]\n",
    "    placeholders = [elem['placeholders'] for elem in annotations] \n",
    "    actions = [elem['template'].replace(\"[\",\"\").replace(\"]\", \"\").replace(\",\",\"\").upper() for elem in annotations]\n",
    "    \n",
    "    return ((os.path.join(root_path, f), label, a, p) for f,label,p, a in zip(files, labels, placeholders, actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path generator\n",
    "path_gen = path_generator('/data/20bn-somethingsomething/json/test_20170929.json.gz', \n",
    "                          '/data/20bn-somethingsomething/videos')\n",
    "# Put the netwoark in evaluation mode\n",
    "_ = net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rtorchn.data.preprocessing import default_evaluation_preprocesser\n",
    "\n",
    "preprocessor = default_evaluation_preprocesser([48, 128, 128], 64.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(5000):\n",
    "    path_to_video, label, _,_ = next(path_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longest Common Subsequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_template(candidates, templates, tokenizer):\n",
    "   \n",
    "    lcs = LCS([fscore], tokenizer)\n",
    "    \n",
    "    max_templates = []\n",
    "    #print(\"There are {} templates\".format(len(templates)))\n",
    "\n",
    "    candidates = [\" \".join(candidates)]\n",
    "    for candidate in candidates:\n",
    "        \n",
    "        max_lcs_template = \"\"\n",
    "        max_lcs_value = -1\n",
    "        for template in templates:\n",
    "            lcs_value = compute_LCS(lcs, candidate, template, tokenizer)\n",
    "            if lcs_value > max_lcs_value:\n",
    "                max_lcs_template = template\n",
    "                max_lcs_value = lcs_value\n",
    "        max_templates.append((max_lcs_template, max_lcs_value))\n",
    "#         print(\"Candidate: {}\".format(candidate))\n",
    "        #print(\"MATCHED ACTION : {}\".format(max_lcs_template))\n",
    "\n",
    "    return max_templates\n",
    "\n",
    "\n",
    "def compute_LCS(lcs, candidate, template, tokenizer):\n",
    "    encoded_caption = Variable(\n",
    "        torch.LongTensor([tokenizer.encode_caption(candidate)]))\n",
    "    encoded_prediction = Variable(\n",
    "        torch.LongTensor([tokenizer.encode_caption(template)]))\n",
    "    score_attr = namedtuple(\"ScoresAttr\", \"string_captions captions predictions\")\n",
    "    in_tuple = score_attr([candidate], encoded_caption, encoded_prediction)\n",
    "    lcs_output = lcs(in_tuple)\n",
    "    return lcs_output['fscore']\n",
    "\n",
    "def extract_objects(object_tokens_list):\n",
    "    \n",
    "    objects_list = []\n",
    "    if len(object_tokens_list) == 0:\n",
    "        return objects_list\n",
    "    \n",
    "    next_token_ind =  object_tokens_list[0][0]\n",
    "    current_object = \"\"\n",
    "    for  (ind, token) in object_tokens_list:\n",
    "        if  next_token_ind == ind:\n",
    "            current_object += token+\" \"\n",
    "        else:\n",
    "            objects_list.append(current_object+\" \")\n",
    "            current_object = token\n",
    "            next_token_ind = ind\n",
    "        next_token_ind += 1\n",
    "        \n",
    "        \n",
    "    if len(current_object)>0:\n",
    "        objects_list.append(current_object)\n",
    "               \n",
    "    #print(\"PREDICTED OBJECTS: {}\".format(objects_list))\n",
    "    return objects_list\n",
    "\n",
    "\n",
    "\n",
    "def get_object_tokens(caption, template):\n",
    "    return [(i,token) for (i,token) in enumerate(caption) if token not in template and token not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "articles= [\"the\", \"a\", \"an\", \"A\", \"An\", \"The\"]\n",
    "\n",
    "annotations = JsonParser.open_annotation(\"/data/20bn-somethingsomething/json/train_20171031.json.gz\")\n",
    "templates = np.unique(annotations[\"template\"]) # A list of templates\n",
    "objects = annotations[\"placeholders\"]\n",
    "obj_tokens = [token for token in objects if token not in stop_words]\n",
    "all_obj=[item for sublist in objects for item in sublist]\n",
    "filtered_obj =  [\" \".join(obj) for obj in all_obj for  token in obj if token not in articles]\n",
    "templates = [\" \".join(tokenizer.tokenize(t)) for t in templates]\n",
    "\n",
    "\n",
    "# get_objects(sentences1[0].split(), sentence1_templates[0].split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "articles= [\"the\", \"a\", \"an\", \"A\", \"An\", \"The\"]\n",
    "\n",
    "fil3 = [token.upper() for obj in all_obj for token in obj.split(\" \")]\n",
    "fil2 = [[token for token in obj.split(\" \") if token not in articles ] for obj in all_obj]\n",
    "fil = list( map(lambda p:\" \".join([token for token in p.split(\" \") if token not in articles ]), all_obj))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_objects = {}\n",
    "correct_objects = {}\n",
    "all_actions = {}\n",
    "correct_actions = {}\n",
    "\n",
    "for i in range(1000):\n",
    "    path_to_video, target_caption, target_action, target_objects = next(path_gen)\n",
    "    for p in target_objects:\n",
    "        p_tokens = p.split(\" \")\n",
    "        for pto in p_tokens:\n",
    "            all_objects[pto.strip().upper()] = all_objects.get(pto.strip().upper(), 0) + 1\n",
    "        \n",
    "    all_actions[target_action] = all_actions.get(target_action, 0) + 1\n",
    "\n",
    "   \n",
    "    print('sample {}'.format(i)) \n",
    "    pred_caption, pred_action, pred_objects, matched_action = demo(net, preprocessor, path_to_video)\n",
    "    for (i,o) in enumerate(pred_objects):\n",
    "        o_tokens = o.strip().split(\" \")\n",
    "        for oto in o_tokens:\n",
    "            if i<len(target_objects) and oto in target_objects[i].upper():\n",
    "                correct_objects[oto] = correct_objects.get(oto, 0) + 1\n",
    "                print(\"woohoo\")\n",
    "               \n",
    "          \n",
    "    print('TARGET CAPTION: {}'.format(target_caption))\n",
    "    print('PRED   CAPTION: {}\\n'.format(pred_caption))\n",
    "    print('TARGET  ACTION: {}'.format(target_action))\n",
    "    print('CLASSIF ACTION: {}'.format(pred_action))\n",
    "    print('CAPTION ACTION: {}\\n'.format(matched_action))\n",
    "            \n",
    "    print('TARGET OBJECTS: {}'.format(target_objects))\n",
    "    print('PRED   OBJECTS: {}\\n'.format(pred_objects))\n",
    "\n",
    "\n",
    "    if matched_action == target_action:\n",
    "        print(\"yesss\")\n",
    "        correct_actions[matched_action] = correct_actions.get(matched_action, 0) + 1\n",
    "        \n",
    "    print('{}\\n'.format('-'*65))\n",
    "    \n",
    "print(all_objects)\n",
    "print(correct_objects)\n",
    "\n",
    "print(all_actions)\n",
    "print(correct_actions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ca in correct_actions:\n",
    "    \n",
    "    print(\"{}/{} of {} actions correct\".format(correct_actions[ca], all_actions[ca], ca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for correct_key in correct_objects.keys():\n",
    "    denom = 0\n",
    "    if correct_key in all_objects.keys():\n",
    "        denom += all_objects[correct_key]\n",
    "        #print(\"{}:{}\".format(correct_key, all_objects[correct_key]))\n",
    "    #for j in all_objects.keys():\n",
    "    #    if correct_key in j or correct_key in j:\n",
    "    #        print(\"{}:{}\".format(j, all_objects[j]))\n",
    "    #        denom += all_objects[j]\n",
    "        \n",
    "                    \n",
    "    print (\">>model got  {}/{} of '{}'s correct\".format(correct_objects[correct_key],denom, correct_key ))\n",
    "    print(\"-\"*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sum(correct_objects.values())\n",
    "b = sum(all_objects.values())\n",
    "\n",
    "print(\"{} out of {} objects are correctly predicted: {:.2}% \".format(a, b, a/b*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_objects.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = sum(correct_actions.values())\n",
    "d = sum(all_actions.values())\n",
    "\n",
    "print(\"{} out of {} actions are correctly predicted: {:}% \".format(c, d, c/d*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_actions.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
